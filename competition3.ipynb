{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SukhmanpreetKaurManes/THAPAR-KAGGLE-3/blob/main/competition3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# === Load Datasets ===\n",
        "train = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "sample_submission = pd.read_csv('sample_submission.csv', delimiter=',', on_bad_lines='skip')\n",
        "\n",
        "# === Drop unnecessary columns ===\n",
        "train = train.drop(columns=['Row#'])\n",
        "test = test.drop(columns=['Row#'])\n",
        "\n",
        "# === Prepare Features and Target ===\n",
        "X = train.drop(columns=['output'])\n",
        "y = train['output']\n",
        "X_test = test.drop(columns=['id'])\n",
        "\n",
        "# === Scale Features ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === K-Fold Cross-Validation ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
        "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "    score = r2_score(y_val, preds)\n",
        "    r2_scores.append(score)\n",
        "    print(f\"Fold {fold+1} R² Score: {score:.4f}\")\n",
        "\n",
        "print(\"✅ Average R² Score across folds:\", np.mean(r2_scores))\n",
        "\n",
        "# === Train Final Model on All Data ===\n",
        "final_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "final_model.fit(X_scaled, y)\n",
        "\n",
        "# === Predict on Test Data ===\n",
        "final_preds = final_model.predict(X_test_scaled)\n",
        "\n",
        "# === Save Final Submission File ===\n",
        "sample_submission['output'] = final_preds\n",
        "sample_submission.to_csv('sukh.csv', index=False)\n",
        "print(\"✅ sukh.csv created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjpRz6lZ0ani",
        "outputId": "676a0783-d8f5-4e2c-8e61-e5de05899596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 R² Score: 0.9232\n",
            "Fold 2 R² Score: 0.9122\n",
            "Fold 3 R² Score: 0.9113\n",
            "Fold 4 R² Score: 0.9297\n",
            "Fold 5 R² Score: 0.9148\n",
            "✅ Average R² Score across folds: 0.918237640224041\n",
            "✅ sukh.csv created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# === Load your data ===\n",
        "train = pd.read_csv(\"t.csv\").drop(columns=['Row#'])\n",
        "test = pd.read_csv(\"te.csv\").drop(columns=['Row#', 'id'])\n",
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "\n",
        "X = train.drop(columns=['output'])\n",
        "y = train['output']\n",
        "test_ids = pd.read_csv(\"te.csv\")['id']\n",
        "\n",
        "# === Scale Features ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(test)\n",
        "\n",
        "# === Baseline: DummyRegressor to force positive R² ===\n",
        "dummy = DummyRegressor(strategy='mean')\n",
        "dummy.fit(X_scaled, y)\n",
        "dummy_preds = dummy.predict(X_scaled)\n",
        "baseline_r2 = r2_score(y, dummy_preds)\n",
        "print(\"Baseline Dummy R² Score:\", baseline_r2)\n",
        "\n",
        "# === Grid Search with RandomForestRegressor ===\n",
        "param_grid = {\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'min_samples_split': [2, 4],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='r2'\n",
        ")\n",
        "grid.fit(X_scaled, y)\n",
        "\n",
        "print(\"Best GridSearchCV R² Score:\", grid.best_score_)\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "\n",
        "# === Predict and Save Submission File ===\n",
        "final_preds = grid.predict(X_test_scaled)\n",
        "sample_submission['output'] = final_preds.astype(int)\n",
        "sample_submission.to_csv(\"gridsearch_submission.csv\", index=False)\n",
        "print(\"✅ Submission file 'gridsearch_submission.csv' created.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "TRxhu_0G7KoO",
        "outputId": "3652f516-2784-46dc-e778-022c24294f45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 't.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4-411889553.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# === Load your data ===\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Row#'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"te.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Row#'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 't.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "!pip install xgboost\n",
        "\n",
        "import xgboost as xgb\n",
        "\n",
        "# === Prepare Features and Target (already done in the preceding code) ===\n",
        "# X_scaled, y, X_test_scaled are available\n",
        "\n",
        "# === XGBoost K-Fold Cross-Validation ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores_xgb = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
        "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    # Use XGBoost Regressor\n",
        "    model_xgb = xgb.XGBRegressor(objective='reg:squarederror',\n",
        "                                n_estimators=100,\n",
        "                                learning_rate=0.1,\n",
        "                                max_depth=5,\n",
        "                                random_state=42)\n",
        "\n",
        "    model_xgb.fit(X_train, y_train)\n",
        "    preds_xgb = model_xgb.predict(X_val)\n",
        "    score_xgb = r2_score(y_val, preds_xgb)\n",
        "    r2_scores_xgb.append(score_xgb)\n",
        "    print(f\"Fold {fold+1} XGBoost R² Score: {score_xgb:.4f}\")\n",
        "\n",
        "print(\"✅ Average XGBoost R² Score across folds:\", np.mean(r2_scores_xgb))\n",
        "\n",
        "\n",
        "# === Train Final XGBoost Model on All Data ===\n",
        "final_model_xgb = xgb.XGBRegressor(objective='reg:squarederror',\n",
        "                                   n_estimators=100,\n",
        "                                   learning_rate=0.1,\n",
        "                                   max_depth=5,\n",
        "                                   random_state=42)\n",
        "final_model_xgb.fit(X_scaled, y)\n",
        "\n",
        "# === Predict on Test Data with XGBoost ===\n",
        "final_preds_xgb = final_model_xgb.predict(X_test_scaled)\n",
        "\n",
        "# Ensure predictions are integers if the output is expected to be integer-like\n",
        "final_preds_xgb = final_preds_xgb.round().astype(int)\n",
        "\n",
        "\n",
        "# === Save Final Submission File (using XGBoost predictions) ===\n",
        "# sample_submission is already loaded from preceding code\n",
        "sample_submission['output'] = final_preds_xgb\n",
        "sample_submission.to_csv('xgb_submission.csv', index=False)\n",
        "print(\"✅ xgb_submission.csv created!\")\n",
        "\n",
        "\n",
        "# === Optional: XGBoost Grid Search (replace RandomForest Grid Search) ===\n",
        "# If you want to optimize XGBoost hyperparameters\n",
        "# param_grid_xgb = {\n",
        "#     'max_depth': [3, 5, 7],\n",
        "#     'learning_rate': [0.01, 0.1, 0.2],\n",
        "#     'n_estimators': [100, 200, 300],\n",
        "#     'subsample': [0.7, 1.0],\n",
        "#     'colsample_bytree': [0.7, 1.0]\n",
        "# }\n",
        "\n",
        "# grid_xgb = GridSearchCV(\n",
        "#     xgb.XGBRegressor(objective='reg:squareəerror', random_state=42),\n",
        "#     param_grid_xgb,\n",
        "#     cv=5,\n",
        "#     scoring='r2',\n",
        "#     n_jobs=-1 # Use all available cores\n",
        "# )\n",
        "# grid_xgb.fit(X_scaled, y)\n",
        "\n",
        "# print(\"Best GridSearchCV XGBoost R² Score:\", grid_xgb.best_score_)\n",
        "# print(\"Best Params XGBoost:\", grid_xgb.best_params_)\n",
        "\n",
        "# === Predict and Save Submission File with XGBoost Grid Search (if used) ===\n",
        "# final_preds_grid_xgb = grid_xgb.predict(X_test_scaled)\n",
        "# sample_submission['output'] = final_preds_grid_xgb.round().astype(int) # Adjust if output is not integer\n",
        "# sample_submission.to_csv(\"xgb_gridsearch_submission.csv\", index=False)\n",
        "# print(\"✅ Submission file 'xgb_gridsearch_submission.csv' created.\")\n",
        "```"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "RlsJVxUb8o1J",
        "outputId": "611295fd-1855-4018-a1b6-88a6aaecb910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-13-2144675461.py, line 84)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-13-2144675461.py\"\u001b[0;36m, line \u001b[0;32m84\u001b[0m\n\u001b[0;31m    ```\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c69ed4b",
        "outputId": "64143d60-e04f-404a-cf53-8e6b92930d55",
        "collapsed": true
      },
      "source": [
        "# Read the file as plain text to inspect its content\n",
        "try:\n",
        "    with open('sample_submission.csv', 'r') as f:\n",
        "        file_content = f.read()\n",
        "    print(file_content)\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: sample_submission.csv not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the file: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id,output\n",
            "1,5974\n",
            "2,7378\n",
            "3,7092\n",
            "4,8038\n",
            "5,8824\n",
            "6,6575\n",
            "7,8364\n",
            "8,6663\n",
            "9,5211\n",
            "10,6242\n",
            "11,6479\n",
            "12,5973\n",
            "13,6369\n",
            "14,7252\n",
            "15,7619\n",
            "16,7607\n",
            "17,8593\n",
            "18,8650\n",
            "19,8715\n",
            "20,6121\n",
            "21,6248\n",
            "22,4208\n",
            "23,5515\n",
            "24,8678\n",
            "25,7232\n",
            "26,6567\n",
            "27,6813\n",
            "28,6158\n",
            "29,7268\n",
            "30,8514\n",
            "31,8859\n",
            "32,5925\n",
            "33,7642\n",
            "34,5167\n",
            "35,4419\n",
            "36,5038\n",
            "37,6760\n",
            "38,4607\n",
            "39,7195\n",
            "40,7294\n",
            "41,6082\n",
            "42,5096\n",
            "43,6265\n",
            "44,8379\n",
            "45,6720\n",
            "46,6952\n",
            "47,7065\n",
            "48,6793\n",
            "49,7150\n",
            "50,4465\n",
            "51,4668\n",
            "52,7273\n",
            "53,4857\n",
            "54,5685\n",
            "55,7761\n",
            "56,7718\n",
            "57,5528\n",
            "58,8037\n",
            "59,7025\n",
            "60,4589\n",
            "61,4597\n",
            "62,5148\n",
            "63,5610\n",
            "64,6376\n",
            "65,4711\n",
            "66,6220\n",
            "67,6900\n",
            "68,7795\n",
            "69,4778\n",
            "70,4343\n",
            "71,5561\n",
            "72,8863\n",
            "73,7453\n",
            "74,8849\n",
            "75,5831\n",
            "76,5145\n",
            "77,4683\n",
            "78,8773\n",
            "79,5784\n",
            "80,8594\n",
            "81,7390\n",
            "82,8113\n",
            "83,6345\n",
            "84,6078\n",
            "85,5514\n",
            "86,4238\n",
            "87,5323\n",
            "88,5381\n",
            "89,4133\n",
            "90,4412\n",
            "91,5445\n",
            "92,6177\n",
            "93,8277\n",
            "94,5602\n",
            "95,6456\n",
            "96,6236\n",
            "97,6640\n",
            "98,5846\n",
            "99,7124\n",
            "100,6763\n",
            "101,6611\n",
            "102,8562\n",
            "103,5143\n",
            "104,6825\n",
            "105,7145\n",
            "106,5338\n",
            "107,5566\n",
            "108,7044\n",
            "109,7322\n",
            "110,5747\n",
            "111,8956\n",
            "112,6981\n",
            "113,7395\n",
            "114,7539\n",
            "115,8692\n",
            "116,8653\n",
            "117,4155\n",
            "118,8187\n",
            "119,4605\n",
            "120,8089\n",
            "121,4771\n",
            "122,5170\n",
            "123,7779\n",
            "124,5340\n",
            "125,4381\n",
            "126,6405\n",
            "127,4950\n",
            "128,4317\n",
            "129,5927\n",
            "130,7956\n",
            "131,6747\n",
            "132,6920\n",
            "133,5829\n",
            "134,8763\n",
            "135,8058\n",
            "136,8121\n",
            "137,4372\n",
            "138,8664\n",
            "139,5762\n",
            "140,6639\n",
            "141,8059\n",
            "142,6312\n",
            "143,8267\n",
            "144,5331\n",
            "145,7360\n",
            "146,6230\n",
            "147,5242\n",
            "148,8789\n",
            "149,4928\n",
            "150,5649\n",
            "151,7261\n",
            "152,5712\n",
            "153,5084\n",
            "154,7754\n",
            "155,4702\n",
            "156,4211\n",
            "157,7716\n",
            "158,5387\n",
            "159,8823\n",
            "160,6761\n",
            "161,7608\n",
            "162,6513\n",
            "163,6731\n",
            "164,4224\n",
            "165,4552\n",
            "166,5714\n",
            "167,6880\n",
            "168,8291\n",
            "169,4295\n",
            "170,4252\n",
            "171,5403\n",
            "172,7316\n",
            "173,5060\n",
            "174,6990\n",
            "175,8183\n",
            "176,6399\n",
            "177,7059\n",
            "178,6555\n",
            "179,4576\n",
            "180,5520\n",
            "181,5805\n",
            "182,6150\n",
            "183,8554\n",
            "184,6471\n",
            "185,5964\n",
            "186,6331\n",
            "187,7772\n",
            "188,4874\n",
            "189,5768\n",
            "190,4451\n",
            "191,8354\n",
            "192,8851\n",
            "193,4634\n",
            "194,4864\n",
            "195,4611\n",
            "196,4667\n",
            "197,4715\n",
            "198,6871\n",
            "199,7792\n",
            "200,8479\n",
            "201,8803\n",
            "202,4799\n",
            "203,5897\n",
            "204,5617\n",
            "205,4825\n",
            "206,7586\n",
            "207,8345\n",
            "208,6603\n",
            "209,8640\n",
            "210,5189\n",
            "211,6800\n",
            "212,5490\n",
            "213,7335\n",
            "214,8933\n",
            "215,8666\n",
            "216,5387\n",
            "217,4532\n",
            "218,7304\n",
            "219,8500\n",
            "220,7558\n",
            "221,4447\n",
            "222,5911\n",
            "223,4571\n",
            "224,4260\n",
            "225,6798\n",
            "226,6956\n",
            "227,8802\n",
            "228,6930\n",
            "229,4180\n",
            "230,5764\n",
            "231,4186\n",
            "232,4642\n",
            "233,4318\n",
            "234,6157\n",
            "235,8022\n",
            "236,6848\n",
            "237,4336\n",
            "238,8712\n",
            "239,8807\n",
            "240,8917\n",
            "241,8871\n",
            "242,5766\n",
            "243,5962\n",
            "244,7738\n",
            "245,8750\n",
            "246,5679\n",
            "247,8957\n",
            "248,7169\n",
            "249,7919\n",
            "250,8343\n",
            "251,5087\n",
            "252,4429\n",
            "253,5062\n",
            "254,4587\n",
            "255,7389\n",
            "256,6271\n",
            "257,7886\n",
            "258,8732\n",
            "259,7904\n",
            "260,4864\n",
            "261,6483\n",
            "262,6039\n",
            "263,7831\n",
            "264,6106\n",
            "265,4212\n",
            "266,4733\n",
            "267,4443\n",
            "268,6780\n",
            "269,8960\n",
            "270,8109\n",
            "271,8914\n",
            "272,5971\n",
            "273,4651\n",
            "274,8132\n",
            "275,6365\n",
            "276,6317\n",
            "277,7772\n",
            "278,4154\n",
            "279,8223\n",
            "280,4884\n",
            "281,5905\n",
            "282,8517\n",
            "283,8743\n",
            "284,5123\n",
            "285,8663\n",
            "286,6159\n",
            "287,5722\n",
            "288,7502\n",
            "289,6059\n",
            "290,6551\n",
            "291,8849\n",
            "292,8163\n",
            "293,6065\n",
            "294,6933\n",
            "295,6461\n",
            "296,8029\n",
            "297,6277\n",
            "298,6168\n",
            "299,7852\n",
            "300,5383\n",
            "301,4189\n",
            "302,4204\n",
            "303,7395\n",
            "304,5684\n",
            "305,8644\n",
            "306,7820\n",
            "307,6632\n",
            "308,4177\n",
            "309,4452\n",
            "310,8540\n",
            "311,6948\n",
            "312,8801\n",
            "313,5870\n",
            "314,8529\n",
            "315,5356\n",
            "316,8725\n",
            "317,8808\n",
            "318,8087\n",
            "319,7470\n",
            "320,5850\n",
            "321,7506\n",
            "322,7426\n",
            "323,6676\n",
            "324,8293\n",
            "325,6258\n",
            "326,6015\n",
            "327,4420\n",
            "328,4752\n",
            "329,5209\n",
            "330,8156\n",
            "331,5745\n",
            "332,6852\n",
            "333,6039\n",
            "334,8202\n",
            "335,4966\n",
            "336,7901\n",
            "337,6864\n",
            "338,7178\n",
            "339,4593\n",
            "340,5431\n",
            "341,6635\n",
            "342,5316\n",
            "343,6612\n",
            "344,5588\n",
            "345,5927\n",
            "346,6858\n",
            "347,6659\n",
            "348,7613\n",
            "349,8404\n",
            "350,6132\n",
            "351,6447\n",
            "352,5399\n",
            "353,4064\n",
            "354,8783\n",
            "355,4215\n",
            "356,5373\n",
            "357,8099\n",
            "358,6080\n",
            "359,4338\n",
            "360,6037\n",
            "361,6127\n",
            "362,6435\n",
            "363,7371\n",
            "364,8143\n",
            "365,4590\n",
            "366,8023\n",
            "367,6808\n",
            "368,5935\n",
            "369,7249\n",
            "370,8375\n",
            "371,5955\n",
            "372,5565\n",
            "373,5149\n",
            "374,5993\n",
            "375,7411\n",
            "376,7969\n",
            "377,4165\n",
            "378,7918\n",
            "379,6662\n",
            "380,4241\n",
            "381,8915\n",
            "382,4494\n",
            "383,6035\n",
            "384,6098\n",
            "385,4168\n",
            "386,7718\n",
            "387,6887\n",
            "388,6061\n",
            "389,6809\n",
            "390,5881\n",
            "391,5602\n",
            "392,5726\n",
            "393,5461\n",
            "394,6039\n",
            "395,6680\n",
            "396,7967\n",
            "397,6149\n",
            "398,4076\n",
            "399,6763\n",
            "400,7647\n",
            "401,8748\n",
            "402,5100\n",
            "403,6444\n",
            "404,8276\n",
            "405,6814\n",
            "406,4680\n",
            "407,7789\n",
            "408,4399\n",
            "409,4170\n",
            "410,6364\n",
            "411,5895\n",
            "412,4177\n",
            "413,8658\n",
            "414,4603\n",
            "415,5414\n",
            "416,8873\n",
            "417,4132\n",
            "418,6830\n",
            "419,8125\n",
            "420,4555\n",
            "421,7895\n",
            "422,7223\n",
            "423,6312\n",
            "424,6017\n",
            "425,5564\n",
            "426,8168\n",
            "427,7005\n",
            "428,5033\n",
            "429,5405\n",
            "430,4065\n",
            "431,5718\n",
            "432,4095\n",
            "433,6963\n",
            "434,4877\n",
            "435,6664\n",
            "436,7815\n",
            "437,7961\n",
            "438,8046\n",
            "439,8387\n",
            "440,5431\n",
            "441,6971\n",
            "442,4688\n",
            "443,4964\n",
            "444,7017\n",
            "445,7124\n",
            "446,7044\n",
            "447,4921\n",
            "448,5690\n",
            "449,8937\n",
            "450,5527\n",
            "451,7418\n",
            "452,5788\n",
            "453,8678\n",
            "454,7951\n",
            "455,6696\n",
            "456,4844\n",
            "457,7178\n",
            "458,4890\n",
            "459,8884\n",
            "460,8786\n",
            "461,8594\n",
            "462,4501\n",
            "463,5365\n",
            "464,7990\n",
            "465,7853\n",
            "466,7178\n",
            "467,6670\n",
            "468,7247\n",
            "469,5677\n",
            "470,8124\n",
            "471,7839\n",
            "472,7869\n",
            "473,4781\n",
            "474,8958\n",
            "475,5718\n",
            "476,6091\n",
            "477,4732\n",
            "478,8395\n",
            "479,4610\n",
            "480,5138\n",
            "481,6084\n",
            "482,6119\n",
            "483,6325\n",
            "484,7682\n",
            "485,7610\n",
            "486,6437\n",
            "487,6644\n",
            "488,5674\n",
            "489,7989\n",
            "490,7201\n",
            "491,8142\n",
            "492,6004\n",
            "493,8653\n",
            "494,8948\n",
            "495,5799\n",
            "496,5306\n",
            "497,5038\n",
            "498,7915\n",
            "499,6009\n",
            "500,5788\n",
            "501,7230\n",
            "502,8047\n",
            "503,7090\n",
            "504,5894\n",
            "505,4520\n",
            "506,7053\n",
            "507,4677\n",
            "508,6874\n",
            "509,7521\n",
            "510,4720\n",
            "511,4716\n",
            "512,8711\n",
            "513,4927\n",
            "514,4411\n",
            "515,5632\n",
            "516,5059\n",
            "517,4752\n",
            "518,4305\n",
            "519,5828\n",
            "520,6974\n",
            "521,5170\n",
            "522,6046\n",
            "523,6492\n",
            "524,8095\n",
            "525,6543\n",
            "526,7885\n",
            "527,6543\n",
            "528,7762\n",
            "529,7022\n",
            "530,5188\n",
            "531,8829\n",
            "532,8658\n",
            "533,7714\n",
            "534,8571\n",
            "535,4723\n",
            "536,4410\n",
            "537,7202\n",
            "538,7432\n",
            "539,5472\n",
            "540,8904\n",
            "541,6033\n",
            "542,5058\n",
            "543,4860\n",
            "544,6642\n",
            "545,6385\n",
            "546,8633\n",
            "547,7189\n",
            "548,7499\n",
            "549,6610\n",
            "550,5601\n",
            "551,7006\n",
            "552,4288\n",
            "553,7768\n",
            "554,5076\n",
            "555,7776\n",
            "556,6412\n",
            "557,6187\n",
            "558,6475\n",
            "559,7198\n",
            "560,8144\n",
            "561,4497\n",
            "562,5537\n",
            "563,4596\n",
            "564,5502\n",
            "565,8084\n",
            "566,7247\n",
            "567,8403\n",
            "568,4986\n",
            "569,8405\n",
            "570,5671\n",
            "571,5337\n",
            "572,7587\n",
            "573,4563\n",
            "574,6968\n",
            "575,5272\n",
            "576,4137\n",
            "577,8405\n",
            "578,6293\n",
            "579,8771\n",
            "580,6149\n",
            "581,5674\n",
            "582,5781\n",
            "583,4173\n",
            "584,5172\n",
            "585,8786\n",
            "586,5514\n",
            "587,7200\n",
            "588,6767\n",
            "589,6384\n",
            "590,8347\n",
            "591,4429\n",
            "592,8383\n",
            "593,4099\n",
            "594,8095\n",
            "595,4081\n",
            "596,8697\n",
            "597,7171\n",
            "598,4546\n",
            "599,4719\n",
            "600,6195\n",
            "601,4939\n",
            "602,6227\n",
            "603,7299\n",
            "604,6391\n",
            "605,4235\n",
            "606,7722\n",
            "607,6592\n",
            "608,8282\n",
            "609,8785\n",
            "610,8749\n",
            "611,5880\n",
            "612,7404\n",
            "613,7338\n",
            "614,7663\n",
            "615,7230\n",
            "616,8846\n",
            "617,6157\n",
            "618,7129\n",
            "619,5475\n",
            "620,7044\n",
            "621,4864\n",
            "622,4194\n",
            "623,7330\n",
            "624,6722\n",
            "625,4280\n",
            "626,4695\n",
            "627,7222\n",
            "628,6313\n",
            "629,8682\n",
            "630,8050\n",
            "631,6751\n",
            "632,7040\n",
            "633,6259\n",
            "634,6568\n",
            "635,7210\n",
            "636,4194\n",
            "637,7233\n",
            "638,7364\n",
            "639,5132\n",
            "640,7678\n",
            "641,4505\n",
            "642,4887\n",
            "643,4392\n",
            "644,4836\n",
            "645,7543\n",
            "646,6439\n",
            "647,5064\n",
            "648,6188\n",
            "649,6513\n",
            "650,5490\n",
            "651,6138\n",
            "652,4070\n",
            "653,8794\n",
            "654,8211\n",
            "655,8436\n",
            "656,4851\n",
            "657,7236\n",
            "658,8782\n",
            "659,4424\n",
            "660,6522\n",
            "661,5293\n",
            "662,8663\n",
            "663,5576\n",
            "664,8551\n",
            "665,7932\n",
            "666,5615\n",
            "667,6276\n",
            "668,4172\n",
            "669,4083\n",
            "670,6363\n",
            "671,5731\n",
            "672,7453\n",
            "673,8524\n",
            "674,4293\n",
            "675,6337\n",
            "676,7669\n",
            "677,7448\n",
            "678,4169\n",
            "679,4717\n",
            "680,8423\n",
            "681,8077\n",
            "682,7412\n",
            "683,4180\n",
            "684,6014\n",
            "685,7025\n",
            "686,6904\n",
            "687,7608\n",
            "688,4861\n",
            "689,8054\n",
            "690,5072\n",
            "691,6533\n",
            "692,5151\n",
            "693,8006\n",
            "694,4685\n",
            "695,6300\n",
            "696,5261\n",
            "697,4087\n",
            "698,8330\n",
            "699,7835\n",
            "700,8812\n",
            "701,5775\n",
            "702,5135\n",
            "703,5010\n",
            "704,6549\n",
            "705,8061\n",
            "706,8672\n",
            "707,6065\n",
            "708,8033\n",
            "709,5941\n",
            "710,7497\n",
            "711,6522\n",
            "712,4362\n",
            "713,7770\n",
            "714,8177\n",
            "715,6367\n",
            "716,5030\n",
            "717,5995\n",
            "718,8638\n",
            "719,5173\n",
            "720,5958\n",
            "721,5993\n",
            "722,4225\n",
            "723,8786\n",
            "724,7006\n",
            "725,7347\n",
            "726,7927\n",
            "727,4393\n",
            "728,5641\n",
            "729,6681\n",
            "730,8903\n",
            "731,7419\n",
            "732,8439\n",
            "733,4529\n",
            "734,6546\n",
            "735,8584\n",
            "736,6784\n",
            "737,8131\n",
            "738,6825\n",
            "739,6090\n",
            "740,4774\n",
            "741,6468\n",
            "742,5227\n",
            "743,4582\n",
            "744,8951\n",
            "745,4349\n",
            "746,5328\n",
            "747,5261\n",
            "748,8959\n",
            "749,8522\n",
            "750,8795\n",
            "751,6001\n",
            "752,4152\n",
            "753,8697\n",
            "754,5826\n",
            "755,8873\n",
            "756,5650\n",
            "757,4149\n",
            "758,8766\n",
            "759,5244\n",
            "760,4421\n",
            "761,4859\n",
            "762,6312\n",
            "763,5926\n",
            "764,8851\n",
            "765,8922\n",
            "766,8328\n",
            "767,5285\n",
            "768,6207\n",
            "769,8142\n",
            "770,6201\n",
            "771,7301\n",
            "772,8881\n",
            "773,7166\n",
            "774,5981\n",
            "775,5244\n",
            "776,7715\n",
            "777,6618\n",
            "778,6954\n",
            "779,4291\n",
            "780,7007\n",
            "781,6681\n",
            "782,8907\n",
            "783,7010\n",
            "784,8252\n",
            "785,8328\n",
            "786,8014\n",
            "787,6260\n",
            "788,7701\n",
            "789,7188\n",
            "790,8792\n",
            "791,7860\n",
            "792,7904\n",
            "793,6934\n",
            "794,5253\n",
            "795,4104\n",
            "796,4297\n",
            "797,8080\n",
            "798,7816\n",
            "799,5051\n",
            "800,4580\n",
            "801,6253\n",
            "802,8709\n",
            "803,5089\n",
            "804,7230\n",
            "805,8465\n",
            "806,4148\n",
            "807,8710\n",
            "808,7806\n",
            "809,8858\n",
            "810,4183\n",
            "811,7131\n",
            "812,8129\n",
            "813,4649\n",
            "814,6054\n",
            "815,8546\n",
            "816,7070\n",
            "817,7306\n",
            "818,8780\n",
            "819,7609\n",
            "820,6479\n",
            "821,6864\n",
            "822,4842\n",
            "823,4867\n",
            "824,8314\n",
            "825,6444\n",
            "826,8218\n",
            "827,8657\n",
            "828,7835\n",
            "829,6576\n",
            "830,8167\n",
            "831,5729\n",
            "832,6240\n",
            "833,4495\n",
            "834,4324\n",
            "835,5800\n",
            "836,4201\n",
            "837,5464\n",
            "838,8728\n",
            "839,8813\n",
            "840,5093\n",
            "841,8943\n",
            "842,7486\n",
            "843,5319\n",
            "844,6901\n",
            "845,7103\n",
            "846,5231\n",
            "847,4578\n",
            "848,7856\n",
            "849,8537\n",
            "850,7447\n",
            "851,7416\n",
            "852,8157\n",
            "853,5798\n",
            "854,5806\n",
            "855,5757\n",
            "856,6818\n",
            "857,6739\n",
            "858,5948\n",
            "859,5492\n",
            "860,7090\n",
            "861,7538\n",
            "862,7903\n",
            "863,4841\n",
            "864,7812\n",
            "865,4901\n",
            "866,6900\n",
            "867,6399\n",
            "868,7517\n",
            "869,6356\n",
            "870,6160\n",
            "871,8187\n",
            "872,7834\n",
            "873,8645\n",
            "874,6169\n",
            "875,5229\n",
            "876,4284\n",
            "877,7451\n",
            "878,5342\n",
            "879,8737\n",
            "880,6090\n",
            "881,6887\n",
            "882,8361\n",
            "883,8604\n",
            "884,4068\n",
            "885,6381\n",
            "886,8090\n",
            "887,4879\n",
            "888,5249\n",
            "889,7972\n",
            "890,6296\n",
            "891,5947\n",
            "892,7396\n",
            "893,6001\n",
            "894,4491\n",
            "895,6756\n",
            "896,5698\n",
            "897,8255\n",
            "898,6771\n",
            "899,5613\n",
            "900,4222\n",
            "901,6828\n",
            "902,7438\n",
            "903,8172\n",
            "904,7509\n",
            "905,7272\n",
            "906,8379\n",
            "907,8494\n",
            "908,5530\n",
            "909,8719\n",
            "910,6643\n",
            "911,7632\n",
            "912,6407\n",
            "913,7306\n",
            "914,6658\n",
            "915,7918\n",
            "916,5570\n",
            "917,5293\n",
            "918,6611\n",
            "919,7891\n",
            "920,4895\n",
            "921,5846\n",
            "922,7616\n",
            "923,8817\n",
            "924,8737\n",
            "925,5917\n",
            "926,4767\n",
            "927,5459\n",
            "928,5008\n",
            "929,4116\n",
            "930,8547\n",
            "931,5879\n",
            "932,6224\n",
            "933,4309\n",
            "934,8391\n",
            "935,6224\n",
            "936,5044\n",
            "937,4132\n",
            "938,8039\n",
            "939,6889\n",
            "940,5882\n",
            "941,4877\n",
            "942,8107\n",
            "943,4738\n",
            "944,6702\n",
            "945,5328\n",
            "946,8963\n",
            "947,5260\n",
            "948,8968\n",
            "949,6841\n",
            "950,8925\n",
            "951,5532\n",
            "952,6201\n",
            "953,5696\n",
            "954,5760\n",
            "955,6923\n",
            "956,8186\n",
            "957,5652\n",
            "958,5776\n",
            "959,7549\n",
            "960,7334\n",
            "961,5091\n",
            "962,4888\n",
            "963,8908\n",
            "964,6218\n",
            "965,5006\n",
            "966,7739\n",
            "967,4175\n",
            "968,6289\n",
            "969,4847\n",
            "970,7074\n",
            "971,6856\n",
            "972,8226\n",
            "973,8084\n",
            "974,6454\n",
            "975,8654\n",
            "976,4624\n",
            "977,8634\n",
            "978,8940\n",
            "979,5603\n",
            "980,5586\n",
            "981,6066\n",
            "982,6922\n",
            "983,7688\n",
            "984,5598\n",
            "985,7785\n",
            "986,5080\n",
            "987,4670\n",
            "988,7188\n",
            "989,5098\n",
            "990,6348\n",
            "991,4098\n",
            "992,5814\n",
            "993,5068\n",
            "994,4964\n",
            "995,7495\n",
            "996,5923\n",
            "997,4168\n",
            "998,4524\n",
            "999,4078\n",
            "1000,5778\n",
            "1001,8793\n",
            "1002,4280\n",
            "1003,6080\n",
            "1004,6693\n",
            "1005,7791\n",
            "1006,7888\n",
            "1007,8104\n",
            "1008,4947\n",
            "1009,8126\n",
            "1010,7792\n",
            "1011,8272\n",
            "1012,4936\n",
            "1013,6931\n",
            "1014,8777\n",
            "1015,5730\n",
            "1016,7222\n",
            "1017,7152\n",
            "1018,4429\n",
            "1019,6405\n",
            "1020,4905\n",
            "1021,5416\n",
            "1022,7692\n",
            "1023,4215\n",
            "1024,5256\n",
            "1025,8069\n",
            "1026,6300\n",
            "1027,8069\n",
            "1028,6883\n",
            "1029,6870\n",
            "1030,4797\n",
            "1031,7498\n",
            "1032,8314\n",
            "1033,8080\n",
            "1034,7586\n",
            "1035,5659\n",
            "1036,8542\n",
            "1037,5291\n",
            "1038,4428\n",
            "1039,6262\n",
            "1040,8364\n",
            "1041,6799\n",
            "1042,4753\n",
            "1043,6316\n",
            "1044,5827\n",
            "1045,5722\n",
            "1046,4733\n",
            "1047,8194\n",
            "1048,5408\n",
            "1049,4795\n",
            "1050,4574\n",
            "1051,5896\n",
            "1052,8076\n",
            "1053,5318\n",
            "1054,5652\n",
            "1055,5593\n",
            "1056,5671\n",
            "1057,6649\n",
            "1058,7579\n",
            "1059,6598\n",
            "1060,6557\n",
            "1061,5710\n",
            "1062,4944\n",
            "1063,8352\n",
            "1064,4350\n",
            "1065,5832\n",
            "1066,7460\n",
            "1067,7525\n",
            "1068,8280\n",
            "1069,5992\n",
            "1070,7562\n",
            "1071,4377\n",
            "1072,4896\n",
            "1073,6654\n",
            "1074,8558\n",
            "1075,6740\n",
            "1076,6744\n",
            "1077,8671\n",
            "1078,6217\n",
            "1079,6194\n",
            "1080,4711\n",
            "1081,5194\n",
            "1082,6443\n",
            "1083,5256\n",
            "1084,8498\n",
            "1085,7053\n",
            "1086,8308\n",
            "1087,8278\n",
            "1088,5466\n",
            "1089,5358\n",
            "1090,8802\n",
            "1091,5950\n",
            "1092,7172\n",
            "1093,6370\n",
            "1094,7394\n",
            "1095,8340\n",
            "1096,7780\n",
            "1097,6091\n",
            "1098,6534\n",
            "1099,7570\n",
            "1100,7053\n",
            "1101,4455\n",
            "1102,6572\n",
            "1103,4942\n",
            "1104,7959\n",
            "1105,6830\n",
            "1106,7329\n",
            "1107,6299\n",
            "1108,7529\n",
            "1109,6913\n",
            "1110,8633\n",
            "1111,4776\n",
            "1112,6867\n",
            "1113,7342\n",
            "1114,7664\n",
            "1115,5546\n",
            "1116,6788\n",
            "1117,8739\n",
            "1118,7322\n",
            "1119,4816\n",
            "1120,6231\n",
            "1121,4685\n",
            "1122,4921\n",
            "1123,7255\n",
            "1124,4874\n",
            "1125,4201\n",
            "1126,8732\n",
            "1127,4309\n",
            "1128,7478\n",
            "1129,4181\n",
            "1130,8766\n",
            "1131,4353\n",
            "1132,8589\n",
            "1133,7683\n",
            "1134,6433\n",
            "1135,7343\n",
            "1136,4883\n",
            "1137,4285\n",
            "1138,4551\n",
            "1139,8324\n",
            "1140,8639\n",
            "1141,6784\n",
            "1142,8072\n",
            "1143,8853\n",
            "1144,7678\n",
            "1145,6330\n",
            "1146,5212\n",
            "1147,8361\n",
            "1148,7454\n",
            "1149,6299\n",
            "1150,7645\n",
            "1151,4206\n",
            "1152,8727\n",
            "1153,6374\n",
            "1154,4362\n",
            "1155,6376\n",
            "1156,6804\n",
            "1157,4086\n",
            "1158,6467\n",
            "1159,6639\n",
            "1160,6192\n",
            "1161,7958\n",
            "1162,7047\n",
            "1163,4643\n",
            "1164,8157\n",
            "1165,4570\n",
            "1166,7264\n",
            "1167,7780\n",
            "1168,8169\n",
            "1169,8552\n",
            "1170,6358\n",
            "1171,5507\n",
            "1172,6688\n",
            "1173,7897\n",
            "1174,5053\n",
            "1175,8667\n",
            "1176,4700\n",
            "1177,7920\n",
            "1178,6904\n",
            "1179,8666\n",
            "1180,5052\n",
            "1181,6938\n",
            "1182,5917\n",
            "1183,6737\n",
            "1184,7189\n",
            "1185,7997\n",
            "1186,7529\n",
            "1187,6346\n",
            "1188,5782\n",
            "1189,6980\n",
            "1190,4103\n",
            "1191,8772\n",
            "1192,4688\n",
            "1193,8827\n",
            "1194,6298\n",
            "1195,4162\n",
            "1196,8739\n",
            "1197,7560\n",
            "1198,8126\n",
            "1199,7960\n",
            "1200,4981\n",
            "1201,6122\n",
            "1202,5024\n",
            "1203,6033\n",
            "1204,7691\n",
            "1205,8006\n",
            "1206,6558\n",
            "1207,5273\n",
            "1208,6414\n",
            "1209,4285\n",
            "1210,8706\n",
            "1211,6304\n",
            "1212,4256\n",
            "1213,6218\n",
            "1214,5698\n",
            "1215,5199\n",
            "1216,5859\n",
            "1217,6859\n",
            "1218,7726\n",
            "1219,7674\n",
            "1220,6480\n",
            "1221,4433\n",
            "1222,5395\n",
            "1223,8051\n",
            "1224,6684\n",
            "1225,7177\n",
            "1226,7971\n",
            "1227,6087\n",
            "1228,8610\n",
            "1229,6794\n",
            "1230,6416\n",
            "1231,5491\n",
            "1232,6826\n",
            "1233,6768\n",
            "1234,5770\n",
            "1235,7524\n",
            "1236,8444\n",
            "1237,6135\n",
            "1238,7782\n",
            "1239,5490\n",
            "1240,5728\n",
            "1241,7272\n",
            "1242,6342\n",
            "1243,8877\n",
            "1244,6207\n",
            "1245,4269\n",
            "1246,8737\n",
            "1247,5430\n",
            "1248,8101\n",
            "1249,8816\n",
            "1250,6012\n",
            "1251,7579\n",
            "1252,4785\n",
            "1253,4136\n",
            "1254,4820\n",
            "1255,8558\n",
            "1256,8400\n",
            "1257,8379\n",
            "1258,4642\n",
            "1259,4924\n",
            "1260,5064\n",
            "1261,4970\n",
            "1262,5551\n",
            "1263,8199\n",
            "1264,8530\n",
            "1265,8945\n",
            "1266,6599\n",
            "1267,7571\n",
            "1268,7383\n",
            "1269,6804\n",
            "1270,6102\n",
            "1271,6644\n",
            "1272,8050\n",
            "1273,8341\n",
            "1274,7124\n",
            "1275,5809\n",
            "1276,4763\n",
            "1277,4650\n",
            "1278,4609\n",
            "1279,8327\n",
            "1280,8356\n",
            "1281,8798\n",
            "1282,6675\n",
            "1283,8533\n",
            "1284,7196\n",
            "1285,6728\n",
            "1286,8139\n",
            "1287,8932\n",
            "1288,7845\n",
            "1289,4674\n",
            "1290,6645\n",
            "1291,4196\n",
            "1292,4948\n",
            "1293,5984\n",
            "1294,5040\n",
            "1295,4854\n",
            "1296,6172\n",
            "1297,4842\n",
            "1298,6057\n",
            "1299,4853\n",
            "1300,6062\n",
            "1301,5803\n",
            "1302,7983\n",
            "1303,4989\n",
            "1304,7378\n",
            "1305,7802\n",
            "1306,6925\n",
            "1307,5976\n",
            "1308,4433\n",
            "1309,4174\n",
            "1310,8923\n",
            "1311,5374\n",
            "1312,6692\n",
            "1313,5584\n",
            "1314,6076\n",
            "1315,7527\n",
            "1316,8596\n",
            "1317,6726\n",
            "1318,5599\n",
            "1319,4615\n",
            "1320,6843\n",
            "1321,6768\n",
            "1322,7274\n",
            "1323,5318\n",
            "1324,5341\n",
            "1325,6421\n",
            "1326,8705\n",
            "1327,8067\n",
            "1328,8895\n",
            "1329,6959\n",
            "1330,6602\n",
            "1331,8296\n",
            "1332,4433\n",
            "1333,5902\n",
            "1334,5416\n",
            "1335,4333\n",
            "1336,4066\n",
            "1337,4965\n",
            "1338,4188\n",
            "1339,5630\n",
            "1340,8225\n",
            "1341,6032\n",
            "1342,7204\n",
            "1343,5229\n",
            "1344,4949\n",
            "1345,7789\n",
            "1346,4237\n",
            "1347,5531\n",
            "1348,6137\n",
            "1349,5152\n",
            "1350,4656\n",
            "1351,8362\n",
            "1352,6864\n",
            "1353,4733\n",
            "1354,6677\n",
            "1355,6662\n",
            "1356,4667\n",
            "1357,4081\n",
            "1358,8028\n",
            "1359,7882\n",
            "1360,5303\n",
            "1361,7339\n",
            "1362,8245\n",
            "1363,5658\n",
            "1364,8334\n",
            "1365,4490\n",
            "1366,6535\n",
            "1367,6864\n",
            "1368,7848\n",
            "1369,6781\n",
            "1370,5938\n",
            "1371,5019\n",
            "1372,8576\n",
            "1373,5916\n",
            "1374,7478\n",
            "1375,7826\n",
            "1376,7845\n",
            "1377,6022\n",
            "1378,7955\n",
            "1379,5908\n",
            "1380,5785\n",
            "1381,4840\n",
            "1382,4631\n",
            "1383,6373\n",
            "1384,5303\n",
            "1385,7943\n",
            "1386,6962\n",
            "1387,8798\n",
            "1388,7891\n",
            "1389,4457\n",
            "1390,7586\n",
            "1391,5093\n",
            "1392,7134\n",
            "1393,6876\n",
            "1394,4839\n",
            "1395,6708\n",
            "1396,8459\n",
            "1397,7534\n",
            "1398,6631\n",
            "1399,6969\n",
            "1400,6551\n",
            "1401,5622\n",
            "1402,7570\n",
            "1403,8336\n",
            "1404,6222\n",
            "1405,5169\n",
            "1406,8270\n",
            "1407,5224\n",
            "1408,8282\n",
            "1409,5094\n",
            "1410,6742\n",
            "1411,6347\n",
            "1412,8019\n",
            "1413,5406\n",
            "1414,4897\n",
            "1415,6680\n",
            "1416,4415\n",
            "1417,8933\n",
            "1418,5146\n",
            "1419,5261\n",
            "1420,6167\n",
            "1421,5087\n",
            "1422,5475\n",
            "1423,8427\n",
            "1424,4570\n",
            "1425,7830\n",
            "1426,7446\n",
            "1427,5066\n",
            "1428,4862\n",
            "1429,5853\n",
            "1430,7913\n",
            "1431,7578\n",
            "1432,7191\n",
            "1433,6399\n",
            "1434,6027\n",
            "1435,4780\n",
            "1436,6718\n",
            "1437,7169\n",
            "1438,8147\n",
            "1439,5705\n",
            "1440,4168\n",
            "1441,7067\n",
            "1442,6824\n",
            "1443,8908\n",
            "1444,4281\n",
            "1445,5082\n",
            "1446,7365\n",
            "1447,8336\n",
            "1448,5499\n",
            "1449,4583\n",
            "1450,4681\n",
            "1451,5454\n",
            "1452,5736\n",
            "1453,4587\n",
            "1454,6280\n",
            "1455,4738\n",
            "1456,4601\n",
            "1457,5530\n",
            "1458,7359\n",
            "1459,5231\n",
            "1460,6450\n",
            "1461,8215\n",
            "1462,6630\n",
            "1463,8393\n",
            "1464,4648\n",
            "1465,4779\n",
            "1466,4880\n",
            "1467,6289\n",
            "1468,4590\n",
            "1469,5977\n",
            "1470,8547\n",
            "1471,5597\n",
            "1472,5154\n",
            "1473,8264\n",
            "1474,7885\n",
            "1475,8710\n",
            "1476,4609\n",
            "1477,6850\n",
            "1478,6347\n",
            "1479,6590\n",
            "1480,5248\n",
            "1481,8483\n",
            "1482,6851\n",
            "1483,8514\n",
            "1484,5164\n",
            "1485,8406\n",
            "1486,4898\n",
            "1487,7048\n",
            "1488,4858\n",
            "1489,5379\n",
            "1490,5757\n",
            "1491,7738\n",
            "1492,6057\n",
            "1493,8171\n",
            "1494,5525\n",
            "1495,5863\n",
            "1496,8081\n",
            "1497,4644\n",
            "1498,4565\n",
            "1499,4826\n",
            "1500,4852\n",
            "1501,7116\n",
            "1502,5551\n",
            "1503,5156\n",
            "1504,7216\n",
            "1505,7689\n",
            "1506,5845\n",
            "1507,7584\n",
            "1508,5938\n",
            "1509,5904\n",
            "1510,7939\n",
            "1511,8237\n",
            "1512,4904\n",
            "1513,5124\n",
            "1514,5579\n",
            "1515,4883\n",
            "1516,8742\n",
            "1517,5537\n",
            "1518,6533\n",
            "1519,7492\n",
            "1520,8144\n",
            "1521,6597\n",
            "1522,8734\n",
            "1523,4270\n",
            "1524,8689\n",
            "1525,8731\n",
            "1526,7427\n",
            "1527,6475\n",
            "1528,4236\n",
            "1529,4241\n",
            "1530,8217\n",
            "1531,7145\n",
            "1532,5532\n",
            "1533,8209\n",
            "1534,4300\n",
            "1535,8356\n",
            "1536,7497\n",
            "1537,8797\n",
            "1538,7305\n",
            "1539,6883\n",
            "1540,6826\n",
            "1541,8969\n",
            "1542,4279\n",
            "1543,7604\n",
            "1544,7075\n",
            "1545,8847\n",
            "1546,5585\n",
            "1547,6993\n",
            "1548,7582\n",
            "1549,7843\n",
            "1550,8373\n",
            "1551,5864\n",
            "1552,7900\n",
            "1553,7985\n",
            "1554,7390\n",
            "1555,7087\n",
            "1556,8085\n",
            "1557,7565\n",
            "1558,5402\n",
            "1559,6843\n",
            "1560,7582\n",
            "1561,8695\n",
            "1562,6695\n",
            "1563,4191\n",
            "1564,4342\n",
            "1565,7082\n",
            "1566,6740\n",
            "1567,7132\n",
            "1568,7907\n",
            "1569,8859\n",
            "1570,8108\n",
            "1571,8512\n",
            "1572,6008\n",
            "1573,5642\n",
            "1574,5983\n",
            "1575,8226\n",
            "1576,4363\n",
            "1577,6879\n",
            "1578,7317\n",
            "1579,7748\n",
            "1580,7518\n",
            "1581,5574\n",
            "1582,8776\n",
            "1583,6697\n",
            "1584,5742\n",
            "1585,5404\n",
            "1586,8070\n",
            "1587,8195\n",
            "1588,5773\n",
            "1589,5908\n",
            "1590,6090\n",
            "1591,6893\n",
            "1592,6882\n",
            "1593,5281\n",
            "1594,5444\n",
            "1595,5333\n",
            "1596,7116\n",
            "1597,7671\n",
            "1598,8062\n",
            "1599,6885\n",
            "1600,5963\n",
            "1601,5810\n",
            "1602,5119\n",
            "1603,6886\n",
            "1604,4148\n",
            "1605,7842\n",
            "1606,4634\n",
            "1607,5830\n",
            "1608,4334\n",
            "1609,6740\n",
            "1610,8024\n",
            "1611,5235\n",
            "1612,6818\n",
            "1613,8813\n",
            "1614,4091\n",
            "1615,5348\n",
            "1616,5965\n",
            "1617,4139\n",
            "1618,6680\n",
            "1619,6869\n",
            "1620,5251\n",
            "1621,7964\n",
            "1622,5966\n",
            "1623,4354\n",
            "1624,5864\n",
            "1625,8191\n",
            "1626,8069\n",
            "1627,4636\n",
            "1628,5257\n",
            "1629,4504\n",
            "1630,4472\n",
            "1631,6233\n",
            "1632,5785\n",
            "1633,7331\n",
            "1634,7961\n",
            "1635,6162\n",
            "1636,7229\n",
            "1637,8410\n",
            "1638,5362\n",
            "1639,5987\n",
            "1640,7323\n",
            "1641,4114\n",
            "1642,5249\n",
            "1643,5027\n",
            "1644,6927\n",
            "1645,8474\n",
            "1646,4720\n",
            "1647,6985\n",
            "1648,5617\n",
            "1649,8756\n",
            "1650,5709\n",
            "1651,5982\n",
            "1652,5758\n",
            "1653,6741\n",
            "1654,7392\n",
            "1655,5464\n",
            "1656,4701\n",
            "1657,5562\n",
            "1658,5361\n",
            "1659,5926\n",
            "1660,6798\n",
            "1661,7454\n",
            "1662,5938\n",
            "1663,4739\n",
            "1664,6830\n",
            "1665,6645\n",
            "1666,5647\n",
            "1667,6412\n",
            "1668,8314\n",
            "1669,4783\n",
            "1670,4826\n",
            "1671,8224\n",
            "1672,6911\n",
            "1673,8713\n",
            "1674,6613\n",
            "1675,8685\n",
            "1676,7256\n",
            "1677,4077\n",
            "1678,4970\n",
            "1679,7454\n",
            "1680,4141\n",
            "1681,6786\n",
            "1682,7153\n",
            "1683,7768\n",
            "1684,6807\n",
            "1685,6811\n",
            "1686,7180\n",
            "1687,6878\n",
            "1688,6195\n",
            "1689,4325\n",
            "1690,4724\n",
            "1691,7055\n",
            "1692,4535\n",
            "1693,6453\n",
            "1694,4783\n",
            "1695,8081\n",
            "1696,7142\n",
            "1697,7829\n",
            "1698,8535\n",
            "1699,7943\n",
            "1700,4345\n",
            "1701,8871\n",
            "1702,8565\n",
            "1703,8584\n",
            "1704,8154\n",
            "1705,5959\n",
            "1706,8844\n",
            "1707,8425\n",
            "1708,5679\n",
            "1709,7436\n",
            "1710,5531\n",
            "1711,5967\n",
            "1712,6424\n",
            "1713,6505\n",
            "1714,5145\n",
            "1715,6670\n",
            "1716,8798\n",
            "1717,5003\n",
            "1718,5102\n",
            "1719,8268\n",
            "1720,4216\n",
            "1721,5583\n",
            "1722,7494\n",
            "1723,8346\n",
            "1724,8072\n",
            "1725,8630\n",
            "1726,6763\n",
            "1727,8635\n",
            "1728,7575\n",
            "1729,4385\n",
            "1730,8957\n",
            "1731,6371\n",
            "1732,4505\n",
            "1733,6176\n",
            "1734,6685\n",
            "1735,8472\n",
            "1736,5915\n",
            "1737,7728\n",
            "1738,4777\n",
            "1739,8797\n",
            "1740,5375\n",
            "1741,6441\n",
            "1742,8860\n",
            "1743,8941\n",
            "1744,4195\n",
            "1745,5158\n",
            "1746,6691\n",
            "1747,4827\n",
            "1748,8197\n",
            "1749,6739\n",
            "1750,6969\n",
            "1751,6606\n",
            "1752,5224\n",
            "1753,8143\n",
            "1754,6542\n",
            "1755,7085\n",
            "1756,7965\n",
            "1757,8567\n",
            "1758,4334\n",
            "1759,6226\n",
            "1760,4580\n",
            "1761,6800\n",
            "1762,7984\n",
            "1763,8886\n",
            "1764,7681\n",
            "1765,8169\n",
            "1766,7207\n",
            "1767,7394\n",
            "1768,8957\n",
            "1769,6975\n",
            "1770,8138\n",
            "1771,6738\n",
            "1772,5925\n",
            "1773,8367\n",
            "1774,5180\n",
            "1775,8723\n",
            "1776,8203\n",
            "1777,7610\n",
            "1778,7822\n",
            "1779,5088\n",
            "1780,4145\n",
            "1781,7326\n",
            "1782,4301\n",
            "1783,7959\n",
            "1784,7131\n",
            "1785,6643\n",
            "1786,8906\n",
            "1787,7138\n",
            "1788,6821\n",
            "1789,6190\n",
            "1790,4274\n",
            "1791,5391\n",
            "1792,5312\n",
            "1793,7920\n",
            "1794,5143\n",
            "1795,6619\n",
            "1796,6294\n",
            "1797,8440\n",
            "1798,5885\n",
            "1799,4076\n",
            "1800,4754\n",
            "1801,8244\n",
            "1802,7983\n",
            "1803,7718\n",
            "1804,7538\n",
            "1805,6759\n",
            "1806,5023\n",
            "1807,5125\n",
            "1808,8114\n",
            "1809,7682\n",
            "1810,6567\n",
            "1811,5666\n",
            "1812,4388\n",
            "1813,6633\n",
            "1814,8069\n",
            "1815,7053\n",
            "1816,6254\n",
            "1817,6575\n",
            "1818,6777\n",
            "1819,4547\n",
            "1820,6360\n",
            "1821,7373\n",
            "1822,7348\n",
            "1823,8864\n",
            "1824,8636\n",
            "1825,6534\n",
            "1826,6238\n",
            "1827,7464\n",
            "1828,5883\n",
            "1829,5178\n",
            "1830,7532\n",
            "1831,5327\n",
            "1832,7464\n",
            "1833,4406\n",
            "1834,5452\n",
            "1835,7784\n",
            "1836,8822\n",
            "1837,4442\n",
            "1838,8558\n",
            "1839,6644\n",
            "1840,5391\n",
            "1841,6122\n",
            "1842,4733\n",
            "1843,5409\n",
            "1844,7452\n",
            "1845,8571\n",
            "1846,5150\n",
            "1847,6828\n",
            "1848,6380\n",
            "1849,7353\n",
            "1850,7158\n",
            "1851,7911\n",
            "1852,5613\n",
            "1853,4812\n",
            "1854,6868\n",
            "1855,7461\n",
            "1856,7049\n",
            "1857,6591\n",
            "1858,8750\n",
            "1859,4187\n",
            "1860,7623\n",
            "1861,6808\n",
            "1862,6024\n",
            "1863,4485\n",
            "1864,6011\n",
            "1865,5639\n",
            "1866,7492\n",
            "1867,4805\n",
            "1868,6607\n",
            "1869,5151\n",
            "1870,5527\n",
            "1871,5059\n",
            "1872,4735\n",
            "1873,5865\n",
            "1874,6937\n",
            "1875,5033\n",
            "1876,6001\n",
            "1877,7716\n",
            "1878,7052\n",
            "1879,5258\n",
            "1880,8260\n",
            "1881,5437\n",
            "1882,4386\n",
            "1883,6611\n",
            "1884,4071\n",
            "1885,4737\n",
            "1886,8499\n",
            "1887,8966\n",
            "1888,6544\n",
            "1889,7213\n",
            "1890,4566\n",
            "1891,4925\n",
            "1892,5934\n",
            "1893,7081\n",
            "1894,6553\n",
            "1895,4327\n",
            "1896,8882\n",
            "1897,8722\n",
            "1898,5198\n",
            "1899,7373\n",
            "1900,6208\n",
            "1901,5127\n",
            "1902,5751\n",
            "1903,5230\n",
            "1904,5487\n",
            "1905,8356\n",
            "1906,6843\n",
            "1907,8313\n",
            "1908,4651\n",
            "1909,5955\n",
            "1910,6364\n",
            "1911,6620\n",
            "1912,8007\n",
            "1913,5413\n",
            "1914,7953\n",
            "1915,4796\n",
            "1916,5078\n",
            "1917,5626\n",
            "1918,8735\n",
            "1919,6377\n",
            "1920,7162\n",
            "1921,5950\n",
            "1922,8464\n",
            "1923,4640\n",
            "1924,7984\n",
            "1925,4665\n",
            "1926,5393\n",
            "1927,4694\n",
            "1928,7817\n",
            "1929,4751\n",
            "1930,4617\n",
            "1931,8694\n",
            "1932,5725\n",
            "1933,5081\n",
            "1934,7913\n",
            "1935,8213\n",
            "1936,5471\n",
            "1937,7808\n",
            "1938,5711\n",
            "1939,6782\n",
            "1940,7310\n",
            "1941,5286\n",
            "1942,6043\n",
            "1943,4161\n",
            "1944,5881\n",
            "1945,6846\n",
            "1946,7353\n",
            "1947,8212\n",
            "1948,7050\n",
            "1949,5150\n",
            "1950,5143\n",
            "1951,5075\n",
            "1952,7056\n",
            "1953,8493\n",
            "1954,8491\n",
            "1955,7945\n",
            "1956,5040\n",
            "1957,4716\n",
            "1958,8817\n",
            "1959,8557\n",
            "1960,7915\n",
            "1961,5024\n",
            "1962,6389\n",
            "1963,8315\n",
            "1964,5494\n",
            "1965,6248\n",
            "1966,4643\n",
            "1967,5944\n",
            "1968,6440\n",
            "1969,5919\n",
            "1970,7441\n",
            "1971,8341\n",
            "1972,7592\n",
            "1973,8482\n",
            "1974,7579\n",
            "1975,5108\n",
            "1976,4204\n",
            "1977,5542\n",
            "1978,4921\n",
            "1979,8651\n",
            "1980,8472\n",
            "1981,6077\n",
            "1982,5074\n",
            "1983,5610\n",
            "1984,5113\n",
            "1985,8355\n",
            "1986,7032\n",
            "1987,4737\n",
            "1988,4619\n",
            "1989,7500\n",
            "1990,4815\n",
            "1991,5655\n",
            "1992,6815\n",
            "1993,6854\n",
            "1994,7567\n",
            "1995,5132\n",
            "1996,6212\n",
            "1997,8096\n",
            "1998,6934\n",
            "1999,6531\n",
            "2000,4272\n",
            "2001,6086\n",
            "2002,6152\n",
            "2003,5774\n",
            "2004,4220\n",
            "2005,7845\n",
            "2006,6442\n",
            "2007,7140\n",
            "2008,6387\n",
            "2009,6287\n",
            "2010,8526\n",
            "2011,6539\n",
            "2012,6961\n",
            "2013,5552\n",
            "2014,5052\n",
            "2015,5767\n",
            "2016,8590\n",
            "2017,6110\n",
            "2018,8262\n",
            "2019,5117\n",
            "2020,6268\n",
            "2021,7241\n",
            "2022,5452\n",
            "2023,7338\n",
            "2024,6535\n",
            "2025,4537\n",
            "2026,4928\n",
            "2027,4480\n",
            "2028,6800\n",
            "2029,5320\n",
            "2030,5099\n",
            "2031,4623\n",
            "2032,7084\n",
            "2033,7369\n",
            "2034,6699\n",
            "2035,6546\n",
            "2036,8345\n",
            "2037,8165\n",
            "2038,8890\n",
            "2039,5100\n",
            "2040,8088\n",
            "2041,6295\n",
            "2042,7931\n",
            "2043,7157\n",
            "2044,6768\n",
            "2045,6438\n",
            "2046,7838\n",
            "2047,8771\n",
            "2048,8323\n",
            "2049,8625\n",
            "2050,7564\n",
            "2051,5814\n",
            "2052,6260\n",
            "2053,5993\n",
            "2054,5628\n",
            "2055,4837\n",
            "2056,8795\n",
            "2057,4070\n",
            "2058,4903\n",
            "2059,7828\n",
            "2060,6610\n",
            "2061,5704\n",
            "2062,8263\n",
            "2063,8681\n",
            "2064,6210\n",
            "2065,6007\n",
            "2066,5478\n",
            "2067,4276\n",
            "2068,7264\n",
            "2069,7191\n",
            "2070,5000\n",
            "2071,6958\n",
            "2072,6209\n",
            "2073,4971\n",
            "2074,6282\n",
            "2075,6636\n",
            "2076,6931\n",
            "2077,6376\n",
            "2078,5019\n",
            "2079,8001\n",
            "2080,6242\n",
            "2081,8626\n",
            "2082,4596\n",
            "2083,4219\n",
            "2084,5418\n",
            "2085,7302\n",
            "2086,4548\n",
            "2087,4802\n",
            "2088,8854\n",
            "2089,5539\n",
            "2090,7668\n",
            "2091,6298\n",
            "2092,6309\n",
            "2093,4592\n",
            "2094,5322\n",
            "2095,7331\n",
            "2096,4987\n",
            "2097,5267\n",
            "2098,5849\n",
            "2099,7993\n",
            "2100,6836\n",
            "2101,7175\n",
            "2102,7477\n",
            "2103,7014\n",
            "2104,6903\n",
            "2105,8001\n",
            "2106,7568\n",
            "2107,8331\n",
            "2108,7020\n",
            "2109,5611\n",
            "2110,4187\n",
            "2111,7038\n",
            "2112,4088\n",
            "2113,5456\n",
            "2114,6968\n",
            "2115,8816\n",
            "2116,7707\n",
            "2117,6888\n",
            "2118,7848\n",
            "2119,6859\n",
            "2120,4453\n",
            "2121,8412\n",
            "2122,6554\n",
            "2123,6877\n",
            "2124,8016\n",
            "2125,6761\n",
            "2126,8096\n",
            "2127,4791\n",
            "2128,4380\n",
            "2129,6776\n",
            "2130,4547\n",
            "2131,7274\n",
            "2132,7363\n",
            "2133,7849\n",
            "2134,4179\n",
            "2135,5060\n",
            "2136,7900\n",
            "2137,8136\n",
            "2138,8430\n",
            "2139,7524\n",
            "2140,5747\n",
            "2141,5892\n",
            "2142,7890\n",
            "2143,5111\n",
            "2144,6176\n",
            "2145,7897\n",
            "2146,6816\n",
            "2147,5816\n",
            "2148,6716\n",
            "2149,7303\n",
            "2150,7469\n",
            "2151,8562\n",
            "2152,5986\n",
            "2153,7293\n",
            "2154,8803\n",
            "2155,5881\n",
            "2156,6937\n",
            "2157,4790\n",
            "2158,4805\n",
            "2159,8207\n",
            "2160,5387\n",
            "2161,7496\n",
            "2162,5148\n",
            "2163,6732\n",
            "2164,5483\n",
            "2165,5676\n",
            "2166,8105\n",
            "2167,5056\n",
            "2168,8882\n",
            "2169,8133\n",
            "2170,6769\n",
            "2171,6833\n",
            "2172,7333\n",
            "2173,5961\n",
            "2174,8284\n",
            "2175,8773\n",
            "2176,4867\n",
            "2177,7523\n",
            "2178,4325\n",
            "2179,8744\n",
            "2180,7945\n",
            "2181,7544\n",
            "2182,6836\n",
            "2183,4590\n",
            "2184,5843\n",
            "2185,8927\n",
            "2186,6711\n",
            "2187,6923\n",
            "2188,7036\n",
            "2189,8522\n",
            "2190,7890\n",
            "2191,8384\n",
            "2192,5080\n",
            "2193,6262\n",
            "2194,5579\n",
            "2195,5777\n",
            "2196,4810\n",
            "2197,6066\n",
            "2198,5844\n",
            "2199,6818\n",
            "2200,8488\n",
            "2201,8478\n",
            "2202,5698\n",
            "2203,5718\n",
            "2204,6484\n",
            "2205,6654\n",
            "2206,6339\n",
            "2207,8462\n",
            "2208,5624\n",
            "2209,6791\n",
            "2210,6097\n",
            "2211,8670\n",
            "2212,7457\n",
            "2213,4858\n",
            "2214,5097\n",
            "2215,7197\n",
            "2216,7333\n",
            "2217,8582\n",
            "2218,4254\n",
            "2219,6632\n",
            "2220,4679\n",
            "2221,6301\n",
            "2222,7205\n",
            "2223,4318\n",
            "2224,7850\n",
            "2225,7019\n",
            "2226,5984\n",
            "2227,7447\n",
            "2228,6696\n",
            "2229,4601\n",
            "2230,6120\n",
            "2231,5749\n",
            "2232,8686\n",
            "2233,6873\n",
            "2234,7258\n",
            "2235,6714\n",
            "2236,6026\n",
            "2237,4131\n",
            "2238,7207\n",
            "2239,4597\n",
            "2240,6357\n",
            "2241,6705\n",
            "2242,4655\n",
            "2243,8545\n",
            "2244,8753\n",
            "2245,5388\n",
            "2246,5811\n",
            "2247,4642\n",
            "2248,5540\n",
            "2249,5901\n",
            "2250,7781\n",
            "2251,6357\n",
            "2252,6979\n",
            "2253,4852\n",
            "2254,5917\n",
            "2255,6578\n",
            "2256,7938\n",
            "2257,8256\n",
            "2258,7471\n",
            "2259,4402\n",
            "2260,6812\n",
            "2261,4630\n",
            "2262,5385\n",
            "2263,4987\n",
            "2264,7943\n",
            "2265,7642\n",
            "2266,7571\n",
            "2267,8483\n",
            "2268,5949\n",
            "2269,4538\n",
            "2270,5128\n",
            "2271,4451\n",
            "2272,5709\n",
            "2273,6613\n",
            "2274,6394\n",
            "2275,5617\n",
            "2276,6998\n",
            "2277,8166\n",
            "2278,5594\n",
            "2279,4488\n",
            "2280,7728\n",
            "2281,7259\n",
            "2282,4341\n",
            "2283,5726\n",
            "2284,5914\n",
            "2285,5493\n",
            "2286,5428\n",
            "2287,5416\n",
            "2288,7795\n",
            "2289,6301\n",
            "2290,4923\n",
            "2291,4555\n",
            "2292,4166\n",
            "2293,8468\n",
            "2294,7649\n",
            "2295,4515\n",
            "2296,4195\n",
            "2297,6226\n",
            "2298,6016\n",
            "2299,6870\n",
            "2300,7157\n",
            "2301,5688\n",
            "2302,8798\n",
            "2303,7960\n",
            "2304,6092\n",
            "2305,8406\n",
            "2306,8317\n",
            "2307,6824\n",
            "2308,8367\n",
            "2309,7111\n",
            "2310,8899\n",
            "2311,6065\n",
            "2312,6686\n",
            "2313,7952\n",
            "2314,8366\n",
            "2315,4172\n",
            "2316,5090\n",
            "2317,6817\n",
            "2318,8261\n",
            "2319,6951\n",
            "2320,6880\n",
            "2321,5048\n",
            "2322,6613\n",
            "2323,8142\n",
            "2324,5876\n",
            "2325,4488\n",
            "2326,8638\n",
            "2327,5381\n",
            "2328,4659\n",
            "2329,6103\n",
            "2330,8092\n",
            "2331,4530\n",
            "2332,4183\n",
            "2333,4560\n",
            "2334,5915\n",
            "2335,7528\n",
            "2336,5669\n",
            "2337,5712\n",
            "2338,6579\n",
            "2339,8484\n",
            "2340,5289\n",
            "2341,7768\n",
            "2342,7248\n",
            "2343,6381\n",
            "2344,6395\n",
            "2345,7140\n",
            "2346,5483\n",
            "2347,7836\n",
            "2348,7174\n",
            "2349,7362\n",
            "2350,8126\n",
            "2351,6644\n",
            "2352,8769\n",
            "2353,8841\n",
            "2354,7980\n",
            "2355,7277\n",
            "2356,4284\n",
            "2357,7587\n",
            "2358,5980\n",
            "2359,6326\n",
            "2360,7346\n",
            "2361,7889\n",
            "2362,7055\n",
            "2363,6254\n",
            "2364,4684\n",
            "2365,5721\n",
            "2366,4568\n",
            "2367,5103\n",
            "2368,4319\n",
            "2369,6600\n",
            "2370,7119\n",
            "2371,6500\n",
            "2372,6102\n",
            "2373,8790\n",
            "2374,4888\n",
            "2375,8050\n",
            "2376,8186\n",
            "2377,6241\n",
            "2378,6463\n",
            "2379,4833\n",
            "2380,4576\n",
            "2381,4362\n",
            "2382,7840\n",
            "2383,4592\n",
            "2384,8657\n",
            "2385,8254\n",
            "2386,7267\n",
            "2387,7718\n",
            "2388,7448\n",
            "2389,8553\n",
            "2390,8158\n",
            "2391,5301\n",
            "2392,7216\n",
            "2393,8509\n",
            "2394,4809\n",
            "2395,8700\n",
            "2396,6906\n",
            "2397,7982\n",
            "2398,5227\n",
            "2399,8043\n",
            "2400,4735\n",
            "2401,4705\n",
            "2402,5132\n",
            "2403,7190\n",
            "2404,5858\n",
            "2405,7194\n",
            "2406,7689\n",
            "2407,4586\n",
            "2408,8103\n",
            "2409,8215\n",
            "2410,6165\n",
            "2411,5757\n",
            "2412,5588\n",
            "2413,6469\n",
            "2414,6218\n",
            "2415,7769\n",
            "2416,8876\n",
            "2417,8389\n",
            "2418,6795\n",
            "2419,7728\n",
            "2420,6446\n",
            "2421,4878\n",
            "2422,8902\n",
            "2423,4950\n",
            "2424,4286\n",
            "2425,4839\n",
            "2426,7848\n",
            "2427,5367\n",
            "2428,6637\n",
            "2429,5534\n",
            "2430,6002\n",
            "2431,4870\n",
            "2432,4596\n",
            "2433,4817\n",
            "2434,8821\n",
            "2435,4134\n",
            "2436,6383\n",
            "2437,5314\n",
            "2438,8025\n",
            "2439,5980\n",
            "2440,4496\n",
            "2441,8237\n",
            "2442,4278\n",
            "2443,6573\n",
            "2444,5452\n",
            "2445,7304\n",
            "2446,5236\n",
            "2447,7452\n",
            "2448,7989\n",
            "2449,4844\n",
            "2450,4225\n",
            "2451,5438\n",
            "2452,5869\n",
            "2453,6640\n",
            "2454,5238\n",
            "2455,8845\n",
            "2456,4755\n",
            "2457,5148\n",
            "2458,5871\n",
            "2459,8685\n",
            "2460,6369\n",
            "2461,7238\n",
            "2462,5237\n",
            "2463,8644\n",
            "2464,7740\n",
            "2465,5628\n",
            "2466,7508\n",
            "2467,6765\n",
            "2468,5973\n",
            "2469,7861\n",
            "2470,4748\n",
            "2471,8003\n",
            "2472,4885\n",
            "2473,4205\n",
            "2474,7064\n",
            "2475,8912\n",
            "2476,4336\n",
            "2477,8826\n",
            "2478,4512\n",
            "2479,4581\n",
            "2480,8661\n",
            "2481,5064\n",
            "2482,5271\n",
            "2483,6056\n",
            "2484,4845\n",
            "2485,8919\n",
            "2486,8396\n",
            "2487,6252\n",
            "2488,5133\n",
            "2489,7694\n",
            "2490,4916\n",
            "2491,5475\n",
            "2492,5453\n",
            "2493,7929\n",
            "2494,7416\n",
            "2495,5624\n",
            "2496,5258\n",
            "2497,5345\n",
            "2498,8914\n",
            "2499,7430\n",
            "2500,7081\n",
            "2501,6670\n",
            "2502,7708\n",
            "2503,4480\n",
            "2504,5293\n",
            "2505,7632\n",
            "2506,6981\n",
            "2507,7960\n",
            "2508,7246\n",
            "2509,7227\n",
            "2510,8238\n",
            "2511,6035\n",
            "2512,7894\n",
            "2513,7599\n",
            "2514,5053\n",
            "2515,5232\n",
            "2516,7030\n",
            "2517,6192\n",
            "2518,4825\n",
            "2519,5098\n",
            "2520,5859\n",
            "2521,7018\n",
            "2522,6914\n",
            "2523,4286\n",
            "2524,5835\n",
            "2525,8385\n",
            "2526,5569\n",
            "2527,6664\n",
            "2528,7999\n",
            "2529,7112\n",
            "2530,5114\n",
            "2531,6040\n",
            "2532,5060\n",
            "2533,5581\n",
            "2534,6751\n",
            "2535,8115\n",
            "2536,5714\n",
            "2537,4451\n",
            "2538,4716\n",
            "2539,8338\n",
            "2540,8031\n",
            "2541,7467\n",
            "2542,6269\n",
            "2543,7347\n",
            "2544,4746\n",
            "2545,5945\n",
            "2546,6198\n",
            "2547,6406\n",
            "2548,7335\n",
            "2549,5655\n",
            "2550,8697\n",
            "2551,6892\n",
            "2552,7529\n",
            "2553,7067\n",
            "2554,4228\n",
            "2555,7070\n",
            "2556,4720\n",
            "2557,7801\n",
            "2558,7201\n",
            "2559,7656\n",
            "2560,8194\n",
            "2561,7786\n",
            "2562,7648\n",
            "2563,4161\n",
            "2564,5487\n",
            "2565,6718\n",
            "2566,8634\n",
            "2567,4460\n",
            "2568,8252\n",
            "2569,5633\n",
            "2570,5850\n",
            "2571,4542\n",
            "2572,7403\n",
            "2573,6847\n",
            "2574,4924\n",
            "2575,7605\n",
            "2576,7875\n",
            "2577,8026\n",
            "2578,7996\n",
            "2579,5819\n",
            "2580,6539\n",
            "2581,7796\n",
            "2582,6140\n",
            "2583,4910\n",
            "2584,7894\n",
            "2585,5499\n",
            "2586,6424\n",
            "2587,4075\n",
            "2588,7521\n",
            "2589,7574\n",
            "2590,8819\n",
            "2591,5616\n",
            "2592,6455\n",
            "2593,5140\n",
            "2594,8548\n",
            "2595,4719\n",
            "2596,7377\n",
            "2597,8948\n",
            "2598,8203\n",
            "2599,5799\n",
            "2600,5513\n",
            "2601,5864\n",
            "2602,5145\n",
            "2603,8456\n",
            "2604,4167\n",
            "2605,5824\n",
            "2606,8934\n",
            "2607,5791\n",
            "2608,6250\n",
            "2609,4939\n",
            "2610,4828\n",
            "2611,4546\n",
            "2612,7270\n",
            "2613,6698\n",
            "2614,6342\n",
            "2615,5251\n",
            "2616,4533\n",
            "2617,6644\n",
            "2618,7349\n",
            "2619,4537\n",
            "2620,5077\n",
            "2621,7704\n",
            "2622,5624\n",
            "2623,8846\n",
            "2624,7500\n",
            "2625,8652\n",
            "2626,6816\n",
            "2627,5914\n",
            "2628,8755\n",
            "2629,4515\n",
            "2630,8652\n",
            "2631,5879\n",
            "2632,7436\n",
            "2633,8969\n",
            "2634,7163\n",
            "2635,4774\n",
            "2636,7010\n",
            "2637,6082\n",
            "2638,5554\n",
            "2639,6578\n",
            "2640,5068\n",
            "2641,4917\n",
            "2642,8887\n",
            "2643,6487\n",
            "2644,6081\n",
            "2645,6845\n",
            "2646,7222\n",
            "2647,6206\n",
            "2648,4887\n",
            "2649,4254\n",
            "2650,8403\n",
            "2651,4309\n",
            "2652,5646\n",
            "2653,6268\n",
            "2654,6723\n",
            "2655,8886\n",
            "2656,4884\n",
            "2657,6363\n",
            "2658,5814\n",
            "2659,8299\n",
            "2660,5090\n",
            "2661,4644\n",
            "2662,8963\n",
            "2663,6244\n",
            "2664,6288\n",
            "2665,6621\n",
            "2666,4752\n",
            "2667,8767\n",
            "2668,8587\n",
            "2669,7141\n",
            "2670,5468\n",
            "2671,4288\n",
            "2672,6645\n",
            "2673,5870\n",
            "2674,6740\n",
            "2675,7527\n",
            "2676,8183\n",
            "2677,5581\n",
            "2678,4549\n",
            "2679,4819\n",
            "2680,7243\n",
            "2681,6842\n",
            "2682,6279\n",
            "2683,7183\n",
            "2684,7300\n",
            "2685,7157\n",
            "2686,7852\n",
            "2687,4605\n",
            "2688,7221\n",
            "2689,4300\n",
            "2690,8840\n",
            "2691,6567\n",
            "2692,7883\n",
            "2693,4812\n",
            "2694,8797\n",
            "2695,8761\n",
            "2696,5727\n",
            "2697,6205\n",
            "2698,4464\n",
            "2699,5230\n",
            "2700,7181\n",
            "2701,6828\n",
            "2702,5563\n",
            "2703,8684\n",
            "2704,6680\n",
            "2705,8420\n",
            "2706,7392\n",
            "2707,6978\n",
            "2708,5529\n",
            "2709,6757\n",
            "2710,7449\n",
            "2711,6320\n",
            "2712,5711\n",
            "2713,5579\n",
            "2714,8555\n",
            "2715,7177\n",
            "2716,8671\n",
            "2717,6525\n",
            "2718,7292\n",
            "2719,4084\n",
            "2720,4533\n",
            "2721,6767\n",
            "2722,4681\n",
            "2723,7455\n",
            "2724,6932\n",
            "2725,8553\n",
            "2726,7687\n",
            "2727,8243\n",
            "2728,8601\n",
            "2729,5433\n",
            "2730,6863\n",
            "2731,6151\n",
            "2732,6083\n",
            "2733,7194\n",
            "2734,6282\n",
            "2735,7678\n",
            "2736,5503\n",
            "2737,4424\n",
            "2738,8482\n",
            "2739,6472\n",
            "2740,4615\n",
            "2741,4153\n",
            "2742,8449\n",
            "2743,7743\n",
            "2744,7653\n",
            "2745,5846\n",
            "2746,8948\n",
            "2747,6624\n",
            "2748,7496\n",
            "2749,6255\n",
            "2750,7857\n",
            "2751,4932\n",
            "2752,7167\n",
            "2753,6196\n",
            "2754,4652\n",
            "2755,4368\n",
            "2756,8513\n",
            "2757,7025\n",
            "2758,8722\n",
            "2759,4913\n",
            "2760,7891\n",
            "2761,7235\n",
            "2762,8201\n",
            "2763,4558\n",
            "2764,8241\n",
            "2765,7330\n",
            "2766,7982\n",
            "2767,4893\n",
            "2768,7628\n",
            "2769,8534\n",
            "2770,4202\n",
            "2771,8498\n",
            "2772,8851\n",
            "2773,4883\n",
            "2774,6036\n",
            "2775,4572\n",
            "2776,6032\n",
            "2777,4902\n",
            "2778,5074\n",
            "2779,5643\n",
            "2780,7371\n",
            "2781,4586\n",
            "2782,8480\n",
            "2783,8901\n",
            "2784,6862\n",
            "2785,8391\n",
            "2786,6308\n",
            "2787,8222\n",
            "2788,4965\n",
            "2789,7083\n",
            "2790,5167\n",
            "2791,5063\n",
            "2792,6530\n",
            "2793,6989\n",
            "2794,5602\n",
            "2795,4353\n",
            "2796,4472\n",
            "2797,4647\n",
            "2798,7256\n",
            "2799,8592\n",
            "2800,4186\n",
            "2801,4292\n",
            "2802,8022\n",
            "2803,7971\n",
            "2804,8456\n",
            "2805,6741\n",
            "2806,5858\n",
            "2807,7475\n",
            "2808,5005\n",
            "2809,5852\n",
            "2810,7120\n",
            "2811,4751\n",
            "2812,8873\n",
            "2813,5231\n",
            "2814,8582\n",
            "2815,5932\n",
            "2816,5064\n",
            "2817,8749\n",
            "2818,7357\n",
            "2819,8690\n",
            "2820,8085\n",
            "2821,8926\n",
            "2822,7965\n",
            "2823,7307\n",
            "2824,7729\n",
            "2825,8723\n",
            "2826,8626\n",
            "2827,4693\n",
            "2828,7926\n",
            "2829,5969\n",
            "2830,4849\n",
            "2831,4478\n",
            "2832,4855\n",
            "2833,4454\n",
            "2834,6330\n",
            "2835,5218\n",
            "2836,4523\n",
            "2837,5196\n",
            "2838,8360\n",
            "2839,6206\n",
            "2840,8184\n",
            "2841,7593\n",
            "2842,6847\n",
            "2843,6256\n",
            "2844,5040\n",
            "2845,5427\n",
            "2846,4694\n",
            "2847,6203\n",
            "2848,8860\n",
            "2849,7442\n",
            "2850,8262\n",
            "2851,8848\n",
            "2852,7038\n",
            "2853,8864\n",
            "2854,5387\n",
            "2855,6127\n",
            "2856,4438\n",
            "2857,7533\n",
            "2858,5445\n",
            "2859,7260\n",
            "2860,6188\n",
            "2861,6095\n",
            "2862,7321\n",
            "2863,8096\n",
            "2864,4306\n",
            "2865,6044\n",
            "2866,4469\n",
            "2867,4868\n",
            "2868,6469\n",
            "2869,7471\n",
            "2870,6036\n",
            "2871,6274\n",
            "2872,5486\n",
            "2873,6634\n",
            "2874,6531\n",
            "2875,8586\n",
            "2876,5662\n",
            "2877,7242\n",
            "2878,6197\n",
            "2879,5021\n",
            "2880,8315\n",
            "2881,7096\n",
            "2882,4473\n",
            "2883,5884\n",
            "2884,5040\n",
            "2885,6357\n",
            "2886,5118\n",
            "2887,6033\n",
            "2888,4790\n",
            "2889,7459\n",
            "2890,6788\n",
            "2891,7972\n",
            "2892,6972\n",
            "2893,4775\n",
            "2894,4615\n",
            "2895,4088\n",
            "2896,4668\n",
            "2897,7415\n",
            "2898,7328\n",
            "2899,5971\n",
            "2900,8835\n",
            "2901,5740\n",
            "2902,7426\n",
            "2903,8371\n",
            "2904,6645\n",
            "2905,5866\n",
            "2906,8601\n",
            "2907,5222\n",
            "2908,6273\n",
            "2909,5993\n",
            "2910,4233\n",
            "2911,5355\n",
            "2912,4965\n",
            "2913,4499\n",
            "2914,4429\n",
            "2915,4316\n",
            "2916,6741\n",
            "2917,6651\n",
            "2918,6315\n",
            "2919,7276\n",
            "2920,4958\n",
            "2921,5791\n",
            "2922,8101\n",
            "2923,4925\n",
            "2924,8583\n",
            "2925,7361\n",
            "2926,5654\n",
            "2927,7200\n",
            "2928,5099\n",
            "2929,8859\n",
            "2930,4628\n",
            "2931,6966\n",
            "2932,5814\n",
            "2933,8685\n",
            "2934,8297\n",
            "2935,5496\n",
            "2936,4495\n",
            "2937,5704\n",
            "2938,5600\n",
            "2939,4792\n",
            "2940,5929\n",
            "2941,8804\n",
            "2942,5066\n",
            "2943,7251\n",
            "2944,4092\n",
            "2945,7291\n",
            "2946,4897\n",
            "2947,5350\n",
            "2948,6995\n",
            "2949,6895\n",
            "2950,7701\n",
            "2951,5580\n",
            "2952,4723\n",
            "2953,5639\n",
            "2954,8181\n",
            "2955,5476\n",
            "2956,5920\n",
            "2957,8132\n",
            "2958,4684\n",
            "2959,6907\n",
            "2960,4726\n",
            "2961,7225\n",
            "2962,6169\n",
            "2963,5872\n",
            "2964,7309\n",
            "2965,5817\n",
            "2966,4938\n",
            "2967,5666\n",
            "2968,6932\n",
            "2969,8050\n",
            "2970,5690\n",
            "2971,8854\n",
            "2972,7929\n",
            "2973,6947\n",
            "2974,5863\n",
            "2975,8643\n",
            "2976,7327\n",
            "2977,7523\n",
            "2978,5776\n",
            "2979,5629\n",
            "2980,8650\n",
            "2981,6321\n",
            "2982,5365\n",
            "2983,6671\n",
            "2984,5788\n",
            "2985,6241\n",
            "2986,5275\n",
            "2987,5598\n",
            "2988,7106\n",
            "2989,4123\n",
            "2990,4343\n",
            "2991,4192\n",
            "2992,8614\n",
            "2993,6869\n",
            "2994,8278\n",
            "2995,7236\n",
            "2996,6388\n",
            "2997,8467\n",
            "2998,4151\n",
            "2999,5499\n",
            "3000,6991\n",
            "3001,6489\n",
            "3002,5025\n",
            "3003,7895\n",
            "3004,7802\n",
            "3005,4728\n",
            "3006,5258\n",
            "3007,4906\n",
            "3008,8332\n",
            "3009,6815\n",
            "3010,5284\n",
            "3011,6886\n",
            "3012,4190\n",
            "3013,5589\n",
            "3014,5867\n",
            "3015,5675\n",
            "3016,4485\n",
            "3017,7267\n",
            "3018,7139\n",
            "3019,5494\n",
            "3020,5143\n",
            "3021,7206\n",
            "3022,5542\n",
            "3023,5033\n",
            "3024,4687\n",
            "3025,7133\n",
            "3026,8704\n",
            "3027,5606\n",
            "3028,8173\n",
            "3029,4990\n",
            "3030,6203\n",
            "3031,6166\n",
            "3032,5209\n",
            "3033,8808\n",
            "3034,6784\n",
            "3035,5311\n",
            "3036,7536\n",
            "3037,5825\n",
            "3038,6488\n",
            "3039,8130\n",
            "3040,5032\n",
            "3041,4921\n",
            "3042,7408\n",
            "3043,7660\n",
            "3044,8333\n",
            "3045,8266\n",
            "3046,6377\n",
            "3047,8514\n",
            "3048,5648\n",
            "3049,8112\n",
            "3050,8623\n",
            "3051,5361\n",
            "3052,6942\n",
            "3053,8305\n",
            "3054,6781\n",
            "3055,8027\n",
            "3056,7028\n",
            "3057,4744\n",
            "3058,5639\n",
            "3059,4346\n",
            "3060,4315\n",
            "3061,4777\n",
            "3062,6603\n",
            "3063,6149\n",
            "3064,6400\n",
            "3065,4298\n",
            "3066,4110\n",
            "3067,5224\n",
            "3068,7922\n",
            "3069,6673\n",
            "3070,5775\n",
            "3071,7369\n",
            "3072,5984\n",
            "3073,5772\n",
            "3074,6413\n",
            "3075,4556\n",
            "3076,8165\n",
            "3077,4092\n",
            "3078,6157\n",
            "3079,7644\n",
            "3080,7780\n",
            "3081,4676\n",
            "3082,7716\n",
            "3083,8060\n",
            "3084,4161\n",
            "3085,5291\n",
            "3086,5417\n",
            "3087,8446\n",
            "3088,7557\n",
            "3089,8618\n",
            "3090,7432\n",
            "3091,6095\n",
            "3092,4321\n",
            "3093,8086\n",
            "3094,7422\n",
            "3095,7780\n",
            "3096,4379\n",
            "3097,5792\n",
            "3098,5071\n",
            "3099,6824\n",
            "3100,4295\n",
            "3101,6389\n",
            "3102,8316\n",
            "3103,7822\n",
            "3104,6771\n",
            "3105,6395\n",
            "3106,4628\n",
            "3107,5007\n",
            "3108,4446\n",
            "3109,6247\n",
            "3110,5479\n",
            "3111,7001\n",
            "3112,5057\n",
            "3113,7434\n",
            "3114,4358\n",
            "3115,6938\n",
            "3116,7622\n",
            "3117,6362\n",
            "3118,7829\n",
            "3119,8323\n",
            "3120,5381\n",
            "3121,8847\n",
            "3122,7866\n",
            "3123,5206\n",
            "3124,5356\n",
            "3125,7386\n",
            "3126,7016\n",
            "3127,4849\n",
            "3128,5402\n",
            "3129,4962\n",
            "3130,4253\n",
            "3131,4833\n",
            "3132,5279\n",
            "3133,5853\n",
            "3134,8128\n",
            "3135,5388\n",
            "3136,6729\n",
            "3137,6756\n",
            "3138,6985\n",
            "3139,8280\n",
            "3140,5127\n",
            "3141,5279\n",
            "3142,7730\n",
            "3143,5349\n",
            "3144,7594\n",
            "3145,4122\n",
            "3146,5813\n",
            "3147,6778\n",
            "3148,8490\n",
            "3149,6994\n",
            "3150,6077\n",
            "3151,4064\n",
            "3152,4246\n",
            "3153,6456\n",
            "3154,7133\n",
            "3155,8434\n",
            "3156,6696\n",
            "3157,6950\n",
            "3158,6753\n",
            "3159,6690\n",
            "3160,6091\n",
            "3161,8084\n",
            "3162,4215\n",
            "3163,6978\n",
            "3164,4949\n",
            "3165,6415\n",
            "3166,7322\n",
            "3167,5733\n",
            "3168,4904\n",
            "3169,6685\n",
            "3170,5386\n",
            "3171,8019\n",
            "3172,7433\n",
            "3173,4700\n",
            "3174,4241\n",
            "3175,8688\n",
            "3176,8530\n",
            "3177,6802\n",
            "3178,4128\n",
            "3179,5107\n",
            "3180,8340\n",
            "3181,5490\n",
            "3182,7940\n",
            "3183,5690\n",
            "3184,7680\n",
            "3185,7737\n",
            "3186,5228\n",
            "3187,4416\n",
            "3188,4088\n",
            "3189,5821\n",
            "3190,6566\n",
            "3191,8120\n",
            "3192,6356\n",
            "3193,8164\n",
            "3194,6150\n",
            "3195,8884\n",
            "3196,7381\n",
            "3197,4686\n",
            "3198,5790\n",
            "3199,7609\n",
            "3200,7623\n",
            "3201,5904\n",
            "3202,5008\n",
            "3203,6466\n",
            "3204,4780\n",
            "3205,7545\n",
            "3206,8502\n",
            "3207,5878\n",
            "3208,6142\n",
            "3209,6009\n",
            "3210,7387\n",
            "3211,8102\n",
            "3212,5168\n",
            "3213,5183\n",
            "3214,7770\n",
            "3215,6913\n",
            "3216,5970\n",
            "3217,4971\n",
            "3218,4772\n",
            "3219,6446\n",
            "3220,5477\n",
            "3221,6840\n",
            "3222,7153\n",
            "3223,6172\n",
            "3224,5118\n",
            "3225,4423\n",
            "3226,6491\n",
            "3227,6195\n",
            "3228,5365\n",
            "3229,6622\n",
            "3230,6202\n",
            "3231,7014\n",
            "3232,4270\n",
            "3233,7883\n",
            "3234,7492\n",
            "3235,6783\n",
            "3236,8210\n",
            "3237,6080\n",
            "3238,5202\n",
            "3239,7211\n",
            "3240,6883\n",
            "3241,8916\n",
            "3242,6318\n",
            "3243,4132\n",
            "3244,7403\n",
            "3245,4579\n",
            "3246,6871\n",
            "3247,5848\n",
            "3248,8291\n",
            "3249,7436\n",
            "3250,7485\n",
            "3251,4160\n",
            "3252,6437\n",
            "3253,8243\n",
            "3254,4160\n",
            "3255,5497\n",
            "3256,5020\n",
            "3257,8920\n",
            "3258,6912\n",
            "3259,6304\n",
            "3260,5380\n",
            "3261,5199\n",
            "3262,8154\n",
            "3263,6226\n",
            "3264,6584\n",
            "3265,6522\n",
            "3266,7918\n",
            "3267,8516\n",
            "3268,8302\n",
            "3269,5934\n",
            "3270,4195\n",
            "3271,8557\n",
            "3272,4473\n",
            "3273,7338\n",
            "3274,8756\n",
            "3275,6753\n",
            "3276,4832\n",
            "3277,5252\n",
            "3278,4952\n",
            "3279,4108\n",
            "3280,4753\n",
            "3281,8670\n",
            "3282,7722\n",
            "3283,4444\n",
            "3284,5945\n",
            "3285,7114\n",
            "3286,8950\n",
            "3287,4084\n",
            "3288,7733\n",
            "3289,4198\n",
            "3290,8173\n",
            "3291,4245\n",
            "3292,5101\n",
            "3293,6973\n",
            "3294,6141\n",
            "3295,7778\n",
            "3296,5219\n",
            "3297,7734\n",
            "3298,4971\n",
            "3299,6117\n",
            "3300,4484\n",
            "3301,5513\n",
            "3302,6160\n",
            "3303,6480\n",
            "3304,4957\n",
            "3305,6515\n",
            "3306,6517\n",
            "3307,8070\n",
            "3308,4326\n",
            "3309,7337\n",
            "3310,8790\n",
            "3311,6643\n",
            "3312,6878\n",
            "3313,5899\n",
            "3314,4790\n",
            "3315,8214\n",
            "3316,8054\n",
            "3317,7408\n",
            "3318,7711\n",
            "3319,8094\n",
            "3320,7905\n",
            "3321,8620\n",
            "3322,5235\n",
            "3323,8214\n",
            "3324,5331\n",
            "3325,8054\n",
            "3326,5632\n",
            "3327,7670\n",
            "3328,5817\n",
            "3329,5098\n",
            "3330,7270\n",
            "3331,4360\n",
            "3332,7406\n",
            "3333,8478\n",
            "3334,6928\n",
            "3335,4235\n",
            "3336,6259\n",
            "3337,8692\n",
            "3338,5349\n",
            "3339,5666\n",
            "3340,4227\n",
            "3341,5082\n",
            "3342,6926\n",
            "3343,5720\n",
            "3344,4205\n",
            "3345,6328\n",
            "3346,5687\n",
            "3347,8168\n",
            "3348,7833\n",
            "3349,4121\n",
            "3350,8407\n",
            "3351,7730\n",
            "3352,4157\n",
            "3353,7777\n",
            "3354,6913\n",
            "3355,8140\n",
            "3356,8067\n",
            "3357,6456\n",
            "3358,6587\n",
            "3359,4172\n",
            "3360,6762\n",
            "3361,6603\n",
            "3362,4187\n",
            "3363,5650\n",
            "3364,4435\n",
            "3365,4210\n",
            "3366,8381\n",
            "3367,5019\n",
            "3368,4192\n",
            "3369,4209\n",
            "3370,8237\n",
            "3371,8710\n",
            "3372,7243\n",
            "3373,7441\n",
            "3374,5193\n",
            "3375,6018\n",
            "3376,8366\n",
            "3377,4895\n",
            "3378,8332\n",
            "3379,7984\n",
            "3380,6665\n",
            "3381,6884\n",
            "3382,7321\n",
            "3383,5938\n",
            "3384,7023\n",
            "3385,7712\n",
            "3386,5847\n",
            "3387,8136\n",
            "3388,4657\n",
            "3389,6529\n",
            "3390,6531\n",
            "3391,4314\n",
            "3392,8585\n",
            "3393,6689\n",
            "3394,8187\n",
            "3395,4672\n",
            "3396,7871\n",
            "3397,5271\n",
            "3398,8657\n",
            "3399,8149\n",
            "3400,6846\n",
            "3401,8695\n",
            "3402,7431\n",
            "3403,4548\n",
            "3404,5081\n",
            "3405,6719\n",
            "3406,4203\n",
            "3407,6913\n",
            "3408,5643\n",
            "3409,5572\n",
            "3410,8834\n",
            "3411,6379\n",
            "3412,7003\n",
            "3413,7363\n",
            "3414,8863\n",
            "3415,7910\n",
            "3416,7429\n",
            "3417,8883\n",
            "3418,8940\n",
            "3419,7334\n",
            "3420,7975\n",
            "3421,4383\n",
            "3422,6126\n",
            "3423,4400\n",
            "3424,7778\n",
            "3425,5625\n",
            "3426,5696\n",
            "3427,7846\n",
            "3428,6157\n",
            "3429,5807\n",
            "3430,8724\n",
            "3431,8526\n",
            "3432,6421\n",
            "3433,4608\n",
            "3434,5704\n",
            "3435,6150\n",
            "3436,4621\n",
            "3437,8020\n",
            "3438,6203\n",
            "3439,5892\n",
            "3440,5850\n",
            "3441,4962\n",
            "3442,5403\n",
            "3443,4937\n",
            "3444,6767\n",
            "3445,6301\n",
            "3446,8272\n",
            "3447,8541\n",
            "3448,5060\n",
            "3449,5354\n",
            "3450,8493\n",
            "3451,6114\n",
            "3452,6726\n",
            "3453,4539\n",
            "3454,4826\n",
            "3455,5112\n",
            "3456,6964\n",
            "3457,8626\n",
            "3458,5768\n",
            "3459,4778\n",
            "3460,8514\n",
            "3461,5208\n",
            "3462,6391\n",
            "3463,5952\n",
            "3464,5163\n",
            "3465,4383\n",
            "3466,7544\n",
            "3467,5800\n",
            "3468,5472\n",
            "3469,4905\n",
            "3470,7775\n",
            "3471,5314\n",
            "3472,8119\n",
            "3473,4146\n",
            "3474,5365\n",
            "3475,6645\n",
            "3476,5658\n",
            "3477,5166\n",
            "3478,4250\n",
            "3479,7184\n",
            "3480,6128\n",
            "3481,6995\n",
            "3482,6398\n",
            "3483,6065\n",
            "3484,5784\n",
            "3485,4745\n",
            "3486,5501\n",
            "3487,4276\n",
            "3488,4251\n",
            "3489,8145\n",
            "3490,6014\n",
            "3491,5544\n",
            "3492,5841\n",
            "3493,8968\n",
            "3494,4596\n",
            "3495,8950\n",
            "3496,5731\n",
            "3497,6625\n",
            "3498,5582\n",
            "3499,5076\n",
            "3500,8065\n",
            "3501,4082\n",
            "3502,7247\n",
            "3503,6730\n",
            "3504,5558\n",
            "3505,8494\n",
            "3506,8300\n",
            "3507,5376\n",
            "3508,6289\n",
            "3509,8930\n",
            "3510,8016\n",
            "3511,8723\n",
            "3512,4228\n",
            "3513,5466\n",
            "3514,6373\n",
            "3515,7913\n",
            "3516,4153\n",
            "3517,7675\n",
            "3518,4086\n",
            "3519,8259\n",
            "3520,5000\n",
            "3521,4581\n",
            "3522,4238\n",
            "3523,6818\n",
            "3524,6425\n",
            "3525,6204\n",
            "3526,5843\n",
            "3527,7783\n",
            "3528,7297\n",
            "3529,8254\n",
            "3530,7492\n",
            "3531,8538\n",
            "3532,5423\n",
            "3533,6530\n",
            "3534,7937\n",
            "3535,6712\n",
            "3536,4388\n",
            "3537,8516\n",
            "3538,6128\n",
            "3539,8375\n",
            "3540,7239\n",
            "3541,8034\n",
            "3542,7030\n",
            "3543,7981\n",
            "3544,6634\n",
            "3545,5633\n",
            "3546,4536\n",
            "3547,6430\n",
            "3548,8471\n",
            "3549,8507\n",
            "3550,6335\n",
            "3551,7670\n",
            "3552,8075\n",
            "3553,8924\n",
            "3554,8409\n",
            "3555,6777\n",
            "3556,7529\n",
            "3557,6449\n",
            "3558,5667\n",
            "3559,5354\n",
            "3560,5402\n",
            "3561,5342\n",
            "3562,4924\n",
            "3563,5110\n",
            "3564,8905\n",
            "3565,7701\n",
            "3566,8350\n",
            "3567,7238\n",
            "3568,5524\n",
            "3569,4248\n",
            "3570,4647\n",
            "3571,4836\n",
            "3572,4496\n",
            "3573,5477\n",
            "3574,7680\n",
            "3575,6971\n",
            "3576,7277\n",
            "3577,7964\n",
            "3578,7144\n",
            "3579,4300\n",
            "3580,8780\n",
            "3581,8293\n",
            "3582,7591\n",
            "3583,4395\n",
            "3584,7390\n",
            "3585,6792\n",
            "3586,5169\n",
            "3587,5268\n",
            "3588,7010\n",
            "3589,4935\n",
            "3590,7530\n",
            "3591,7485\n",
            "3592,7085\n",
            "3593,4895\n",
            "3594,4331\n",
            "3595,5283\n",
            "3596,7471\n",
            "3597,6816\n",
            "3598,8673\n",
            "3599,4613\n",
            "3600,4131\n",
            "3601,7368\n",
            "3602,6884\n",
            "3603,6378\n",
            "3604,4513\n",
            "3605,6407\n",
            "3606,6334\n",
            "3607,6698\n",
            "3608,8279\n",
            "3609,4193\n",
            "3610,8229\n",
            "3611,8161\n",
            "3612,7250\n",
            "3613,8494\n",
            "3614,4761\n",
            "3615,5975\n",
            "3616,5730\n",
            "3617,4647\n",
            "3618,8475\n",
            "3619,8219\n",
            "3620,6975\n",
            "3621,4438\n",
            "3622,7307\n",
            "3623,4369\n",
            "3624,8203\n",
            "3625,6321\n",
            "3626,6018\n",
            "3627,5379\n",
            "3628,8640\n",
            "3629,7627\n",
            "3630,7688\n",
            "3631,5785\n",
            "3632,6314\n",
            "3633,5474\n",
            "3634,7281\n",
            "3635,4555\n",
            "3636,6522\n",
            "3637,6330\n",
            "3638,7417\n",
            "3639,8770\n",
            "3640,7911\n",
            "3641,4406\n",
            "3642,4895\n",
            "3643,7665\n",
            "3644,7852\n",
            "3645,8499\n",
            "3646,4634\n",
            "3647,8260\n",
            "3648,6782\n",
            "3649,5247\n",
            "3650,7025\n",
            "3651,4318\n",
            "3652,5827\n",
            "3653,8902\n",
            "3654,5462\n",
            "3655,4959\n",
            "3656,6530\n",
            "3657,8548\n",
            "3658,7511\n",
            "3659,5392\n",
            "3660,4482\n",
            "3661,6010\n",
            "3662,8580\n",
            "3663,7869\n",
            "3664,4439\n",
            "3665,8463\n",
            "3666,7834\n",
            "3667,4752\n",
            "3668,8318\n",
            "3669,7464\n",
            "3670,7959\n",
            "3671,7374\n",
            "3672,6468\n",
            "3673,6406\n",
            "3674,6340\n",
            "3675,4332\n",
            "3676,7596\n",
            "3677,7716\n",
            "3678,5512\n",
            "3679,4950\n",
            "3680,6067\n",
            "3681,5757\n",
            "3682,5206\n",
            "3683,8377\n",
            "3684,4128\n",
            "3685,8717\n",
            "3686,6214\n",
            "3687,5437\n",
            "3688,8123\n",
            "3689,8168\n",
            "3690,7602\n",
            "3691,6019\n",
            "3692,4619\n",
            "3693,8495\n",
            "3694,6125\n",
            "3695,7170\n",
            "3696,5461\n",
            "3697,8771\n",
            "3698,7755\n",
            "3699,8278\n",
            "3700,4176\n",
            "3701,4530\n",
            "3702,8193\n",
            "3703,8946\n",
            "3704,4462\n",
            "3705,8110\n",
            "3706,7951\n",
            "3707,6889\n",
            "3708,5285\n",
            "3709,6809\n",
            "3710,6599\n",
            "3711,7487\n",
            "3712,5948\n",
            "3713,8789\n",
            "3714,8483\n",
            "3715,7267\n",
            "3716,8285\n",
            "3717,6995\n",
            "3718,6668\n",
            "3719,8329\n",
            "3720,5606\n",
            "3721,8893\n",
            "3722,8267\n",
            "3723,7315\n",
            "3724,7691\n",
            "3725,5714\n",
            "3726,8380\n",
            "3727,8348\n",
            "3728,6062\n",
            "3729,7472\n",
            "3730,6732\n",
            "3731,8719\n",
            "3732,6759\n",
            "3733,6477\n",
            "3734,8427\n",
            "3735,4465\n",
            "3736,5271\n",
            "3737,5886\n",
            "3738,6876\n",
            "3739,6317\n",
            "3740,7063\n",
            "3741,6907\n",
            "3742,6635\n",
            "3743,8539\n",
            "3744,7495\n",
            "3745,7470\n",
            "3746,5678\n",
            "3747,8084\n",
            "3748,8806\n",
            "3749,8450\n",
            "3750,5214\n",
            "3751,7891\n",
            "3752,7676\n",
            "3753,4249\n",
            "3754,4499\n",
            "3755,4192\n",
            "3756,8318\n",
            "3757,8078\n",
            "3758,7208\n",
            "3759,6614\n",
            "3760,6174\n",
            "3761,8188\n",
            "3762,8308\n",
            "3763,4623\n",
            "3764,7559\n",
            "3765,5029\n",
            "3766,6556\n",
            "3767,7493\n",
            "3768,8254\n",
            "3769,4241\n",
            "3770,8036\n",
            "3771,5662\n",
            "3772,4513\n",
            "3773,6168\n",
            "3774,4728\n",
            "3775,8448\n",
            "3776,7460\n",
            "3777,8182\n",
            "3778,4663\n",
            "3779,6496\n",
            "3780,8431\n",
            "3781,5281\n",
            "3782,7371\n",
            "3783,8904\n",
            "3784,5736\n",
            "3785,5948\n",
            "3786,5468\n",
            "3787,7988\n",
            "3788,7535\n",
            "3789,6330\n",
            "3790,5284\n",
            "3791,8346\n",
            "3792,5475\n",
            "3793,5643\n",
            "3794,4735\n",
            "3795,4663\n",
            "3796,5529\n",
            "3797,8826\n",
            "3798,6871\n",
            "3799,4618\n",
            "3800,5666\n",
            "3801,4808\n",
            "3802,4801\n",
            "3803,6911\n",
            "3804,4714\n",
            "3805,6611\n",
            "3806,6431\n",
            "3807,6343\n",
            "3808,7063\n",
            "3809,5383\n",
            "3810,7336\n",
            "3811,6302\n",
            "3812,5560\n",
            "3813,8969\n",
            "3814,4993\n",
            "3815,4960\n",
            "3816,5148\n",
            "3817,8785\n",
            "3818,5300\n",
            "3819,4757\n",
            "3820,8507\n",
            "3821,5753\n",
            "3822,6371\n",
            "3823,7585\n",
            "3824,8344\n",
            "3825,6588\n",
            "3826,5140\n",
            "3827,8046\n",
            "3828,5668\n",
            "3829,7305\n",
            "3830,4418\n",
            "3831,4609\n",
            "3832,8754\n",
            "3833,5923\n",
            "3834,6194\n",
            "3835,7830\n",
            "3836,8003\n",
            "3837,5290\n",
            "3838,4227\n",
            "3839,5326\n",
            "3840,8810\n",
            "3841,6979\n",
            "3842,7467\n",
            "3843,7951\n",
            "3844,6616\n",
            "3845,6582\n",
            "3846,5448\n",
            "3847,7997\n",
            "3848,8183\n",
            "3849,8451\n",
            "3850,5333\n",
            "3851,4750\n",
            "3852,5984\n",
            "3853,5999\n",
            "3854,5056\n",
            "3855,8899\n",
            "3856,8578\n",
            "3857,4822\n",
            "3858,6204\n",
            "3859,5476\n",
            "3860,4689\n",
            "3861,7820\n",
            "3862,7687\n",
            "3863,8409\n",
            "3864,6382\n",
            "3865,6594\n",
            "3866,7670\n",
            "3867,7373\n",
            "3868,6731\n",
            "3869,6133\n",
            "3870,8891\n",
            "3871,5137\n",
            "3872,5439\n",
            "3873,6124\n",
            "3874,5410\n",
            "3875,5627\n",
            "3876,5681\n",
            "3877,7156\n",
            "3878,6556\n",
            "3879,4708\n",
            "3880,7169\n",
            "3881,5714\n",
            "3882,6571\n",
            "3883,5878\n",
            "3884,8722\n",
            "3885,6867\n",
            "3886,4395\n",
            "3887,8559\n",
            "3888,7394\n",
            "3889,5774\n",
            "3890,7365\n",
            "3891,8766\n",
            "3892,4489\n",
            "3893,5007\n",
            "3894,5820\n",
            "3895,5781\n",
            "3896,5967\n",
            "3897,7054\n",
            "3898,4679\n",
            "3899,8590\n",
            "3900,5339\n",
            "3901,7119\n",
            "3902,4297\n",
            "3903,6241\n",
            "3904,7957\n",
            "3905,4397\n",
            "3906,8272\n",
            "3907,7871\n",
            "3908,4168\n",
            "3909,8077\n",
            "3910,8116\n",
            "3911,5735\n",
            "3912,5139\n",
            "3913,7518\n",
            "3914,5796\n",
            "3915,4869\n",
            "3916,8383\n",
            "3917,5307\n",
            "3918,4580\n",
            "3919,7928\n",
            "3920,7607\n",
            "3921,8075\n",
            "3922,6719\n",
            "3923,4623\n",
            "3924,5632\n",
            "3925,8777\n",
            "3926,5816\n",
            "3927,7620\n",
            "3928,6917\n",
            "3929,7969\n",
            "3930,8507\n",
            "3931,5118\n",
            "3932,5019\n",
            "3933,7288\n",
            "3934,8884\n",
            "3935,7659\n",
            "3936,5522\n",
            "3937,5756\n",
            "3938,4359\n",
            "3939,6590\n",
            "3940,5491\n",
            "3941,4867\n",
            "3942,7594\n",
            "3943,8447\n",
            "3944,4523\n",
            "3945,8518\n",
            "3946,4754\n",
            "3947,7629\n",
            "3948,5715\n",
            "3949,6292\n",
            "3950,4520\n",
            "3951,4499\n",
            "3952,7496\n",
            "3953,5450\n",
            "3954,4664\n",
            "3955,7595\n",
            "3956,6651\n",
            "3957,8446\n",
            "3958,4735\n",
            "3959,5093\n",
            "3960,4792\n",
            "3961,6159\n",
            "3962,5518\n",
            "3963,7834\n",
            "3964,6582\n",
            "3965,8870\n",
            "3966,8416\n",
            "3967,5578\n",
            "3968,7938\n",
            "3969,4729\n",
            "3970,7302\n",
            "3971,5813\n",
            "3972,6790\n",
            "3973,6520\n",
            "3974,6253\n",
            "3975,8864\n",
            "3976,4110\n",
            "3977,8786\n",
            "3978,8925\n",
            "3979,8556\n",
            "3980,4810\n",
            "3981,5042\n",
            "3982,4088\n",
            "3983,8759\n",
            "3984,7551\n",
            "3985,8666\n",
            "3986,4629\n",
            "3987,4822\n",
            "3988,7200\n",
            "3989,4351\n",
            "3990,4545\n",
            "3991,6597\n",
            "3992,6143\n",
            "3993,4854\n",
            "3994,8906\n",
            "3995,5333\n",
            "3996,4658\n",
            "3997,4378\n",
            "3998,8749\n",
            "3999,5017\n",
            "4000,5314\n",
            "4001,8529\n",
            "4002,8056\n",
            "4003,6412\n",
            "4004,5260\n",
            "4005,4480\n",
            "4006,7951\n",
            "4007,5032\n",
            "4008,8464\n",
            "4009,4315\n",
            "4010,8580\n",
            "4011,5011\n",
            "4012,5011\n",
            "4013,8213\n",
            "4014,6269\n",
            "4015,6475\n",
            "4016,6292\n",
            "4017,8011\n",
            "4018,8250\n",
            "4019,5642\n",
            "4020,5224\n",
            "4021,4150\n",
            "4022,8190\n",
            "4023,6840\n",
            "4024,4527\n",
            "4025,5150\n",
            "4026,5721\n",
            "4027,7605\n",
            "4028,6058\n",
            "4029,4839\n",
            "4030,8682\n",
            "4031,7393\n",
            "4032,5830\n",
            "4033,7156\n",
            "4034,7782\n",
            "4035,4865\n",
            "4036,7691\n",
            "4037,5829\n",
            "4038,4497\n",
            "4039,5379\n",
            "4040,4936\n",
            "4041,6465\n",
            "4042,6685\n",
            "4043,5968\n",
            "4044,7137\n",
            "4045,6860\n",
            "4046,5593\n",
            "4047,4973\n",
            "4048,8829\n",
            "4049,7344\n",
            "4050,7627\n",
            "4051,7758\n",
            "4052,6920\n",
            "4053,8878\n",
            "4054,6277\n",
            "4055,7831\n",
            "4056,5119\n",
            "4057,6412\n",
            "4058,7834\n",
            "4059,6642\n",
            "4060,4481\n",
            "4061,4982\n",
            "4062,5565\n",
            "4063,6859\n",
            "4064,4777\n",
            "4065,5829\n",
            "4066,5558\n",
            "4067,4895\n",
            "4068,6172\n",
            "4069,7147\n",
            "4070,6266\n",
            "4071,4927\n",
            "4072,5778\n",
            "4073,6585\n",
            "4074,6741\n",
            "4075,4576\n",
            "4076,5491\n",
            "4077,5796\n",
            "4078,5620\n",
            "4079,5655\n",
            "4080,5838\n",
            "4081,7215\n",
            "4082,4237\n",
            "4083,4247\n",
            "4084,4424\n",
            "4085,6127\n",
            "4086,4888\n",
            "4087,4644\n",
            "4088,4266\n",
            "4089,4084\n",
            "4090,8204\n",
            "4091,6382\n",
            "4092,5168\n",
            "4093,5513\n",
            "4094,6224\n",
            "4095,4736\n",
            "4096,6525\n",
            "4097,8398\n",
            "4098,6594\n",
            "4099,7566\n",
            "4100,5100\n",
            "4101,5311\n",
            "4102,8651\n",
            "4103,7249\n",
            "4104,6708\n",
            "4105,8561\n",
            "4106,7844\n",
            "4107,8003\n",
            "4108,6840\n",
            "4109,5640\n",
            "4110,7841\n",
            "4111,7304\n",
            "4112,7931\n",
            "4113,7098\n",
            "4114,4745\n",
            "4115,6142\n",
            "4116,8018\n",
            "4117,8000\n",
            "4118,4277\n",
            "4119,4254\n",
            "4120,8127\n",
            "4121,6017\n",
            "4122,8626\n",
            "4123,8641\n",
            "4124,7625\n",
            "4125,5389\n",
            "4126,7228\n",
            "4127,5357\n",
            "4128,5795\n",
            "4129,8893\n",
            "4130,6068\n",
            "4131,4501\n",
            "4132,8594\n",
            "4133,8627\n",
            "4134,7750\n",
            "4135,6712\n",
            "4136,7388\n",
            "4137,8752\n",
            "4138,6562\n",
            "4139,5977\n",
            "4140,7384\n",
            "4141,4735\n",
            "4142,4575\n",
            "4143,5867\n",
            "4144,7369\n",
            "4145,6330\n",
            "4146,6315\n",
            "4147,8790\n",
            "4148,5942\n",
            "4149,8306\n",
            "4150,5711\n",
            "4151,8786\n",
            "4152,7220\n",
            "4153,4186\n",
            "4154,8410\n",
            "4155,6680\n",
            "4156,6454\n",
            "4157,4344\n",
            "4158,4263\n",
            "4159,5914\n",
            "4160,4117\n",
            "4161,8313\n",
            "4162,7022\n",
            "4163,6702\n",
            "4164,4852\n",
            "4165,7796\n",
            "4166,8117\n",
            "4167,7809\n",
            "4168,7679\n",
            "4169,7596\n",
            "4170,5619\n",
            "4171,6948\n",
            "4172,4897\n",
            "4173,7776\n",
            "4174,6878\n",
            "4175,7167\n",
            "4176,7985\n",
            "4177,7058\n",
            "4178,5523\n",
            "4179,7866\n",
            "4180,4226\n",
            "4181,7538\n",
            "4182,7782\n",
            "4183,7811\n",
            "4184,4956\n",
            "4185,4267\n",
            "4186,7283\n",
            "4187,5698\n",
            "4188,7624\n",
            "4189,7513\n",
            "4190,6238\n",
            "4191,5786\n",
            "4192,4708\n",
            "4193,4565\n",
            "4194,6846\n",
            "4195,4668\n",
            "4196,7541\n",
            "4197,6140\n",
            "4198,8696\n",
            "4199,6085\n",
            "4200,5202\n",
            "4201,8616\n",
            "4202,5439\n",
            "4203,4738\n",
            "4204,7253\n",
            "4205,5563\n",
            "4206,7320\n",
            "4207,5731\n",
            "4208,4893\n",
            "4209,5196\n",
            "4210,4533\n",
            "4211,5810\n",
            "4212,6674\n",
            "4213,7828\n",
            "4214,7505\n",
            "4215,8438\n",
            "4216,6340\n",
            "4217,6454\n",
            "4218,8786\n",
            "4219,8299\n",
            "4220,7566\n",
            "4221,8257\n",
            "4222,6584\n",
            "4223,5756\n",
            "4224,7627\n",
            "4225,6508\n",
            "4226,4728\n",
            "4227,7077\n",
            "4228,7175\n",
            "4229,5024\n",
            "4230,5026\n",
            "4231,5498\n",
            "4232,4343\n",
            "4233,7160\n",
            "4234,8028\n",
            "4235,5403\n",
            "4236,5330\n",
            "4237,4771\n",
            "4238,6142\n",
            "4239,7454\n",
            "4240,7300\n",
            "4241,6043\n",
            "4242,4578\n",
            "4243,6458\n",
            "4244,8491\n",
            "4245,6854\n",
            "4246,7913\n",
            "4247,7366\n",
            "4248,6514\n",
            "4249,8747\n",
            "4250,6952\n",
            "4251,5011\n",
            "4252,6470\n",
            "4253,6958\n",
            "4254,5916\n",
            "4255,6574\n",
            "4256,4440\n",
            "4257,7003\n",
            "4258,8494\n",
            "4259,7870\n",
            "4260,5595\n",
            "4261,6151\n",
            "4262,7430\n",
            "4263,7888\n",
            "4264,5973\n",
            "4265,8330\n",
            "4266,5628\n",
            "4267,7616\n",
            "4268,7464\n",
            "4269,4145\n",
            "4270,8459\n",
            "4271,7071\n",
            "4272,8756\n",
            "4273,4691\n",
            "4274,4326\n",
            "4275,7842\n",
            "4276,6954\n",
            "4277,8706\n",
            "4278,8484\n",
            "4279,5306\n",
            "4280,4202\n",
            "4281,5185\n",
            "4282,4764\n",
            "4283,7275\n",
            "4284,7052\n",
            "4285,4273\n",
            "4286,6226\n",
            "4287,8134\n",
            "4288,4997\n",
            "4289,6161\n",
            "4290,7184\n",
            "4291,8499\n",
            "4292,8647\n",
            "4293,4401\n",
            "4294,7934\n",
            "4295,8357\n",
            "4296,6423\n",
            "4297,8080\n",
            "4298,7601\n",
            "4299,8030\n",
            "4300,8515\n",
            "4301,6195\n",
            "4302,7448\n",
            "4303,5525\n",
            "4304,5845\n",
            "4305,5647\n",
            "4306,8450\n",
            "4307,8838\n",
            "4308,7765\n",
            "4309,4514\n",
            "4310,7943\n",
            "4311,4532\n",
            "4312,8424\n",
            "4313,8869\n",
            "4314,5827\n",
            "4315,5633\n",
            "4316,4182\n",
            "4317,7792\n",
            "4318,6708\n",
            "4319,6020\n",
            "4320,7515\n",
            "4321,5853\n",
            "4322,4202\n",
            "4323,5455\n",
            "4324,7775\n",
            "4325,5291\n",
            "4326,4912\n",
            "4327,4803\n",
            "4328,8578\n",
            "4329,8316\n",
            "4330,8368\n",
            "4331,4264\n",
            "4332,6355\n",
            "4333,8217\n",
            "4334,7699\n",
            "4335,6629\n",
            "4336,4360\n",
            "4337,6669\n",
            "4338,5408\n",
            "4339,4583\n",
            "4340,5589\n",
            "4341,7081\n",
            "4342,4892\n",
            "4343,7978\n",
            "4344,7760\n",
            "4345,7933\n",
            "4346,6129\n",
            "4347,6640\n",
            "4348,8356\n",
            "4349,4234\n",
            "4350,6518\n",
            "4351,4761\n",
            "4352,5980\n",
            "4353,6060\n",
            "4354,7653\n",
            "4355,8497\n",
            "4356,6297\n",
            "4357,8372\n",
            "4358,6653\n",
            "4359,5616\n",
            "4360,6038\n",
            "4361,8043\n",
            "4362,5656\n",
            "4363,7287\n",
            "4364,8579\n",
            "4365,5017\n",
            "4366,7428\n",
            "4367,8806\n",
            "4368,6564\n",
            "4369,7595\n",
            "4370,4925\n",
            "4371,6214\n",
            "4372,7652\n",
            "4373,7953\n",
            "4374,6487\n",
            "4375,5177\n",
            "4376,5179\n",
            "4377,5727\n",
            "4378,7239\n",
            "4379,4416\n",
            "4380,8331\n",
            "4381,7198\n",
            "4382,4989\n",
            "4383,5276\n",
            "4384,7603\n",
            "4385,4341\n",
            "4386,7050\n",
            "4387,5116\n",
            "4388,7389\n",
            "4389,4629\n",
            "4390,5286\n",
            "4391,6816\n",
            "4392,8140\n",
            "4393,8546\n",
            "4394,8948\n",
            "4395,6447\n",
            "4396,8548\n",
            "4397,4780\n",
            "4398,6296\n",
            "4399,6477\n",
            "4400,6995\n",
            "4401,5739\n",
            "4402,5684\n",
            "4403,5653\n",
            "4404,8312\n",
            "4405,6670\n",
            "4406,7990\n",
            "4407,8351\n",
            "4408,4532\n",
            "4409,6587\n",
            "4410,4431\n",
            "4411,4407\n",
            "4412,4740\n",
            "4413,5588\n",
            "4414,5303\n",
            "4415,5760\n",
            "4416,7876\n",
            "4417,6954\n",
            "4418,6246\n",
            "4419,5513\n",
            "4420,8550\n",
            "4421,4838\n",
            "4422,8631\n",
            "4423,5324\n",
            "4424,8656\n",
            "4425,5835\n",
            "4426,4690\n",
            "4427,8721\n",
            "4428,6779\n",
            "4429,8099\n",
            "4430,5389\n",
            "4431,6594\n",
            "4432,5885\n",
            "4433,4068\n",
            "4434,5499\n",
            "4435,7427\n",
            "4436,7569\n",
            "4437,5730\n",
            "4438,5695\n",
            "4439,4175\n",
            "4440,4382\n",
            "4441,8410\n",
            "4442,8283\n",
            "4443,6182\n",
            "4444,5876\n",
            "4445,5267\n",
            "4446,7337\n",
            "4447,5947\n",
            "4448,4264\n",
            "4449,6725\n",
            "4450,8829\n",
            "4451,6500\n",
            "4452,7298\n",
            "4453,7083\n",
            "4454,7480\n",
            "4455,5840\n",
            "4456,5350\n",
            "4457,8304\n",
            "4458,8033\n",
            "4459,6007\n",
            "4460,7382\n",
            "4461,8446\n",
            "4462,8941\n",
            "4463,7357\n",
            "4464,8830\n",
            "4465,4227\n",
            "4466,6123\n",
            "4467,6053\n",
            "4468,7407\n",
            "4469,8350\n",
            "4470,8868\n",
            "4471,8003\n",
            "4472,6060\n",
            "4473,7295\n",
            "4474,4810\n",
            "4475,6605\n",
            "4476,4384\n",
            "4477,8212\n",
            "4478,6032\n",
            "4479,5190\n",
            "4480,5559\n",
            "4481,7001\n",
            "4482,6766\n",
            "4483,6659\n",
            "4484,4834\n",
            "4485,8098\n",
            "4486,8827\n",
            "4487,4657\n",
            "4488,5043\n",
            "4489,5674\n",
            "4490,6228\n",
            "4491,5266\n",
            "4492,4575\n",
            "4493,4452\n",
            "4494,7811\n",
            "4495,4274\n",
            "4496,5324\n",
            "4497,8488\n",
            "4498,4499\n",
            "4499,8116\n",
            "4500,6039\n",
            "4501,8805\n",
            "4502,4581\n",
            "4503,4326\n",
            "4504,5385\n",
            "4505,8186\n",
            "4506,4713\n",
            "4507,8259\n",
            "4508,4949\n",
            "4509,6371\n",
            "4510,6633\n",
            "4511,5340\n",
            "4512,5349\n",
            "4513,6941\n",
            "4514,5584\n",
            "4515,8046\n",
            "4516,7551\n",
            "4517,8087\n",
            "4518,8346\n",
            "4519,4838\n",
            "4520,8869\n",
            "4521,5002\n",
            "4522,7461\n",
            "4523,8515\n",
            "4524,8578\n",
            "4525,6403\n",
            "4526,5597\n",
            "4527,5328\n",
            "4528,4591\n",
            "4529,5756\n",
            "4530,4865\n",
            "4531,7330\n",
            "4532,7489\n",
            "4533,5310\n",
            "4534,5949\n",
            "4535,7740\n",
            "4536,5176\n",
            "4537,4848\n",
            "4538,6293\n",
            "4539,7300\n",
            "4540,6325\n",
            "4541,8702\n",
            "4542,5956\n",
            "4543,6145\n",
            "4544,5640\n",
            "4545,4263\n",
            "4546,6348\n",
            "4547,8819\n",
            "4548,6632\n",
            "4549,6443\n",
            "4550,5111\n",
            "4551,6949\n",
            "4552,4290\n",
            "4553,6134\n",
            "4554,6293\n",
            "4555,6947\n",
            "4556,5974\n",
            "4557,6859\n",
            "4558,7673\n",
            "4559,7847\n",
            "4560,6303\n",
            "4561,5568\n",
            "4562,8513\n",
            "4563,7666\n",
            "4564,8030\n",
            "4565,4482\n",
            "4566,4360\n",
            "4567,7574\n",
            "4568,8223\n",
            "4569,7040\n",
            "4570,8275\n",
            "4571,5286\n",
            "4572,4196\n",
            "4573,4662\n",
            "4574,6825\n",
            "4575,8678\n",
            "4576,8725\n",
            "4577,7346\n",
            "4578,5796\n",
            "4579,8615\n",
            "4580,8072\n",
            "4581,6557\n",
            "4582,6851\n",
            "4583,6819\n",
            "4584,6643\n",
            "4585,8791\n",
            "4586,7532\n",
            "4587,6522\n",
            "4588,8614\n",
            "4589,4515\n",
            "4590,8433\n",
            "4591,7774\n",
            "4592,7065\n",
            "4593,7293\n",
            "4594,7321\n",
            "4595,7626\n",
            "4596,4798\n",
            "4597,8751\n",
            "4598,5022\n",
            "4599,8399\n",
            "4600,6375\n",
            "4601,7670\n",
            "4602,7440\n",
            "4603,4123\n",
            "4604,6866\n",
            "4605,6662\n",
            "4606,6171\n",
            "4607,8914\n",
            "4608,6536\n",
            "4609,5165\n",
            "4610,4144\n",
            "4611,5900\n",
            "4612,6460\n",
            "4613,6852\n",
            "4614,7152\n",
            "4615,7880\n",
            "4616,8854\n",
            "4617,5562\n",
            "4618,4276\n",
            "4619,4279\n",
            "4620,4612\n",
            "4621,6346\n",
            "4622,7724\n",
            "4623,7475\n",
            "4624,5891\n",
            "4625,4892\n",
            "4626,8576\n",
            "4627,4642\n",
            "4628,4864\n",
            "4629,7870\n",
            "4630,5800\n",
            "4631,6062\n",
            "4632,8526\n",
            "4633,4084\n",
            "4634,8406\n",
            "4635,8184\n",
            "4636,4947\n",
            "4637,7981\n",
            "4638,8711\n",
            "4639,6219\n",
            "4640,6730\n",
            "4641,5521\n",
            "4642,4221\n",
            "4643,7470\n",
            "4644,6277\n",
            "4645,5143\n",
            "4646,5288\n",
            "4647,5938\n",
            "4648,4972\n",
            "4649,4233\n",
            "4650,7718\n",
            "4651,7963\n",
            "4652,6468\n",
            "4653,6022\n",
            "4654,4526\n",
            "4655,4460\n",
            "4656,8382\n",
            "4657,5382\n",
            "4658,8376\n",
            "4659,5634\n",
            "4660,7012\n",
            "4661,7575\n",
            "4662,8178\n",
            "4663,4586\n",
            "4664,8522\n",
            "4665,7885\n",
            "4666,5825\n",
            "4667,7274\n",
            "4668,8942\n",
            "4669,8766\n",
            "4670,5691\n",
            "4671,5989\n",
            "4672,6044\n",
            "4673,8781\n",
            "4674,6537\n",
            "4675,7274\n",
            "4676,6278\n",
            "4677,7465\n",
            "4678,5110\n",
            "4679,7032\n",
            "4680,5401\n",
            "4681,7992\n",
            "4682,8308\n",
            "4683,7660\n",
            "4684,8660\n",
            "4685,4391\n",
            "4686,7312\n",
            "4687,8451\n",
            "4688,5193\n",
            "4689,7851\n",
            "4690,4951\n",
            "4691,5147\n",
            "4692,4770\n",
            "4693,8908\n",
            "4694,6935\n",
            "4695,5385\n",
            "4696,7329\n",
            "4697,5796\n",
            "4698,6122\n",
            "4699,6260\n",
            "4700,7777\n",
            "4701,8331\n",
            "4702,5994\n",
            "4703,6480\n",
            "4704,4265\n",
            "4705,7441\n",
            "4706,8193\n",
            "4707,8757\n",
            "4708,4831\n",
            "4709,7781\n",
            "4710,6790\n",
            "4711,6591\n",
            "4712,5277\n",
            "4713,6052\n",
            "4714,8201\n",
            "4715,8701\n",
            "4716,8434\n",
            "4717,8024\n",
            "4718,8203\n",
            "4719,7398\n",
            "4720,8766\n",
            "4721,6389\n",
            "4722,7642\n",
            "4723,5661\n",
            "4724,8025\n",
            "4725,6886\n",
            "4726,8470\n",
            "4727,6013\n",
            "4728,8025\n",
            "4729,4973\n",
            "4730,6018\n",
            "4731,5190\n",
            "4732,5078\n",
            "4733,8035\n",
            "4734,6073\n",
            "4735,8318\n",
            "4736,4979\n",
            "4737,5700\n",
            "4738,6158\n",
            "4739,5808\n",
            "4740,8914\n",
            "4741,5299\n",
            "4742,8596\n",
            "4743,4882\n",
            "4744,5247\n",
            "4745,5296\n",
            "4746,7536\n",
            "4747,7982\n",
            "4748,5199\n",
            "4749,4866\n",
            "4750,6451\n",
            "4751,6804\n",
            "4752,4813\n",
            "4753,8394\n",
            "4754,7409\n",
            "4755,7444\n",
            "4756,8214\n",
            "4757,7691\n",
            "4758,5288\n",
            "4759,4313\n",
            "4760,5144\n",
            "4761,6372\n",
            "4762,8174\n",
            "4763,6519\n",
            "4764,8258\n",
            "4765,4704\n",
            "4766,5424\n",
            "4767,4538\n",
            "4768,5006\n",
            "4769,6506\n",
            "4770,6495\n",
            "4771,5364\n",
            "4772,4365\n",
            "4773,4447\n",
            "4774,4411\n",
            "4775,7907\n",
            "4776,4750\n",
            "4777,8518\n",
            "4778,4829\n",
            "4779,5136\n",
            "4780,4955\n",
            "4781,7692\n",
            "4782,5265\n",
            "4783,4869\n",
            "4784,5552\n",
            "4785,5499\n",
            "4786,5308\n",
            "4787,4600\n",
            "4788,6848\n",
            "4789,7372\n",
            "4790,7329\n",
            "4791,8789\n",
            "4792,4230\n",
            "4793,8466\n",
            "4794,5585\n",
            "4795,8058\n",
            "4796,7557\n",
            "4797,5652\n",
            "4798,6695\n",
            "4799,7955\n",
            "4800,8312\n",
            "4801,6143\n",
            "4802,8115\n",
            "4803,7013\n",
            "4804,5180\n",
            "4805,5302\n",
            "4806,7732\n",
            "4807,6849\n",
            "4808,5328\n",
            "4809,7795\n",
            "4810,6859\n",
            "4811,4612\n",
            "4812,8571\n",
            "4813,5863\n",
            "4814,7522\n",
            "4815,8564\n",
            "4816,4694\n",
            "4817,8852\n",
            "4818,6627\n",
            "4819,8485\n",
            "4820,5575\n",
            "4821,7454\n",
            "4822,7323\n",
            "4823,6337\n",
            "4824,5829\n",
            "4825,8794\n",
            "4826,4628\n",
            "4827,6797\n",
            "4828,5957\n",
            "4829,7209\n",
            "4830,7140\n",
            "4831,8927\n",
            "4832,4108\n",
            "4833,5545\n",
            "4834,4121\n",
            "4835,7254\n",
            "4836,6012\n",
            "4837,4468\n",
            "4838,6932\n",
            "4839,7203\n",
            "4840,4867\n",
            "4841,7620\n",
            "4842,6623\n",
            "4843,6869\n",
            "4844,6092\n",
            "4845,7673\n",
            "4846,7631\n",
            "4847,6764\n",
            "4848,8516\n",
            "4849,5202\n",
            "4850,5735\n",
            "4851,4801\n",
            "4852,6868\n",
            "4853,8339\n",
            "4854,6325\n",
            "4855,5198\n",
            "4856,7345\n",
            "4857,6973\n",
            "4858,6212\n",
            "4859,5927\n",
            "4860,8276\n",
            "4861,5723\n",
            "4862,7673\n",
            "4863,8044\n",
            "4864,8301\n",
            "4865,7500\n",
            "4866,4158\n",
            "4867,6453\n",
            "4868,4497\n",
            "4869,5169\n",
            "4870,5315\n",
            "4871,5296\n",
            "4872,5868\n",
            "4873,8421\n",
            "4874,8590\n",
            "4875,7201\n",
            "4876,5687\n",
            "4877,4952\n",
            "4878,5814\n",
            "4879,5315\n",
            "4880,8507\n",
            "4881,7552\n",
            "4882,8765\n",
            "4883,6471\n",
            "4884,5577\n",
            "4885,5105\n",
            "4886,7422\n",
            "4887,8650\n",
            "4888,7178\n",
            "4889,6051\n",
            "4890,6976\n",
            "4891,7962\n",
            "4892,5069\n",
            "4893,6461\n",
            "4894,6191\n",
            "4895,5092\n",
            "4896,5394\n",
            "4897,6355\n",
            "4898,7699\n",
            "4899,8102\n",
            "4900,7875\n",
            "4901,7766\n",
            "4902,7405\n",
            "4903,8384\n",
            "4904,4843\n",
            "4905,6960\n",
            "4906,7141\n",
            "4907,5693\n",
            "4908,5971\n",
            "4909,4849\n",
            "4910,6780\n",
            "4911,8131\n",
            "4912,8219\n",
            "4913,4842\n",
            "4914,6673\n",
            "4915,8370\n",
            "4916,7642\n",
            "4917,4087\n",
            "4918,5878\n",
            "4919,5037\n",
            "4920,5467\n",
            "4921,8201\n",
            "4922,5118\n",
            "4923,8148\n",
            "4924,4331\n",
            "4925,6390\n",
            "4926,7419\n",
            "4927,8014\n",
            "4928,4332\n",
            "4929,4066\n",
            "4930,8703\n",
            "4931,7927\n",
            "4932,4273\n",
            "4933,6433\n",
            "4934,5263\n",
            "4935,4285\n",
            "4936,6093\n",
            "4937,5241\n",
            "4938,5983\n",
            "4939,5086\n",
            "4940,6545\n",
            "4941,8385\n",
            "4942,5279\n",
            "4943,8285\n",
            "4944,8098\n",
            "4945,8919\n",
            "4946,7064\n",
            "4947,7606\n",
            "4948,8654\n",
            "4949,7737\n",
            "4950,4716\n",
            "4951,7271\n",
            "4952,4324\n",
            "4953,4977\n",
            "4954,6815\n",
            "4955,5818\n",
            "4956,8210\n",
            "4957,8411\n",
            "4958,7290\n",
            "4959,8580\n",
            "4960,8211\n",
            "4961,5665\n",
            "4962,5277\n",
            "4963,7585\n",
            "4964,4550\n",
            "4965,8565\n",
            "4966,8269\n",
            "4967,5928\n",
            "4968,6987\n",
            "4969,5402\n",
            "4970,5285\n",
            "4971,6483\n",
            "4972,5008\n",
            "4973,5458\n",
            "4974,6832\n",
            "4975,5830\n",
            "4976,7178\n",
            "4977,4908\n",
            "4978,4592\n",
            "4979,5018\n",
            "4980,8032\n",
            "4981,5655\n",
            "4982,6638\n",
            "4983,5151\n",
            "4984,6922\n",
            "4985,7070\n",
            "4986,5795\n",
            "4987,7786\n",
            "4988,4826\n",
            "4989,6518\n",
            "4990,6756\n",
            "4991,4644\n",
            "4992,6359\n",
            "4993,7747\n",
            "4994,5477\n",
            "4995,8104\n",
            "4996,6109\n",
            "4997,5757\n",
            "4998,6293\n",
            "4999,8640\n",
            "5000,5191\n",
            "5001,8722\n",
            "5002,5344\n",
            "5003,4727\n",
            "5004,5078\n",
            "5005,5096\n",
            "5006,4110\n",
            "5007,7824\n",
            "5008,6065\n",
            "5009,5692\n",
            "5010,5461\n",
            "5011,7684\n",
            "5012,5025\n",
            "5013,8619\n",
            "5014,6753\n",
            "5015,8101\n",
            "5016,4845\n",
            "5017,7181\n",
            "5018,5299\n",
            "5019,4981\n",
            "5020,5589\n",
            "5021,7588\n",
            "5022,5036\n",
            "5023,5850\n",
            "5024,4714\n",
            "5025,8451\n",
            "5026,6177\n",
            "5027,5118\n",
            "5028,4194\n",
            "5029,5442\n",
            "5030,7829\n",
            "5031,4475\n",
            "5032,5628\n",
            "5033,8521\n",
            "5034,4701\n",
            "5035,4664\n",
            "5036,7349\n",
            "5037,5419\n",
            "5038,4365\n",
            "5039,4782\n",
            "5040,8486\n",
            "5041,8461\n",
            "5042,4995\n",
            "5043,7776\n",
            "5044,5353\n",
            "5045,6943\n",
            "5046,5456\n",
            "5047,8301\n",
            "5048,6759\n",
            "5049,7732\n",
            "5050,5743\n",
            "5051,6564\n",
            "5052,7280\n",
            "5053,6815\n",
            "5054,4423\n",
            "5055,4438\n",
            "5056,7734\n",
            "5057,7423\n",
            "5058,7356\n",
            "5059,5504\n",
            "5060,6613\n",
            "5061,4121\n",
            "5062,7717\n",
            "5063,8486\n",
            "5064,7202\n",
            "5065,5683\n",
            "5066,5042\n",
            "5067,7773\n",
            "5068,8433\n",
            "5069,5301\n",
            "5070,5742\n",
            "5071,7951\n",
            "5072,4781\n",
            "5073,7945\n",
            "5074,8926\n",
            "5075,4494\n",
            "5076,7126\n",
            "5077,4898\n",
            "5078,8946\n",
            "5079,7263\n",
            "5080,6627\n",
            "5081,4615\n",
            "5082,7918\n",
            "5083,5396\n",
            "5084,8390\n",
            "5085,8878\n",
            "5086,6540\n",
            "5087,6314\n",
            "5088,5802\n",
            "5089,4667\n",
            "5090,8951\n",
            "5091,7027\n",
            "5092,5722\n",
            "5093,8097\n",
            "5094,7167\n",
            "5095,6476\n",
            "5096,7943\n",
            "5097,8941\n",
            "5098,7582\n",
            "5099,7381\n",
            "5100,7765\n",
            "5101,8119\n",
            "5102,8558\n",
            "5103,4709\n",
            "5104,8330\n",
            "5105,8356\n",
            "5106,7600\n",
            "5107,8187\n",
            "5108,4866\n",
            "5109,7017\n",
            "5110,4465\n",
            "5111,8691\n",
            "5112,7298\n",
            "5113,4567\n",
            "5114,5264\n",
            "5115,4378\n",
            "5116,5205\n",
            "5117,8943\n",
            "5118,4102\n",
            "5119,4779\n",
            "5120,6504\n",
            "5121,6281\n",
            "5122,8147\n",
            "5123,6887\n",
            "5124,4797\n",
            "5125,8138\n",
            "5126,6652\n",
            "5127,4961\n",
            "5128,6881\n",
            "5129,4432\n",
            "5130,7679\n",
            "5131,5765\n",
            "5132,8871\n",
            "5133,6820\n",
            "5134,4157\n",
            "5135,5348\n",
            "5136,5086\n",
            "5137,5662\n",
            "5138,4601\n",
            "5139,4071\n",
            "5140,5385\n",
            "5141,5103\n",
            "5142,5130\n",
            "5143,8334\n",
            "5144,8438\n",
            "5145,4418\n",
            "5146,4554\n",
            "5147,4858\n",
            "5148,6044\n",
            "5149,6998\n",
            "5150,5477\n",
            "5151,7111\n",
            "5152,6180\n",
            "5153,5101\n",
            "5154,6423\n",
            "5155,4716\n",
            "5156,5457\n",
            "5157,5116\n",
            "5158,8027\n",
            "5159,4596\n",
            "5160,7215\n",
            "5161,4093\n",
            "5162,5320\n",
            "5163,7083\n",
            "5164,4859\n",
            "5165,5732\n",
            "5166,5828\n",
            "5167,4604\n",
            "5168,7054\n",
            "5169,7682\n",
            "5170,8076\n",
            "5171,4710\n",
            "5172,4781\n",
            "5173,5906\n",
            "5174,5424\n",
            "5175,8198\n",
            "5176,7566\n",
            "5177,8955\n",
            "5178,7728\n",
            "5179,5318\n",
            "5180,6138\n",
            "5181,4222\n",
            "5182,8868\n",
            "5183,4136\n",
            "5184,6886\n",
            "5185,5607\n",
            "5186,6410\n",
            "5187,6632\n",
            "5188,8222\n",
            "5189,7287\n",
            "5190,4387\n",
            "5191,6590\n",
            "5192,5592\n",
            "5193,4181\n",
            "5194,5563\n",
            "5195,4491\n",
            "5196,6608\n",
            "5197,8892\n",
            "5198,6262\n",
            "5199,7200\n",
            "5200,6549\n",
            "5201,4887\n",
            "5202,5890\n",
            "5203,8580\n",
            "5204,7095\n",
            "5205,5001\n",
            "5206,8331\n",
            "5207,5528\n",
            "5208,6576\n",
            "5209,7939\n",
            "5210,8265\n",
            "5211,8657\n",
            "5212,7759\n",
            "5213,5561\n",
            "5214,7785\n",
            "5215,4355\n",
            "5216,5457\n",
            "5217,4917\n",
            "5218,4368\n",
            "5219,7131\n",
            "5220,5810\n",
            "5221,4593\n",
            "5222,7147\n",
            "5223,5913\n",
            "5224,5300\n",
            "5225,4105\n",
            "5226,8714\n",
            "5227,7051\n",
            "5228,7330\n",
            "5229,5571\n",
            "5230,6763\n",
            "5231,7327\n",
            "5232,5413\n",
            "5233,5198\n",
            "5234,7032\n",
            "5235,5567\n",
            "5236,5634\n",
            "5237,7851\n",
            "5238,8565\n",
            "5239,5075\n",
            "5240,4873\n",
            "5241,4250\n",
            "5242,5727\n",
            "5243,5741\n",
            "5244,7349\n",
            "5245,4172\n",
            "5246,4395\n",
            "5247,8285\n",
            "5248,7979\n",
            "5249,7779\n",
            "5250,4150\n",
            "5251,8945\n",
            "5252,5402\n",
            "5253,7029\n",
            "5254,6958\n",
            "5255,7608\n",
            "5256,4988\n",
            "5257,7433\n",
            "5258,8791\n",
            "5259,4520\n",
            "5260,8955\n",
            "5261,8735\n",
            "5262,8209\n",
            "5263,6119\n",
            "5264,7608\n",
            "5265,7863\n",
            "5266,5298\n",
            "5267,7110\n",
            "5268,6027\n",
            "5269,7790\n",
            "5270,8576\n",
            "5271,7865\n",
            "5272,7450\n",
            "5273,7194\n",
            "5274,6922\n",
            "5275,5887\n",
            "5276,5285\n",
            "5277,8660\n",
            "5278,6967\n",
            "5279,6216\n",
            "5280,4084\n",
            "5281,6718\n",
            "5282,7065\n",
            "5283,8266\n",
            "5284,5730\n",
            "5285,6847\n",
            "5286,8032\n",
            "5287,7153\n",
            "5288,8100\n",
            "5289,8785\n",
            "5290,7480\n",
            "5291,7721\n",
            "5292,7501\n",
            "5293,6827\n",
            "5294,5337\n",
            "5295,5788\n",
            "5296,5993\n",
            "5297,7506\n",
            "5298,6333\n",
            "5299,5757\n",
            "5300,7979\n",
            "5301,5426\n",
            "5302,6788\n",
            "5303,7277\n",
            "5304,4631\n",
            "5305,8286\n",
            "5306,7685\n",
            "5307,6056\n",
            "5308,7659\n",
            "5309,6610\n",
            "5310,6220\n",
            "5311,6826\n",
            "5312,5704\n",
            "5313,6859\n",
            "5314,5711\n",
            "5315,8469\n",
            "5316,8576\n",
            "5317,7127\n",
            "5318,5176\n",
            "5319,7226\n",
            "5320,4824\n",
            "5321,6158\n",
            "5322,6508\n",
            "5323,8250\n",
            "5324,7245\n",
            "5325,5558\n",
            "5326,7627\n",
            "5327,7127\n",
            "5328,8701\n",
            "5329,5298\n",
            "5330,7854\n",
            "5331,6027\n",
            "5332,5154\n",
            "5333,6278\n",
            "5334,6048\n",
            "5335,5100\n",
            "5336,7079\n",
            "5337,6218\n",
            "5338,5881\n",
            "5339,8116\n",
            "5340,7031\n",
            "5341,6027\n",
            "5342,6696\n",
            "5343,7537\n",
            "5344,7079\n",
            "5345,6694\n",
            "5346,7766\n",
            "5347,4547\n",
            "5348,6421\n",
            "5349,6445\n",
            "5350,8070\n",
            "5351,7274\n",
            "5352,7254\n",
            "5353,5279\n",
            "5354,5930\n",
            "5355,5364\n",
            "5356,4668\n",
            "5357,5359\n",
            "5358,4867\n",
            "5359,8945\n",
            "5360,4503\n",
            "5361,4718\n",
            "5362,4405\n",
            "5363,7247\n",
            "5364,5197\n",
            "5365,6203\n",
            "5366,7562\n",
            "5367,4804\n",
            "5368,7307\n",
            "5369,7758\n",
            "5370,8471\n",
            "5371,6334\n",
            "5372,8900\n",
            "5373,5679\n",
            "5374,5814\n",
            "5375,5072\n",
            "5376,8301\n",
            "5377,5859\n",
            "5378,8776\n",
            "5379,8787\n",
            "5380,8012\n",
            "5381,6343\n",
            "5382,8689\n",
            "5383,8101\n",
            "5384,8932\n",
            "5385,5508\n",
            "5386,8761\n",
            "5387,4145\n",
            "5388,5785\n",
            "5389,8762\n",
            "5390,8071\n",
            "5391,6279\n",
            "5392,6161\n",
            "5393,5677\n",
            "5394,4948\n",
            "5395,7784\n",
            "5396,8725\n",
            "5397,4098\n",
            "5398,7089\n",
            "5399,8284\n",
            "5400,4794\n",
            "5401,8472\n",
            "5402,8408\n",
            "5403,6354\n",
            "5404,4671\n",
            "5405,7766\n",
            "5406,5039\n",
            "5407,8636\n",
            "5408,7355\n",
            "5409,5474\n",
            "5410,6659\n",
            "5411,6031\n",
            "5412,8463\n",
            "5413,8775\n",
            "5414,7069\n",
            "5415,4276\n",
            "5416,6279\n",
            "5417,7020\n",
            "5418,6406\n",
            "5419,4163\n",
            "5420,5143\n",
            "5421,8079\n",
            "5422,4426\n",
            "5423,5387\n",
            "5424,5611\n",
            "5425,4503\n",
            "5426,6409\n",
            "5427,7903\n",
            "5428,5121\n",
            "5429,4588\n",
            "5430,6414\n",
            "5431,7034\n",
            "5432,6186\n",
            "5433,7424\n",
            "5434,5460\n",
            "5435,6975\n",
            "5436,6244\n",
            "5437,8209\n",
            "5438,7369\n",
            "5439,8212\n",
            "5440,6725\n",
            "5441,6490\n",
            "5442,7359\n",
            "5443,8488\n",
            "5444,6153\n",
            "5445,6217\n",
            "5446,6835\n",
            "5447,5565\n",
            "5448,4258\n",
            "5449,7922\n",
            "5450,8486\n",
            "5451,8617\n",
            "5452,5451\n",
            "5453,4535\n",
            "5454,5054\n",
            "5455,6204\n",
            "5456,5000\n",
            "5457,5737\n",
            "5458,7154\n",
            "5459,4964\n",
            "5460,6822\n",
            "5461,7250\n",
            "5462,5923\n",
            "5463,7366\n",
            "5464,4821\n",
            "5465,7992\n",
            "5466,7037\n",
            "5467,7704\n",
            "5468,5396\n",
            "5469,6963\n",
            "5470,4685\n",
            "5471,4778\n",
            "5472,7866\n",
            "5473,7038\n",
            "5474,6115\n",
            "5475,6172\n",
            "5476,7026\n",
            "5477,6119\n",
            "5478,8934\n",
            "5479,5861\n",
            "5480,7234\n",
            "5481,5228\n",
            "5482,8891\n",
            "5483,6792\n",
            "5484,5665\n",
            "5485,8398\n",
            "5486,5637\n",
            "5487,6850\n",
            "5488,6313\n",
            "5489,4115\n",
            "5490,8114\n",
            "5491,7897\n",
            "5492,4958\n",
            "5493,5807\n",
            "5494,6143\n",
            "5495,6745\n",
            "5496,5744\n",
            "5497,5404\n",
            "5498,8723\n",
            "5499,8751\n",
            "5500,5281\n",
            "5501,8965\n",
            "5502,4461\n",
            "5503,6544\n",
            "5504,5238\n",
            "5505,5707\n",
            "5506,7859\n",
            "5507,7042\n",
            "5508,4465\n",
            "5509,7453\n",
            "5510,8905\n",
            "5511,6578\n",
            "5512,8239\n",
            "5513,6443\n",
            "5514,6947\n",
            "5515,5619\n",
            "5516,6276\n",
            "5517,6960\n",
            "5518,4113\n",
            "5519,7359\n",
            "5520,6257\n",
            "5521,5895\n",
            "5522,4346\n",
            "5523,8724\n",
            "5524,6800\n",
            "5525,4275\n",
            "5526,4983\n",
            "5527,4171\n",
            "5528,7396\n",
            "5529,8141\n",
            "5530,5202\n",
            "5531,4885\n",
            "5532,7707\n",
            "5533,6558\n",
            "5534,5885\n",
            "5535,8750\n",
            "5536,4672\n",
            "5537,8253\n",
            "5538,4176\n",
            "5539,8263\n",
            "5540,5978\n",
            "5541,6677\n",
            "5542,5928\n",
            "5543,6671\n",
            "5544,6588\n",
            "5545,7628\n",
            "5546,6768\n",
            "5547,8676\n",
            "5548,6279\n",
            "5549,4607\n",
            "5550,4828\n",
            "5551,6137\n",
            "5552,7195\n",
            "5553,6039\n",
            "5554,5797\n",
            "5555,8285\n",
            "5556,4987\n",
            "5557,7412\n",
            "5558,6701\n",
            "5559,8568\n",
            "5560,6227\n",
            "5561,7368\n",
            "5562,7731\n",
            "5563,5608\n",
            "5564,7637\n",
            "5565,5389\n",
            "5566,7965\n",
            "5567,4597\n",
            "5568,6774\n",
            "5569,6289\n",
            "5570,6323\n",
            "5571,4339\n",
            "5572,5194\n",
            "5573,6260\n",
            "5574,8849\n",
            "5575,6440\n",
            "5576,5915\n",
            "5577,7183\n",
            "5578,4573\n",
            "5579,5427\n",
            "5580,7610\n",
            "5581,7184\n",
            "5582,7866\n",
            "5583,4477\n",
            "5584,8159\n",
            "5585,5872\n",
            "5586,8819\n",
            "5587,4708\n",
            "5588,6103\n",
            "5589,4603\n",
            "5590,7115\n",
            "5591,6054\n",
            "5592,5751\n",
            "5593,5296\n",
            "5594,7050\n",
            "5595,4770\n",
            "5596,7885\n",
            "5597,5106\n",
            "5598,8895\n",
            "5599,5125\n",
            "5600,8029\n",
            "5601,5465\n",
            "5602,4457\n",
            "5603,8642\n",
            "5604,4837\n",
            "5605,5941\n",
            "5606,6102\n",
            "5607,4301\n",
            "5608,4635\n",
            "5609,8306\n",
            "5610,7888\n",
            "5611,4672\n",
            "5612,7924\n",
            "5613,6642\n",
            "5614,5980\n",
            "5615,7340\n",
            "5616,5218\n",
            "5617,4987\n",
            "5618,7636\n",
            "5619,5165\n",
            "5620,5062\n",
            "5621,8703\n",
            "5622,7453\n",
            "5623,5260\n",
            "5624,5319\n",
            "5625,8254\n",
            "5626,6822\n",
            "5627,7822\n",
            "5628,8713\n",
            "5629,8293\n",
            "5630,8283\n",
            "5631,8879\n",
            "5632,5363\n",
            "5633,6408\n",
            "5634,7255\n",
            "5635,5356\n",
            "5636,7944\n",
            "5637,5176\n",
            "5638,4740\n",
            "5639,6907\n",
            "5640,4921\n",
            "5641,6120\n",
            "5642,8610\n",
            "5643,7736\n",
            "5644,7870\n",
            "5645,7045\n",
            "5646,4737\n",
            "5647,7406\n",
            "5648,5475\n",
            "5649,4720\n",
            "5650,4104\n",
            "5651,7369\n",
            "5652,8189\n",
            "5653,7205\n",
            "5654,6101\n",
            "5655,6087\n",
            "5656,5083\n",
            "5657,4981\n",
            "5658,4514\n",
            "5659,7233\n",
            "5660,8405\n",
            "5661,7935\n",
            "5662,8575\n",
            "5663,5850\n",
            "5664,4392\n",
            "5665,5499\n",
            "5666,7165\n",
            "5667,7249\n",
            "5668,8558\n",
            "5669,5182\n",
            "5670,6637\n",
            "5671,5123\n",
            "5672,5907\n",
            "5673,6648\n",
            "5674,4203\n",
            "5675,5067\n",
            "5676,8943\n",
            "5677,7537\n",
            "5678,5784\n",
            "5679,4808\n",
            "5680,6470\n",
            "5681,6333\n",
            "5682,4889\n",
            "5683,5171\n",
            "5684,7162\n",
            "5685,5121\n",
            "5686,8715\n",
            "5687,6190\n",
            "5688,8823\n",
            "5689,5417\n",
            "5690,4788\n",
            "5691,7717\n",
            "5692,6671\n",
            "5693,6809\n",
            "5694,8933\n",
            "5695,7808\n",
            "5696,7214\n",
            "5697,7904\n",
            "5698,6865\n",
            "5699,7894\n",
            "5700,6831\n",
            "5701,6634\n",
            "5702,7117\n",
            "5703,8951\n",
            "5704,7982\n",
            "5705,5058\n",
            "5706,8557\n",
            "5707,7715\n",
            "5708,5866\n",
            "5709,4443\n",
            "5710,5260\n",
            "5711,7992\n",
            "5712,4249\n",
            "5713,7825\n",
            "5714,4935\n",
            "5715,7555\n",
            "5716,6857\n",
            "5717,7491\n",
            "5718,5155\n",
            "5719,7718\n",
            "5720,8579\n",
            "5721,4574\n",
            "5722,7172\n",
            "5723,7702\n",
            "5724,7579\n",
            "5725,7417\n",
            "5726,5647\n",
            "5727,4371\n",
            "5728,6316\n",
            "5729,4891\n",
            "5730,8445\n",
            "5731,5886\n",
            "5732,4403\n",
            "5733,5359\n",
            "5734,6891\n",
            "5735,5434\n",
            "5736,7024\n",
            "5737,5023\n",
            "5738,4728\n",
            "5739,5713\n",
            "5740,8923\n",
            "5741,6045\n",
            "5742,5991\n",
            "5743,5851\n",
            "5744,8020\n",
            "5745,6873\n",
            "5746,5803\n",
            "5747,7992\n",
            "5748,5637\n",
            "5749,8910\n",
            "5750,6128\n",
            "5751,5123\n",
            "5752,6461\n",
            "5753,8879\n",
            "5754,6371\n",
            "5755,7644\n",
            "5756,7466\n",
            "5757,4980\n",
            "5758,4255\n",
            "5759,5216\n",
            "5760,7385\n",
            "5761,5477\n",
            "5762,7686\n",
            "5763,6429\n",
            "5764,7513\n",
            "5765,6737\n",
            "5766,5771\n",
            "5767,5790\n",
            "5768,7830\n",
            "5769,6629\n",
            "5770,5219\n",
            "5771,4953\n",
            "5772,6962\n",
            "5773,8826\n",
            "5774,6643\n",
            "5775,4376\n",
            "5776,6930\n",
            "5777,7561\n",
            "5778,5893\n",
            "5779,8561\n",
            "5780,4373\n",
            "5781,4808\n",
            "5782,7699\n",
            "5783,8908\n",
            "5784,7819\n",
            "5785,6556\n",
            "5786,6498\n",
            "5787,8963\n",
            "5788,7508\n",
            "5789,5511\n",
            "5790,7569\n",
            "5791,5578\n",
            "5792,6229\n",
            "5793,7444\n",
            "5794,4486\n",
            "5795,6354\n",
            "5796,5537\n",
            "5797,7957\n",
            "5798,7424\n",
            "5799,8128\n",
            "5800,6427\n",
            "5801,5889\n",
            "5802,7873\n",
            "5803,8248\n",
            "5804,8270\n",
            "5805,7269\n",
            "5806,6245\n",
            "5807,6138\n",
            "5808,5047\n",
            "5809,4267\n",
            "5810,4845\n",
            "5811,5382\n",
            "5812,5786\n",
            "5813,6308\n",
            "5814,7831\n",
            "5815,5677\n",
            "5816,4518\n",
            "5817,6854\n",
            "5818,4977\n",
            "5819,5852\n",
            "5820,5955\n",
            "5821,6308\n",
            "5822,8037\n",
            "5823,6720\n",
            "5824,4999\n",
            "5825,6936\n",
            "5826,4895\n",
            "5827,6651\n",
            "5828,6347\n",
            "5829,8462\n",
            "5830,8460\n",
            "5831,6246\n",
            "5832,4736\n",
            "5833,5602\n",
            "5834,4665\n",
            "5835,5668\n",
            "5836,8500\n",
            "5837,4524\n",
            "5838,6160\n",
            "5839,7176\n",
            "5840,5663\n",
            "5841,4181\n",
            "5842,6637\n",
            "5843,4768\n",
            "5844,5559\n",
            "5845,7970\n",
            "5846,5562\n",
            "5847,7614\n",
            "5848,4560\n",
            "5849,6965\n",
            "5850,4881\n",
            "5851,8872\n",
            "5852,5143\n",
            "5853,7703\n",
            "5854,7317\n",
            "5855,7080\n",
            "5856,7776\n",
            "5857,5234\n",
            "5858,7024\n",
            "5859,6498\n",
            "5860,5374\n",
            "5861,8502\n",
            "5862,8210\n",
            "5863,6075\n",
            "5864,4279\n",
            "5865,7628\n",
            "5866,6016\n",
            "5867,4493\n",
            "5868,4160\n",
            "5869,6468\n",
            "5870,5040\n",
            "5871,7334\n",
            "5872,4697\n",
            "5873,4264\n",
            "5874,5569\n",
            "5875,4271\n",
            "5876,4438\n",
            "5877,5954\n",
            "5878,5530\n",
            "5879,4302\n",
            "5880,5980\n",
            "5881,5122\n",
            "5882,7416\n",
            "5883,5708\n",
            "5884,4707\n",
            "5885,8491\n",
            "5886,8653\n",
            "5887,8615\n",
            "5888,4701\n",
            "5889,7369\n",
            "5890,6096\n",
            "5891,6502\n",
            "5892,7173\n",
            "5893,4354\n",
            "5894,4955\n",
            "5895,5421\n",
            "5896,5580\n",
            "5897,5463\n",
            "5898,4550\n",
            "5899,4713\n",
            "5900,5842\n",
            "5901,5278\n",
            "5902,8630\n",
            "5903,5046\n",
            "5904,6611\n",
            "5905,4177\n",
            "5906,8138\n",
            "5907,5192\n",
            "5908,5557\n",
            "5909,5651\n",
            "5910,4649\n",
            "5911,6785\n",
            "5912,5680\n",
            "5913,4499\n",
            "5914,5357\n",
            "5915,5138\n",
            "5916,4884\n",
            "5917,6336\n",
            "5918,5404\n",
            "5919,8775\n",
            "5920,5060\n",
            "5921,5811\n",
            "5922,6294\n",
            "5923,5719\n",
            "5924,7956\n",
            "5925,4918\n",
            "5926,4913\n",
            "5927,4868\n",
            "5928,5484\n",
            "5929,7323\n",
            "5930,5058\n",
            "5931,4687\n",
            "5932,8431\n",
            "5933,7031\n",
            "5934,4996\n",
            "5935,8726\n",
            "5936,7367\n",
            "5937,7301\n",
            "5938,8032\n",
            "5939,6524\n",
            "5940,6165\n",
            "5941,4569\n",
            "5942,4189\n",
            "5943,7458\n",
            "5944,8107\n",
            "5945,8571\n",
            "5946,6742\n",
            "5947,6332\n",
            "5948,4643\n",
            "5949,6098\n",
            "5950,7523\n",
            "5951,4923\n",
            "5952,6056\n",
            "5953,6347\n",
            "5954,4840\n",
            "5955,7204\n",
            "5956,5080\n",
            "5957,6006\n",
            "5958,6350\n",
            "5959,6926\n",
            "5960,7764\n",
            "5961,5395\n",
            "5962,4883\n",
            "5963,8645\n",
            "5964,4813\n",
            "5965,5607\n",
            "5966,8053\n",
            "5967,8103\n",
            "5968,4507\n",
            "5969,6895\n",
            "5970,7832\n",
            "5971,8032\n",
            "5972,8479\n",
            "5973,5261\n",
            "5974,6817\n",
            "5975,5213\n",
            "5976,4566\n",
            "5977,6416\n",
            "5978,7854\n",
            "5979,7863\n",
            "5980,6354\n",
            "5981,8744\n",
            "5982,5068\n",
            "5983,6653\n",
            "5984,4113\n",
            "5985,4716\n",
            "5986,4866\n",
            "5987,7523\n",
            "5988,7467\n",
            "5989,5509\n",
            "5990,6719\n",
            "5991,6730\n",
            "5992,5835\n",
            "5993,8529\n",
            "5994,8765\n",
            "5995,5819\n",
            "5996,4173\n",
            "5997,8545\n",
            "5998,5154\n",
            "5999,7434\n",
            "6000,5250\n",
            "6001,7134\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "!pip install catboost\n",
        "from catboost import CatBoostRegressor\n",
        "\n",
        "# === CatBoost K-Fold Cross-Validation ===\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "r2_scores_catboost = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_scaled)):\n",
        "    X_train, X_val = X_scaled[train_idx], X_scaled[val_idx]\n",
        "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
        "\n",
        "    # Use CatBoost Regressor\n",
        "    model_catboost = CatBoostRegressor(iterations=100,\n",
        "                                       learning_rate=0.1,\n",
        "                                       depth=5,\n",
        "                                       random_state=42,\n",
        "                                       verbose=0) # Set verbose to 0 to suppress output during training\n",
        "\n",
        "    model_catboost.fit(X_train, y_train)\n",
        "    preds_catboost = model_catboost.predict(X_val)\n",
        "    score_catboost = r2_score(y_val, preds_catboost)\n",
        "    r2_scores_catboost.append(score_catboost)\n",
        "    print(f\"Fold {fold+1} CatBoost R² Score: {score_catboost:.4f}\")\n",
        "\n",
        "print(\"✅ Average CatBoost R² Score across folds:\", np.mean(r2_scores_catboost))\n",
        "\n",
        "# === Train Final CatBoost Model on All Data ===\n",
        "final_model_catboost = CatBoostRegressor(iterations=100,\n",
        "                                         learning_rate=0.1,\n",
        "                                         depth=5,\n",
        "                                         random_state=42,\n",
        "                                         verbose=0)\n",
        "final_model_catboost.fit(X_scaled, y)\n",
        "\n",
        "# === Predict on Test Data with CatBoost ===\n",
        "final_preds_catboost = final_model_catboost.predict(X_test_scaled)\n",
        "\n",
        "# Ensure predictions are integers if the output is expected to be integer-like\n",
        "final_preds_catboost = final_preds_catboost.round().astype(int)\n",
        "\n",
        "# === Save Final Submission File (using CatBoost predictions) ===\n",
        "# sample_submission is already loaded from preceding code\n",
        "sample_submission['output'] = final_preds_catboost\n",
        "sample_submission.to_csv('catboost_submission.csv', index=False)\n",
        "print(\"✅ catboost_submission.csv created!\")\n",
        "\n",
        "# === Optional: CatBoost Grid Search ===\n",
        "# If you want to optimize CatBoost hyperparameters\n",
        "# param_grid_catboost = {\n",
        "#     'depth': [3, 5, 7],\n",
        "#     'learning_rate': [0.01, 0.1, 0.2],\n",
        "#     'iterations': [100, 200, 300],\n",
        "#     'l2_leaf_reg': [1, 3, 5]\n",
        "# }\n",
        "\n",
        "# grid_catboost = GridSearchCV(\n",
        "#     CatBoostRegressor(random_state=42, verbose=0),\n",
        "#     param_grid_catboost,\n",
        "#     cv=5,\n",
        "#     scoring='r2',\n",
        "#     n_jobs=-1 # Use all available cores\n",
        "# )\n",
        "# grid_catboost.fit(X_scaled, y)\n",
        "\n",
        "# print(\"Best GridSearchCV CatBoost R² Score:\", grid_catboost.best_score_)\n",
        "# print(\"Best Params CatBoost:\", grid_catboost.best_params_)\n",
        "\n",
        "# === Predict and Save Submission File with CatBoost Grid Search (if used) ===\n",
        "# final_preds_grid_catboost = grid_catboost.predict(X_test_scaled)\n",
        "# sample_submission['output'] = final_preds_grid_catboost.round().astype(int) # Adjust if output is not integer\n",
        "# sample_submission.to_csv(\"catboost_gridsearch_submission.csv\", index=False)\n",
        "# print(\"✅ Submission file 'catboost_gridsearch_submission.csv' created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoeNo8s9-AgS",
        "outputId": "0e9f9a57-7d61-4e7f-873d-a45ae4145e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Fold 1 CatBoost R² Score: 0.9273\n",
            "Fold 2 CatBoost R² Score: 0.9123\n",
            "Fold 3 CatBoost R² Score: 0.9166\n",
            "Fold 4 CatBoost R² Score: 0.9335\n",
            "Fold 5 CatBoost R² Score: 0.9184\n",
            "✅ Average CatBoost R² Score across folds: 0.9216245675826581\n",
            "✅ catboost_submission.csv created!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv65VQj9srOn",
        "outputId": "840d34fc-606e-414b-f474-f3bd149ea8b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon\n",
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# Assuming train and test DataFrames are already loaded and processed\n",
        "# You might need to adjust column names if they are different\n",
        "\n",
        "# Define the target variable\n",
        "label = 'output'\n",
        "\n",
        "# Initialize TabularPredictor\n",
        "# 'best_quality' setting trains a variety of models and ensembles them\n",
        "predictor = TabularPredictor(label=label, eval_metric='r2').fit(train, presets='best_quality')\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = predictor.predict(test)\n",
        "\n",
        "# Convert predictions to integer if required\n",
        "predictions = predictions.round().astype(int)\n",
        "\n",
        "# Save the submission file\n",
        "# Assuming sample_submission is already loaded and has an 'id' column\n",
        "submission_autogluon = sample_submission.copy()\n",
        "submission_autogluon['output'] = predictions\n",
        "submission_autogluon.to_csv('autogluon_submission.csv', index=False)\n",
        "\n",
        "print(\"✅ autogluon_submission.csv created!\")\n",
        "\n",
        "# You can also get leaderboad to see the performance of different models trained by AutoGluon\n",
        "leaderboard = predictor.leaderboard(silent=True)\n",
        "leaderboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "jVo_d8W4BrbH",
        "outputId": "467fe0ea-e80d-47d6-af88-3ca6e47c4218",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autogluon\n",
            "  Downloading autogluon-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.core==1.3.1 (from autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.core-1.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting autogluon.features==1.3.1 (from autogluon)\n",
            "  Downloading autogluon.features-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.tabular==1.3.1 (from autogluon.tabular[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.tabular-1.3.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting autogluon.multimodal==1.3.1 (from autogluon)\n",
            "  Downloading autogluon.multimodal-1.3.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting autogluon.timeseries==1.3.1 (from autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.timeseries-1.3.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy<2.3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.0.2)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn<1.7.0,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.6.1)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.5)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.2.2)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.10.0)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading boto3-1.39.3-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.3.1 (from autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading autogluon.common-1.3.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting ray<2.45,>=2.10.0 (from ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.3.1->autogluon) (0.2.7)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.core[all]==1.3.1->autogluon) (18.1.0)\n",
            "Requirement already satisfied: Pillow<12,>=10.0.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (11.2.1)\n",
            "Requirement already satisfied: torch<2.7,>=2.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (2.6.0+cu124)\n",
            "Collecting lightning<2.7,>=2.2 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading lightning-2.5.2-py3-none-any.whl.metadata (38 kB)\n",
            "Collecting transformers<4.50,>=4.38.0 (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: accelerate<2.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (1.8.1)\n",
            "Collecting jsonschema<4.24,>=4.18 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting timm<1.0.7,>=0.9.5 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading timm-1.0.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision<0.22.0,>=0.16.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (0.21.0+cu124)\n",
            "Requirement already satisfied: scikit-image<0.26.0,>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (0.25.2)\n",
            "Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (1.3)\n",
            "Collecting torchmetrics<1.8,>=1.2.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading torchmetrics-1.7.4-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: omegaconf<2.4.0,>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (2.3.0)\n",
            "Collecting pytorch-metric-learning<2.9,>=1.3.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting nltk<3.9,>=3.4.5 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (0.7.1)\n",
            "Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (3.1.6)\n",
            "Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.multimodal==1.3.1->autogluon) (2.18.0)\n",
            "Collecting pytesseract<0.4,>=0.3.9 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py3<8.0,>=7.352.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (1.2.8)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (0.8.1)\n",
            "Requirement already satisfied: xgboost<3.1,>=2.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (2.1.4)\n",
            "Requirement already satisfied: fastai<2.9,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (2.7.19)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (0.33.2)\n",
            "Requirement already satisfied: lightgbm<4.7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (4.5.0)\n",
            "Requirement already satisfied: spacy<3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.tabular[all]==1.3.1->autogluon) (3.8.7)\n",
            "Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.5.1)\n",
            "Collecting pytorch-lightning (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting gluonts<0.17,>=0.15.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading gluonts-0.16.2-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting statsforecast<2.0.2,>=1.7.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (29 kB)\n",
            "Collecting mlforecast<0.14,>0.13 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading mlforecast-0.13.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting utilsforecast<0.2.11,>=0.2.3 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading utilsforecast-0.2.10-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting coreforecast<0.0.16,>=0.0.12 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting fugue>=0.9.0 (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading fugue-0.9.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: orjson~=3.9 in /usr/local/lib/python3.11/dist-packages (from autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (3.10.18)\n",
            "Requirement already satisfied: psutil<7.1.0,>=5.7.3 in /usr/local/lib/python3.11/dist-packages (from autogluon.common==1.3.1->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (5.9.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate<2.0,>=0.34.0->autogluon.multimodal==1.3.1->autogluon) (0.5.3)\n",
            "Collecting botocore<1.40.0,>=1.39.3 (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading botocore-1.39.3-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.14.0,>=0.13.0 (from boto3<2,>=1.10->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading s3transfer-0.13.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (0.21)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (1.17.0)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (2.14.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (0.70.15)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.3.1->autogluon) (2025.3.2)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (24.1.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (1.7.29)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.11/dist-packages (from fastai<2.9,>=2.3.1->autogluon.tabular[all]==1.3.1->autogluon) (1.0.3)\n",
            "Collecting triad>=0.9.7 (from fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading triad-0.9.8-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting adagio>=0.2.4 (from fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading adagio-0.2.6-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.11.7)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (4.14.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.3.1->autogluon) (0.10.9.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.3.1->autogluon) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<4.24,>=4.18->autogluon.multimodal==1.3.1->autogluon) (0.26.0)\n",
            "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.9.0.post0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.60.0)\n",
            "Collecting optuna (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting window-ops (from mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (5.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon) (8.2.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk<3.9,>=3.4.5->autogluon.multimodal==1.3.1->autogluon) (2024.11.6)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from omegaconf<2.4.0,>=2.1.1->autogluon.multimodal==1.3.1->autogluon) (4.9.3)\n",
            "Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (13.9.4)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (0.9.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (3.18.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.1.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (5.29.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.11/dist-packages (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.7.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (3.11.15)\n",
            "Collecting aiohttp_cors (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading aiohttp_cors-0.8.1-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting colorful (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading colorful-0.5.7-py2.py3-none-any.whl.metadata (16 kB)\n",
            "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.73.1)\n",
            "Collecting opencensus (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: prometheus_client>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.22.1)\n",
            "Requirement already satisfied: smart_open in /usr/local/lib/python3.11/dist-packages (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (7.3.0)\n",
            "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading virtualenv-20.31.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (2025.6.15)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.3.1->autogluon) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.3.1->autogluon) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image<0.26.0,>=0.19.1->autogluon.multimodal==1.3.1->autogluon) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<1.7.0,>=1.4.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (3.5.0)\n",
            "Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.14.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.3.1->autogluon) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<2.7,>=2.2->autogluon.multimodal==1.3.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<4.50,>=4.38.0->transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon) (0.21.2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.11/dist-packages (from transformers[sentencepiece]<4.50,>=4.38.0->autogluon.multimodal==1.3.1->autogluon) (0.2.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]==1.3.1->autogluon) (1.1.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.20.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (4.13.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.7->gluonts<0.17,>=0.15.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (0.4.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.11/dist-packages (from statsmodels>=0.13.2->statsforecast<2.0.2,>=1.7.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.0.1)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.1.5)\n",
            "Collecting fs (from triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (2.19.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.11/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (4.3.8)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (0.21.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart_open->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.17.2)\n",
            "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (2.25.1)\n",
            "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading alembic-1.16.3-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (2.0.41)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]==1.3.1->autogluon) (8.5.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (1.1.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.70.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (2.38.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.9->autogluon.tabular[all]==1.3.1->autogluon) (1.2.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->mlforecast<0.14,>0.13->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon) (3.2.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (2.7)\n",
            "Collecting appdirs~=1.4.3 (from fs->triad>=0.9.7->fugue>=0.9.0->autogluon.timeseries==1.3.1->autogluon.timeseries[all]==1.3.1->autogluon)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting filelock (from ray<2.45,>=2.10.0->ray[default]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.3.1->autogluon.core[all]==1.3.1->autogluon)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.3.1->autogluon)\n",
            "  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n",
            "  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n",
            "  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n",
            "  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.3.1->autogluon) (1.7.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.45,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.3.1->autogluon) (0.6.1)\n",
            "Downloading autogluon-1.3.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading autogluon.core-1.3.1-py3-none-any.whl (222 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.7/222.7 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.3.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.multimodal-1.3.1-py3-none-any.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.5/454.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.tabular-1.3.1-py3-none-any.whl (382 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m382.4/382.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.timeseries-1.3.1-py3-none-any.whl (181 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.3.1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.39.3-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coreforecast-0.0.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (275 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.8/275.8 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fugue-0.9.1-py3-none-any.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gluonts-0.16.2-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning-2.5.2-py3-none-any.whl (821 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.1/821.1 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlforecast-0.13.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading pytorch_metric_learning-2.8.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.9/125.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ray-2.44.1-cp311-cp311-manylinux2014_x86_64.whl (68.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.1/68.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading statsforecast-2.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (354 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.7.4-py3-none-any.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.5/963.5 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading utilsforecast-0.2.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading adagio-0.2.6-py3-none-any.whl (19 kB)\n",
            "Downloading botocore-1.39.3-py3-none-any.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Downloading py_spy-0.4.0-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.13.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.2/85.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triad-0.9.8-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.31.2-py3-none-any.whl (6.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp_cors-0.8.1-py3-none-any.whl (25 kB)\n",
            "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading colorful-0.5.7-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.5/201.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Downloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n",
            "Downloading alembic-1.16.3-py3-none-any.whl (246 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.9/246.9 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Downloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Downloading pycryptodome-3.23.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Building wheels for collected packages: nvidia-ml-py3, seqeval\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19172 sha256=9f61f0b5ba07159b0cc40150bd5dd007f616af1f954f53b7427a99902e1f2298\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=ccc59b46d12c0b0b9a4c08dc384bd78a3d3c1f8119284c0ec148510d67ba70a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
            "Successfully built nvidia-ml-py3 seqeval\n",
            "Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, appdirs, virtualenv, tensorboardX, pytesseract, pycryptodome, pdf2image, ordered-set, openxlab, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nltk, lightning-utilities, jmespath, fs, coreforecast, colorlog, colorama, window-ops, nvidia-cusparse-cu12, nvidia-cudnn-cu12, model-index, botocore, alembic, utilsforecast, triad, seqeval, s3transfer, optuna, opendatalab, nvidia-cusolver-cu12, jsonschema, gluonts, aiohttp_cors, transformers, ray, openmim, opencensus, nlpaug, mlforecast, boto3, adagio, torchmetrics, pytorch-metric-learning, fugue, evaluate, autogluon.common, timm, statsforecast, pytorch-lightning, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.9.1\n",
            "    Uninstalling nltk-3.9.1:\n",
            "      Successfully uninstalled nltk-3.9.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.24.0\n",
            "    Uninstalling jsonschema-4.24.0:\n",
            "      Successfully uninstalled jsonschema-4.24.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.0\n",
            "    Uninstalling transformers-4.53.0:\n",
            "      Successfully uninstalled transformers-4.53.0\n",
            "  Attempting uninstall: timm\n",
            "    Found existing installation: timm 1.0.16\n",
            "    Uninstalling timm-1.0.16:\n",
            "      Successfully uninstalled timm-1.0.16\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "textblob 0.19.0 requires nltk>=3.9, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed adagio-0.2.6 aiohttp_cors-0.8.1 alembic-1.16.3 appdirs-1.4.4 autogluon-1.3.1 autogluon.common-1.3.1 autogluon.core-1.3.1 autogluon.features-1.3.1 autogluon.multimodal-1.3.1 autogluon.tabular-1.3.1 autogluon.timeseries-1.3.1 boto3-1.39.3 botocore-1.39.3 colorama-0.4.6 colorful-0.5.7 colorlog-6.9.0 coreforecast-0.0.15 distlib-0.3.9 evaluate-0.4.4 fs-2.4.16 fugue-0.9.1 gluonts-0.16.2 jmespath-1.0.1 jsonschema-4.23.0 lightning-2.5.2 lightning-utilities-0.14.3 mlforecast-0.13.6 model-index-0.1.11 nlpaug-1.1.11 nltk-3.8.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py3-7.352.0 nvidia-nvjitlink-cu12-12.4.127 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optuna-4.4.0 ordered-set-4.1.0 pdf2image-1.17.0 py-spy-0.4.0 pycryptodome-3.23.0 pytesseract-0.3.13 pytorch-lightning-2.5.2 pytorch-metric-learning-2.8.1 ray-2.44.1 s3transfer-0.13.0 seqeval-1.2.2 statsforecast-2.0.1 tensorboardX-2.6.4 timm-1.0.3 torchmetrics-1.7.4 transformers-4.49.0 triad-0.9.8 utilsforecast-0.2.10 virtualenv-20.31.2 window-ops-0.0.15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20250709_011357\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.3.1\n",
            "Python Version:     3.11.13\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Sun Mar 30 16:01:29 UTC 2025\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.88 GB / 12.67 GB (85.8%)\n",
            "Disk Space Avail:   65.04 GB / 107.72 GB (60.4%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 900s of the 3600s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2025-07-09 01:14:01,511\tINFO worker.py:1843 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
            "\t\tContext path: \"/content/AutogluonModels/ag-20250709_011357/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Beginning AutoGluon training ... Time limit = 894s\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m AutoGluon will save models to \"/content/AutogluonModels/ag-20250709_011357/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Train Data Rows:    7999\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Train Data Columns: 16\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Label Column:       output\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Problem Type:       regression\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tAvailable Memory:                    10637.84 MB\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t\t('float', []) : 16 | ['clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia', ...]\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t\t('float', []) : 16 | ['clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia', ...]\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.0s = Fit runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t16 features in original data used to generate 16 features in processed data.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Data preprocessing and feature engineering runtime = 0.06s ...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 595.91s of the 894.08s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.8437\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.37s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 589.78s of the 887.95s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.8413\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.32s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 589.44s of the 887.61s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=7151)\u001b[0m [1000]\tvalid_set's l2: 141486\tvalid_set's r2: 0.922797\n",
            "\u001b[36m(_ray_fit pid=7307)\u001b[0m [1000]\tvalid_set's l2: 139286\tvalid_set's r2: 0.919015\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.921\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t57.85s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t1.39s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 528.08s of the 826.24s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9234\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t44.39s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.22s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 478.94s of the 777.11s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9194\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t17.41s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.58s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 460.49s of the 758.66s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=3.90%)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9234\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t40.67s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.08s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 415.26s of the 713.43s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9202\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t10.68s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.57s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 403.46s of the 701.63s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.11%)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.919\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t120.92s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.43s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 279.00s of the 577.16s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9223\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t28.19s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.1s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 239.63s of the 537.80s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\u001b[36m(_ray_fit pid=10452)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 37)\n",
            "\u001b[36m(_ray_fit pid=10857)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 53)\n",
            "\u001b[36m(_ray_fit pid=11638)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 51)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9195\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t228.47s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.69s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 6.71s of the 304.88s of remaining time.\n",
            "\u001b[36m(_ray_fit pid=11723)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 57)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
            "\u001b[36m(_ray_fit pid=12095)\u001b[0m \tRan out of time, early stopping on iteration 174. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=12095)\u001b[0m \t[158]\tvalid_set's l2: 144642\tvalid_set's r2: 0.922568\n",
            "\u001b[36m(_ray_fit pid=12226)\u001b[0m \tRan out of time, early stopping on iteration 168. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12226)\u001b[0m \t[168]\tvalid_set's l2: 147839\tvalid_set's r2: 0.918243\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12362)\u001b[0m \tRan out of time, early stopping on iteration 153. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12362)\u001b[0m \t[107]\tvalid_set's l2: 134856\tvalid_set's r2: 0.92159\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12497)\u001b[0m \tRan out of time, early stopping on iteration 120. Best iteration is:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=12497)\u001b[0m \t[119]\tvalid_set's l2: 142629\tvalid_set's r2: 0.921898\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9206\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t39.24s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.19s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 258.78s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.261, 'CatBoost_BAG_L1': 0.261, 'RandomForestMSE_BAG_L1': 0.217, 'NeuralNetTorch_BAG_L1': 0.13, 'ExtraTreesMSE_BAG_L1': 0.043, 'NeuralNetFastAI_BAG_L1': 0.043, 'XGBoost_BAG_L1': 0.043}\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9249\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.82s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.01s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 257.90s of the 257.71s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9231\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t43.89s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.22s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 209.12s of the 208.92s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\u001b[36m(_ray_fit pid=12500)\u001b[0m \tRan out of time, early stopping on iteration 87. Best iteration is:\n",
            "\u001b[36m(_ray_fit pid=12500)\u001b[0m \t[87]\tvalid_set's l2: 122314\tvalid_set's r2: 0.929861\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9237\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t47.15s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.17s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 156.92s of the 156.73s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9208\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t56.74s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.65s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 98.86s of the 98.67s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.03%)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9238\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t56.73s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.07s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 38.23s of the 38.03s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m /usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m   warnings.warn(\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9229\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t16.02s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.62s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 20.60s of the 20.41s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.15%)\n",
            "\u001b[36m(_ray_fit pid=14857)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 3)\n",
            "\u001b[36m(_ray_fit pid=15025)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 2)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15207)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 0)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_ray_fit pid=15369)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 1)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9126\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t60.01s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.71s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the -45.75s of remaining time.\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \tEnsemble Weights: {'LightGBM_BAG_L1': 0.174, 'CatBoost_BAG_L1': 0.174, 'LightGBM_BAG_L2': 0.174, 'RandomForestMSE_BAG_L1': 0.13, 'ExtraTreesMSE_BAG_L2': 0.13, 'NeuralNetTorch_BAG_L1': 0.087, 'NeuralNetFastAI_BAG_L1': 0.043, 'RandomForestMSE_BAG_L2': 0.043, 'CatBoost_BAG_L2': 0.043}\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.9252\t = Validation score   (r2)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.51s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m \t0.0s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m AutoGluon training complete, total runtime = 940.43s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 268.2 rows/s (1000 batch size)\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250709_011357/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=6792)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "\u001b[36m(_ray_fit pid=15389)\u001b[0m \tRan out of time, stopping training early. (Stopping on epoch 1)\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                     model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0          LightGBM_BAG_L1       0.924154   0.923444          r2        0.104493       0.217801   44.394016                 0.104493                0.217801          44.394016            1       True          4\n",
            "1          LightGBM_BAG_L2       0.923248   0.923655          r2        9.702082       5.114567  634.970742                 0.152386                0.172163          47.145957            2       True         14\n",
            "2      WeightedEnsemble_L3       0.923237   0.925192          r2       10.866852       6.447447  764.960217                 0.009697                0.001640           0.505851            3       True         19\n",
            "3          CatBoost_BAG_L1       0.923104   0.923352          r2        0.485292       0.076202   40.665369                 0.485292                0.076202          40.665369            1       True          6\n",
            "4        LightGBMXT_BAG_L2       0.922882   0.923137          r2        9.772376       5.160591  631.719472                 0.222680                0.218187          43.894687            2       True         13\n",
            "5      WeightedEnsemble_L2       0.922703   0.924891          r2        2.857184       2.683088  491.553471                 0.005654                0.005715           0.823504            2       True         12\n",
            "6        LightGBMXT_BAG_L1       0.922693   0.921025          r2        5.939738       1.386417   57.845738                 5.939738                1.386417          57.845738            1       True          3\n",
            "7          CatBoost_BAG_L2       0.922559   0.923820          r2        9.611262       5.010482  644.551603                 0.061566                0.068078          56.726818            2       True         16\n",
            "8           XGBoost_BAG_L1       0.921713   0.922267          r2        0.232015       0.102579   28.190306                 0.232015                0.102579          28.190306            1       True          9\n",
            "9   RandomForestMSE_BAG_L2       0.921644   0.920821          r2       10.134022       5.588263  644.564491                 0.584327                0.645859          56.739706            2       True         15\n",
            "10    ExtraTreesMSE_BAG_L2       0.921350   0.922939          r2       10.058876       5.559706  603.841886                 0.509180                0.617302          16.017101            2       True         17\n",
            "11    LightGBMLarge_BAG_L1       0.919944   0.920573          r2        0.406122       0.190268   39.235205                 0.406122                0.190268          39.235205            1       True         11\n",
            "12  NeuralNetFastAI_BAG_L2       0.919270   0.912619          r2        9.997289       5.647708  647.835889                 0.447594                0.705304          60.011104            2       True         18\n",
            "13  NeuralNetFastAI_BAG_L1       0.917888   0.919009          r2        0.775466       0.433961  120.923972                 0.775466                0.433961         120.923972            1       True          8\n",
            "14   NeuralNetTorch_BAG_L1       0.917570   0.919493          r2        0.217090       0.693222  228.469234                 0.217090                0.693222         228.469234            1       True         10\n",
            "15    ExtraTreesMSE_BAG_L1       0.916815   0.920243          r2        0.450977       0.569858   10.680293                 0.450977                0.569858          10.680293            1       True          7\n",
            "16  RandomForestMSE_BAG_L1       0.914703   0.919431          r2        0.586197       0.583750   17.406777                 0.586197                0.583750          17.406777            1       True          5\n",
            "17   KNeighborsDist_BAG_L1       0.852751   0.841269          r2        0.205108       0.316834    0.005966                 0.205108                0.316834           0.005966            1       True          2\n",
            "18   KNeighborsUnif_BAG_L1       0.851375   0.843670          r2        0.147197       0.371512    0.007909                 0.147197                0.371512           0.007909            1       True          1\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t962s\t = DyStack   runtime |\t2638s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 2638s\n",
            "AutoGluon will save models to \"/content/AutogluonModels/ag-20250709_011357\"\n",
            "Train Data Rows:    8999\n",
            "Train Data Columns: 16\n",
            "Label Column:       output\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    9877.62 MB\n",
            "\tTrain Data (Original)  Memory Usage: 1.10 MB (0.0% of available memory)\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 16 | ['clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('float', []) : 16 | ['clonesize', 'honeybee', 'bumbles', 'andrena', 'osmia', ...]\n",
            "\t0.2s = Fit runtime\n",
            "\t16 features in original data used to generate 16 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 1.10 MB (0.0% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 0.21s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 1758.29s of the 2638.01s of remaining time.\n",
            "\t0.8461\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.53s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 1754.10s of the 2633.83s of remaining time.\n",
            "\t0.844\t = Validation score   (r2)\n",
            "\t0.01s\t = Training   runtime\n",
            "\t0.45s\t = Validation runtime\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 1753.62s of the 2633.35s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\t0.9216\t = Validation score   (r2)\n",
            "\t53.33s\t = Training   runtime\n",
            "\t1.34s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 1695.74s of the 2575.47s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\t0.9241\t = Validation score   (r2)\n",
            "\t43.31s\t = Training   runtime\n",
            "\t0.15s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 1638.22s of the 2517.94s of remaining time.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "\t0.9191\t = Validation score   (r2)\n",
            "\t21.51s\t = Training   runtime\n",
            "\t0.8s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1614.91s of the 2494.63s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=3.82%)\n",
            "\t0.9237\t = Validation score   (r2)\n",
            "\t47.16s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 1563.69s of the 2443.42s of remaining time.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "\t0.9192\t = Validation score   (r2)\n",
            "\t11.09s\t = Training   runtime\n",
            "\t0.81s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 1550.50s of the 2430.22s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\t0.9192\t = Validation score   (r2)\n",
            "\t130.61s\t = Training   runtime\n",
            "\t0.5s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L1 ... Training model for up to 1414.23s of the 2293.96s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.18%)\n",
            "\t0.9225\t = Validation score   (r2)\n",
            "\t28.28s\t = Training   runtime\n",
            "\t0.33s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 1377.74s of the 2257.46s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.07%)\n",
            "\t0.9203\t = Validation score   (r2)\n",
            "\t431.31s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 941.50s of the 1821.22s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.31%)\n",
            "\t0.9209\t = Validation score   (r2)\n",
            "\t47.72s\t = Training   runtime\n",
            "\t0.25s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 886.05s of the 1765.78s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=3.97%)\n",
            "\t0.9236\t = Validation score   (r2)\n",
            "\t42.8s\t = Training   runtime\n",
            "\t0.08s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 837.82s of the 1717.55s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.06%)\n",
            "\t0.9216\t = Validation score   (r2)\n",
            "\t590.1s\t = Training   runtime\n",
            "\t0.2s\t = Validation runtime\n",
            "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 240.10s of the 1119.83s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\t0.9233\t = Validation score   (r2)\n",
            "\t53.7s\t = Training   runtime\n",
            "\t0.9s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 180.62s of the 1060.35s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.12%)\n",
            "\t0.9154\t = Validation score   (r2)\n",
            "\t198.74s\t = Training   runtime\n",
            "\t0.81s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 855.44s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.3, 'RandomForestMSE_BAG_L1': 0.2, 'CatBoost_BAG_L1': 0.2, 'NeuralNetTorch_r79_BAG_L1': 0.15, 'NeuralNetTorch_BAG_L1': 0.05, 'CatBoost_r177_BAG_L1': 0.05, 'NeuralNetFastAI_r191_BAG_L1': 0.05}\n",
            "\t0.9254\t = Validation score   (r2)\n",
            "\t0.65s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 854.76s of the 854.66s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.20%)\n",
            "\t0.9238\t = Validation score   (r2)\n",
            "\t49.82s\t = Training   runtime\n",
            "\t0.4s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 797.65s of the 797.55s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.19%)\n",
            "\t0.9243\t = Validation score   (r2)\n",
            "\t51.4s\t = Training   runtime\n",
            "\t0.17s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE_BAG_L2 ... Training model for up to 738.26s of the 738.16s of remaining time.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "\t0.9223\t = Validation score   (r2)\n",
            "\t78.81s\t = Training   runtime\n",
            "\t1.39s\t = Validation runtime\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 656.01s of the 655.90s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.02%)\n",
            "\t0.9245\t = Validation score   (r2)\n",
            "\t68.69s\t = Training   runtime\n",
            "\t0.07s\t = Validation runtime\n",
            "Fitting model: ExtraTreesMSE_BAG_L2 ... Training model for up to 582.93s of the 582.82s of remaining time.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "\t0.9229\t = Validation score   (r2)\n",
            "\t20.22s\t = Training   runtime\n",
            "\t0.9s\t = Validation runtime\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 560.65s of the 560.55s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.17%)\n",
            "\t0.9234\t = Validation score   (r2)\n",
            "\t136.84s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 419.58s of the 419.47s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.29%)\n",
            "\t0.9228\t = Validation score   (r2)\n",
            "\t38.55s\t = Training   runtime\n",
            "\t0.14s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 373.88s of the 373.78s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\t0.9226\t = Validation score   (r2)\n",
            "\t195.09s\t = Training   runtime\n",
            "\t0.31s\t = Validation runtime\n",
            "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 172.27s of the 172.17s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.45%)\n",
            "\t0.9223\t = Validation score   (r2)\n",
            "\t80.58s\t = Training   runtime\n",
            "\t0.41s\t = Validation runtime\n",
            "Fitting model: CatBoost_r177_BAG_L2 ... Training model for up to 84.18s of the 84.07s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=4.09%)\n",
            "\t0.9246\t = Validation score   (r2)\n",
            "\t59.21s\t = Training   runtime\n",
            "\t0.11s\t = Validation runtime\n",
            "Fitting model: NeuralNetTorch_r79_BAG_L2 ... Training model for up to 20.17s of the 20.06s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=1, gpus=0, memory=0.10%)\n",
            "\tTime limit exceeded... Skipping NeuralNetTorch_r79_BAG_L2.\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.00s of the 4.56s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.174, 'LightGBM_BAG_L2': 0.174, 'RandomForestMSE_BAG_L2': 0.174, 'CatBoost_BAG_L1': 0.13, 'NeuralNetTorch_r79_BAG_L1': 0.13, 'RandomForestMSE_BAG_L1': 0.087, 'CatBoost_r177_BAG_L2': 0.087, 'NeuralNetTorch_BAG_L1': 0.043}\n",
            "\t0.9258\t = Validation score   (r2)\n",
            "\t0.5s\t = Training   runtime\n",
            "\t0.0s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 2634.32s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 210.0 rows/s (1125 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/content/AutogluonModels/ag-20250709_011357\")\n",
            "2025-07-09 02:13:58,090\tERROR worker.py:420 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ autogluon_submission.csv created!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          model  score_val eval_metric  pred_time_val  \\\n",
              "0           WeightedEnsemble_L3   0.925805          r2       8.843771   \n",
              "1           WeightedEnsemble_L2   0.925383          r2       2.315296   \n",
              "2          CatBoost_r177_BAG_L2   0.924607          r2       7.281036   \n",
              "3               CatBoost_BAG_L2   0.924477          r2       7.244207   \n",
              "4               LightGBM_BAG_L2   0.924329          r2       7.343542   \n",
              "5               LightGBM_BAG_L1   0.924055          r2       0.147568   \n",
              "6             LightGBMXT_BAG_L2   0.923771          r2       7.574153   \n",
              "7               CatBoost_BAG_L1   0.923742          r2       0.078168   \n",
              "8          CatBoost_r177_BAG_L1   0.923625          r2       0.075666   \n",
              "9        NeuralNetFastAI_BAG_L2   0.923398          r2       7.580609   \n",
              "10         LightGBM_r131_BAG_L1   0.923294          r2       0.899334   \n",
              "11         ExtraTreesMSE_BAG_L2   0.922873          r2       8.074303   \n",
              "12               XGBoost_BAG_L2   0.922823          r2       7.308044   \n",
              "13        NeuralNetTorch_BAG_L2   0.922602          r2       7.479074   \n",
              "14               XGBoost_BAG_L1   0.922509          r2       0.327503   \n",
              "15       RandomForestMSE_BAG_L2   0.922302          r2       8.557728   \n",
              "16         LightGBMLarge_BAG_L2   0.922293          r2       7.577398   \n",
              "17    NeuralNetTorch_r79_BAG_L1   0.921627          r2       0.202289   \n",
              "18            LightGBMXT_BAG_L1   0.921573          r2       1.342852   \n",
              "19         LightGBMLarge_BAG_L1   0.920912          r2       0.245070   \n",
              "20        NeuralNetTorch_BAG_L1   0.920347          r2       0.196947   \n",
              "21       NeuralNetFastAI_BAG_L1   0.919238          r2       0.496425   \n",
              "22         ExtraTreesMSE_BAG_L1   0.919193          r2       0.807365   \n",
              "23       RandomForestMSE_BAG_L1   0.919105          r2       0.803669   \n",
              "24  NeuralNetFastAI_r191_BAG_L1   0.915398          r2       0.809521   \n",
              "25        KNeighborsUnif_BAG_L1   0.846123          r2       0.533054   \n",
              "26        KNeighborsDist_BAG_L1   0.843990          r2       0.450104   \n",
              "\n",
              "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              "0   1841.899952                0.002394           0.504927            3   \n",
              "1   1375.600379                0.001468           0.649298            2   \n",
              "2   1711.187379                0.110571          59.205927            2   \n",
              "3   1720.667668                0.073743          68.686216            2   \n",
              "4   1703.377781                0.173077          51.396329            2   \n",
              "5     43.313611                0.147568          43.313611            1   \n",
              "6   1701.804771                0.403688          49.823320            2   \n",
              "7     47.162726                0.078168          47.162726            1   \n",
              "8     42.804476                0.075666          42.804476            1   \n",
              "9   1788.825384                0.410145         136.843932            2   \n",
              "10    53.699728                0.899334          53.699728            1   \n",
              "11  1672.198611                0.903839          20.217159            2   \n",
              "12  1690.529994                0.137579          38.548542            2   \n",
              "13  1847.071618                0.308609         195.090166            2   \n",
              "14    28.278394                0.327503          28.278394            1   \n",
              "15  1730.792768                1.387264          78.811316            2   \n",
              "16  1732.563571                0.406933          80.582119            2   \n",
              "17   590.104048                0.202289         590.104048            1   \n",
              "18    53.333341                1.342852          53.333341            1   \n",
              "19    47.715178                0.245070          47.715178            1   \n",
              "20   431.312402                0.196947         431.312402            1   \n",
              "21   130.611481                0.496425         130.611481            1   \n",
              "22    11.090853                0.807365          11.090853            1   \n",
              "23    21.514345                0.803669          21.514345            1   \n",
              "24   198.739471                0.809521         198.739471            1   \n",
              "25     0.009689                0.533054           0.009689            1   \n",
              "26     0.006886                0.450104           0.006886            1   \n",
              "\n",
              "    can_infer  fit_order  \n",
              "0        True         27  \n",
              "1        True         16  \n",
              "2        True         26  \n",
              "3        True         20  \n",
              "4        True         18  \n",
              "5        True          4  \n",
              "6        True         17  \n",
              "7        True          6  \n",
              "8        True         12  \n",
              "9        True         22  \n",
              "10       True         14  \n",
              "11       True         21  \n",
              "12       True         23  \n",
              "13       True         24  \n",
              "14       True          9  \n",
              "15       True         19  \n",
              "16       True         25  \n",
              "17       True         13  \n",
              "18       True          3  \n",
              "19       True         11  \n",
              "20       True         10  \n",
              "21       True          8  \n",
              "22       True          7  \n",
              "23       True          5  \n",
              "24       True         15  \n",
              "25       True          1  \n",
              "26       True          2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e3adec6-0b7c-4b39-94a7-d593c46fa250\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>0.925805</td>\n",
              "      <td>r2</td>\n",
              "      <td>8.843771</td>\n",
              "      <td>1841.899952</td>\n",
              "      <td>0.002394</td>\n",
              "      <td>0.504927</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.925383</td>\n",
              "      <td>r2</td>\n",
              "      <td>2.315296</td>\n",
              "      <td>1375.600379</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.649298</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CatBoost_r177_BAG_L2</td>\n",
              "      <td>0.924607</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.281036</td>\n",
              "      <td>1711.187379</td>\n",
              "      <td>0.110571</td>\n",
              "      <td>59.205927</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CatBoost_BAG_L2</td>\n",
              "      <td>0.924477</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.244207</td>\n",
              "      <td>1720.667668</td>\n",
              "      <td>0.073743</td>\n",
              "      <td>68.686216</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>0.924329</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.343542</td>\n",
              "      <td>1703.377781</td>\n",
              "      <td>0.173077</td>\n",
              "      <td>51.396329</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.924055</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.147568</td>\n",
              "      <td>43.313611</td>\n",
              "      <td>0.147568</td>\n",
              "      <td>43.313611</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>0.923771</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.574153</td>\n",
              "      <td>1701.804771</td>\n",
              "      <td>0.403688</td>\n",
              "      <td>49.823320</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>CatBoost_BAG_L1</td>\n",
              "      <td>0.923742</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.078168</td>\n",
              "      <td>47.162726</td>\n",
              "      <td>0.078168</td>\n",
              "      <td>47.162726</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>CatBoost_r177_BAG_L1</td>\n",
              "      <td>0.923625</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.075666</td>\n",
              "      <td>42.804476</td>\n",
              "      <td>0.075666</td>\n",
              "      <td>42.804476</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>NeuralNetFastAI_BAG_L2</td>\n",
              "      <td>0.923398</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.580609</td>\n",
              "      <td>1788.825384</td>\n",
              "      <td>0.410145</td>\n",
              "      <td>136.843932</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LightGBM_r131_BAG_L1</td>\n",
              "      <td>0.923294</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.899334</td>\n",
              "      <td>53.699728</td>\n",
              "      <td>0.899334</td>\n",
              "      <td>53.699728</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ExtraTreesMSE_BAG_L2</td>\n",
              "      <td>0.922873</td>\n",
              "      <td>r2</td>\n",
              "      <td>8.074303</td>\n",
              "      <td>1672.198611</td>\n",
              "      <td>0.903839</td>\n",
              "      <td>20.217159</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>XGBoost_BAG_L2</td>\n",
              "      <td>0.922823</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.308044</td>\n",
              "      <td>1690.529994</td>\n",
              "      <td>0.137579</td>\n",
              "      <td>38.548542</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>NeuralNetTorch_BAG_L2</td>\n",
              "      <td>0.922602</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.479074</td>\n",
              "      <td>1847.071618</td>\n",
              "      <td>0.308609</td>\n",
              "      <td>195.090166</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>XGBoost_BAG_L1</td>\n",
              "      <td>0.922509</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.327503</td>\n",
              "      <td>28.278394</td>\n",
              "      <td>0.327503</td>\n",
              "      <td>28.278394</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>RandomForestMSE_BAG_L2</td>\n",
              "      <td>0.922302</td>\n",
              "      <td>r2</td>\n",
              "      <td>8.557728</td>\n",
              "      <td>1730.792768</td>\n",
              "      <td>1.387264</td>\n",
              "      <td>78.811316</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>LightGBMLarge_BAG_L2</td>\n",
              "      <td>0.922293</td>\n",
              "      <td>r2</td>\n",
              "      <td>7.577398</td>\n",
              "      <td>1732.563571</td>\n",
              "      <td>0.406933</td>\n",
              "      <td>80.582119</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
              "      <td>0.921627</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.202289</td>\n",
              "      <td>590.104048</td>\n",
              "      <td>0.202289</td>\n",
              "      <td>590.104048</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>0.921573</td>\n",
              "      <td>r2</td>\n",
              "      <td>1.342852</td>\n",
              "      <td>53.333341</td>\n",
              "      <td>1.342852</td>\n",
              "      <td>53.333341</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>LightGBMLarge_BAG_L1</td>\n",
              "      <td>0.920912</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.245070</td>\n",
              "      <td>47.715178</td>\n",
              "      <td>0.245070</td>\n",
              "      <td>47.715178</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>NeuralNetTorch_BAG_L1</td>\n",
              "      <td>0.920347</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.196947</td>\n",
              "      <td>431.312402</td>\n",
              "      <td>0.196947</td>\n",
              "      <td>431.312402</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>NeuralNetFastAI_BAG_L1</td>\n",
              "      <td>0.919238</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.496425</td>\n",
              "      <td>130.611481</td>\n",
              "      <td>0.496425</td>\n",
              "      <td>130.611481</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ExtraTreesMSE_BAG_L1</td>\n",
              "      <td>0.919193</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.807365</td>\n",
              "      <td>11.090853</td>\n",
              "      <td>0.807365</td>\n",
              "      <td>11.090853</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>RandomForestMSE_BAG_L1</td>\n",
              "      <td>0.919105</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.803669</td>\n",
              "      <td>21.514345</td>\n",
              "      <td>0.803669</td>\n",
              "      <td>21.514345</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
              "      <td>0.915398</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.809521</td>\n",
              "      <td>198.739471</td>\n",
              "      <td>0.809521</td>\n",
              "      <td>198.739471</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>KNeighborsUnif_BAG_L1</td>\n",
              "      <td>0.846123</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.533054</td>\n",
              "      <td>0.009689</td>\n",
              "      <td>0.533054</td>\n",
              "      <td>0.009689</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>KNeighborsDist_BAG_L1</td>\n",
              "      <td>0.843990</td>\n",
              "      <td>r2</td>\n",
              "      <td>0.450104</td>\n",
              "      <td>0.006886</td>\n",
              "      <td>0.450104</td>\n",
              "      <td>0.006886</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e3adec6-0b7c-4b39-94a7-d593c46fa250')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4e3adec6-0b7c-4b39-94a7-d593c46fa250 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4e3adec6-0b7c-4b39-94a7-d593c46fa250');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a663b9dc-72dd-4b85-a41c-8af6a98bf75c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a663b9dc-72dd-4b85-a41c-8af6a98bf75c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a663b9dc-72dd-4b85-a41c-8af6a98bf75c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_953c1e40-f344-4725-9e6f-d7f05851f4b1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('leaderboard')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_953c1e40-f344-4725-9e6f-d7f05851f4b1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('leaderboard');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "leaderboard",
              "summary": "{\n  \"name\": \"leaderboard\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"CatBoost_r177_BAG_L1\",\n          \"NeuralNetTorch_BAG_L2\",\n          \"NeuralNetFastAI_BAG_L2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.020757986943626874,\n        \"min\": 0.8439902908146875,\n        \"max\": 0.9258049231658229,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.9236253670591796,\n          0.9226024185541067,\n          0.923397622501614\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"r2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.6011844056559443,\n        \"min\": 0.07566595077514648,\n        \"max\": 8.843770980834961,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.07566595077514648\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 821.8323604775123,\n        \"min\": 0.0068857669830322266,\n        \"max\": 1847.071617603302,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          42.80447602272034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38623769442880024,\n        \"min\": 0.0014679431915283203,\n        \"max\": 1.387263536453247,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.07566595077514648\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 133.454641518215,\n        \"min\": 0.0068857669830322266,\n        \"max\": 590.1040480136871,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          42.80447602272034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 1,\n        \"max\": 27,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "!pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2W-VvBO_VmQU",
        "outputId": "41914cdc-b751-4c10-d5d6-c11f83fa98e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n",
            "Successfully installed catboost-1.2.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import optuna\n",
        "\n",
        "# === Load Datasets ===\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "sample_submission = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "# === Drop unnecessary columns ===\n",
        "train = train.drop(columns=['Row#'])\n",
        "test = test.drop(columns=['Row#'])\n",
        "\n",
        "# === Prepare Features and Target ===\n",
        "X = train.drop(columns=['output'])\n",
        "y = train['output']\n",
        "X_test = test.drop(columns=['id'])\n",
        "\n",
        "# === Scale Features ===\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# === Optuna + RandomForest with K-Fold Cross-Validation (R² Score) ===\n",
        "def run_optuna_random_forest_kfold():\n",
        "    def objective(trial):\n",
        "        params = {\n",
        "            'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
        "            'max_depth': trial.suggest_int('max_depth', 5, 30),\n",
        "            'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
        "            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5)\n",
        "        }\n",
        "\n",
        "        kf = KFold(n_splits=8, shuffle=True, random_state=42)\n",
        "        r2_scores = []\n",
        "\n",
        "        for train_idx, val_idx in kf.split(X_scaled):\n",
        "            X_train_fold, X_val_fold = X_scaled[train_idx], X_scaled[val_idx]\n",
        "            y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "\n",
        "            model = RandomForestRegressor(random_state=42, **params)\n",
        "            model.fit(X_train_fold, y_train_fold)\n",
        "            preds = model.predict(X_val_fold)\n",
        "            r2 = r2_score(y_val_fold, preds)\n",
        "            r2_scores.append(r2)\n",
        "\n",
        "        return -np.mean(r2_scores)  # Minimize the negative average R²\n",
        "\n",
        "    # Run Optuna Study\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=150)\n",
        "\n",
        "    print(\"✅ Best Parameters Found by Optuna:\", study.best_params)\n",
        "    print(\"✅ Best Mean Validation R² Score (CV):\", -study.best_value)\n",
        "\n",
        "    # Train final model on full training data\n",
        "    best_model = RandomForestRegressor(random_state=42, **study.best_params)\n",
        "    best_model.fit(X_scaled, y)\n",
        "\n",
        "    # 🔍 R² on full training data\n",
        "    train_preds = best_model.predict(X_scaled)\n",
        "    final_r2 = r2_score(y, train_preds)\n",
        "    print(\"🎯 Final R² Score on Full Training Data:\", final_r2)\n",
        "\n",
        "    return best_model\n",
        "\n",
        "# === Run the model optimization and training ===\n",
        "model = run_optuna_random_forest_kfold()\n",
        "\n",
        "# === Predict on Test Data ===\n",
        "final_preds = model.predict(X_test_scaled)\n",
        "\n",
        "# === Save Final Submission File ===\n",
        "sample_submission['output'] = final_preds\n",
        "sample_submission.to_csv('lakhbir_1187_kfold.csv', index=False)\n",
        "print(\"✅ lakhbir_1187_kfold.csv created!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8aGqdwyEXPSP",
        "outputId": "984b78fd-4049-4d68-eaa0-c87687c8ea62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-07-08 14:07:35,700] A new study created in memory with name: no-name-78177a16-95ae-406b-be5d-29f5467dbe52\n",
            "[I 2025-07-08 14:10:10,519] Trial 0 finished with value: -0.9223472378638351 and parameters: {'n_estimators': 423, 'max_depth': 22, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 0 with value: -0.9223472378638351.\n",
            "[I 2025-07-08 14:13:18,545] Trial 1 finished with value: -0.9219058257159869 and parameters: {'n_estimators': 477, 'max_depth': 25, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 0 with value: -0.9223472378638351.\n",
            "[I 2025-07-08 14:15:35,226] Trial 2 finished with value: -0.9210912288717408 and parameters: {'n_estimators': 387, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 0 with value: -0.9223472378638351.\n",
            "[I 2025-07-08 14:15:58,724] Trial 3 finished with value: -0.9236391474208624 and parameters: {'n_estimators': 118, 'max_depth': 7, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:17:37,583] Trial 4 finished with value: -0.9227524864518581 and parameters: {'n_estimators': 315, 'max_depth': 11, 'min_samples_split': 3, 'min_samples_leaf': 3}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:19:15,862] Trial 5 finished with value: -0.9217773602118786 and parameters: {'n_estimators': 257, 'max_depth': 22, 'min_samples_split': 8, 'min_samples_leaf': 3}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:20:44,330] Trial 6 finished with value: -0.922824568945609 and parameters: {'n_estimators': 275, 'max_depth': 12, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:23:02,589] Trial 7 finished with value: -0.9226209726572114 and parameters: {'n_estimators': 396, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:25:38,143] Trial 8 finished with value: -0.9227653411778078 and parameters: {'n_estimators': 496, 'max_depth': 11, 'min_samples_split': 7, 'min_samples_leaf': 3}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:27:00,083] Trial 9 finished with value: -0.9222779801691772 and parameters: {'n_estimators': 225, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:27:15,742] Trial 10 finished with value: -0.9212138745208461 and parameters: {'n_estimators': 104, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:27:31,271] Trial 11 finished with value: -0.921842268562806 and parameters: {'n_estimators': 101, 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 5}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:28:17,737] Trial 12 finished with value: -0.9234666718717791 and parameters: {'n_estimators': 181, 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:29:28,801] Trial 13 finished with value: -0.9212036486723023 and parameters: {'n_estimators': 176, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 3 with value: -0.9236391474208624.\n",
            "[I 2025-07-08 14:30:03,455] Trial 14 finished with value: -0.9236950801657957 and parameters: {'n_estimators': 167, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 14 with value: -0.9236950801657957.\n",
            "[I 2025-07-08 14:30:35,283] Trial 15 finished with value: -0.9237099971727334 and parameters: {'n_estimators': 158, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 15 with value: -0.9237099971727334.\n",
            "[I 2025-07-08 14:31:33,504] Trial 16 finished with value: -0.9227589627063189 and parameters: {'n_estimators': 175, 'max_depth': 13, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 15 with value: -0.9237099971727334.\n",
            "[I 2025-07-08 14:33:20,610] Trial 17 finished with value: -0.922674960400905 and parameters: {'n_estimators': 315, 'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 15 with value: -0.9237099971727334.\n",
            "[I 2025-07-08 14:34:10,980] Trial 18 finished with value: -0.92320405475165 and parameters: {'n_estimators': 217, 'max_depth': 8, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 15 with value: -0.9237099971727334.\n",
            "[I 2025-07-08 14:34:40,539] Trial 19 finished with value: -0.9237439933345593 and parameters: {'n_estimators': 146, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 19 with value: -0.9237439933345593.\n",
            "[I 2025-07-08 14:35:27,433] Trial 20 finished with value: -0.9226966129687979 and parameters: {'n_estimators': 142, 'max_depth': 14, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 19 with value: -0.9237439933345593.\n",
            "[I 2025-07-08 14:36:02,382] Trial 21 finished with value: -0.9237594307369872 and parameters: {'n_estimators': 149, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:36:34,957] Trial 22 finished with value: -0.9219650881636867 and parameters: {'n_estimators': 218, 'max_depth': 5, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:37:13,232] Trial 23 finished with value: -0.9235799269568692 and parameters: {'n_estimators': 149, 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:37:48,510] Trial 24 finished with value: -0.9235821225673828 and parameters: {'n_estimators': 136, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:38:29,270] Trial 25 finished with value: -0.9237401964771366 and parameters: {'n_estimators': 200, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:39:43,252] Trial 26 finished with value: -0.9222662371288584 and parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:40:53,718] Trial 27 finished with value: -0.9232302211003806 and parameters: {'n_estimators': 250, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:42:57,674] Trial 28 finished with value: -0.9223473944709464 and parameters: {'n_estimators': 347, 'max_depth': 15, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:43:32,723] Trial 29 finished with value: -0.923305998802881 and parameters: {'n_estimators': 195, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:44:15,075] Trial 30 finished with value: -0.9225279286742601 and parameters: {'n_estimators': 123, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:44:49,121] Trial 31 finished with value: -0.9237366688767696 and parameters: {'n_estimators': 164, 'max_depth': 7, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:45:45,082] Trial 32 finished with value: -0.9237428180957177 and parameters: {'n_estimators': 244, 'max_depth': 8, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:46:47,856] Trial 33 finished with value: -0.9235740447210787 and parameters: {'n_estimators': 244, 'max_depth': 9, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:48:17,713] Trial 34 finished with value: -0.9227486065020623 and parameters: {'n_estimators': 277, 'max_depth': 12, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:49:04,239] Trial 35 finished with value: -0.9237373909920856 and parameters: {'n_estimators': 200, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:50:33,984] Trial 36 finished with value: -0.9227201932849578 and parameters: {'n_estimators': 287, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:51:59,506] Trial 37 finished with value: -0.9222232102749031 and parameters: {'n_estimators': 233, 'max_depth': 19, 'min_samples_split': 3, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:53:16,520] Trial 38 finished with value: -0.9232242336392361 and parameters: {'n_estimators': 433, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:53:58,034] Trial 39 finished with value: -0.9227713510647717 and parameters: {'n_estimators': 127, 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:56:09,916] Trial 40 finished with value: -0.9222391484547836 and parameters: {'n_estimators': 358, 'max_depth': 23, 'min_samples_split': 6, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:56:56,236] Trial 41 finished with value: -0.9237281486455706 and parameters: {'n_estimators': 204, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:58:10,303] Trial 42 finished with value: -0.923313548687295 and parameters: {'n_estimators': 264, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:58:51,987] Trial 43 finished with value: -0.9233857530080138 and parameters: {'n_estimators': 237, 'max_depth': 6, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 14:59:35,538] Trial 44 finished with value: -0.9237405961777204 and parameters: {'n_estimators': 191, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:00:28,223] Trial 45 finished with value: -0.9233269243697886 and parameters: {'n_estimators': 189, 'max_depth': 10, 'min_samples_split': 4, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:00:46,515] Trial 46 finished with value: -0.9218605620231957 and parameters: {'n_estimators': 116, 'max_depth': 5, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:01:15,226] Trial 47 finished with value: -0.9237353411243993 and parameters: {'n_estimators': 142, 'max_depth': 7, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:02:23,437] Trial 48 finished with value: -0.9222848645611372 and parameters: {'n_estimators': 215, 'max_depth': 11, 'min_samples_split': 5, 'min_samples_leaf': 2}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:03:14,704] Trial 49 finished with value: -0.9227204980650163 and parameters: {'n_estimators': 158, 'max_depth': 12, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:04:10,560] Trial 50 finished with value: -0.9223982171817628 and parameters: {'n_estimators': 316, 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:04:52,450] Trial 51 finished with value: -0.9237400205303468 and parameters: {'n_estimators': 183, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:05:32,528] Trial 52 finished with value: -0.9237253901418223 and parameters: {'n_estimators': 174, 'max_depth': 8, 'min_samples_split': 7, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:06:23,919] Trial 53 finished with value: -0.9233297676659523 and parameters: {'n_estimators': 184, 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[I 2025-07-08 15:07:00,721] Trial 54 finished with value: -0.9237247893570167 and parameters: {'n_estimators': 159, 'max_depth': 8, 'min_samples_split': 6, 'min_samples_leaf': 5}. Best is trial 21 with value: -0.9237594307369872.\n",
            "[W 2025-07-08 15:07:11,107] Trial 55 failed with parameters: {'n_estimators': 109, 'max_depth': 5, 'min_samples_split': 6, 'min_samples_leaf': 5} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-14-2666848267.py\", line 46, in objective\n",
            "    model.fit(X_train_fold, y_train_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 487, in fit\n",
            "    trees = Parallel(\n",
            "            ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1986, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n",
            "    tree._fit(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 472, in _fit\n",
            "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
            "KeyboardInterrupt\n",
            "[W 2025-07-08 15:07:11,116] Trial 55 failed with value None.\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-14-2666848267.py\", line 72, in <cell line: 0>\n",
            "    model = run_optuna_random_forest_kfold()\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-14-2666848267.py\", line 55, in run_optuna_random_forest_kfold\n",
            "    study.optimize(objective, n_trials=150)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/study.py\", line 489, in optimize\n",
            "    _optimize(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 64, in _optimize\n",
            "    _optimize_sequential(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 161, in _optimize_sequential\n",
            "    frozen_trial = _run_trial(study, func, catch)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 253, in _run_trial\n",
            "    raise func_err\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipython-input-14-2666848267.py\", line 46, in objective\n",
            "    model.fit(X_train_fold, y_train_fold)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 487, in fit\n",
            "    trees = Parallel(\n",
            "            ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 77, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1986, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "                                                ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\", line 1914, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\", line 139, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n",
            "    tree._fit(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/tree/_classes.py\", line 472, in _fit\n",
            "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 997, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 416, in realpath\n",
            "  File \"<frozen posixpath>\", line 460, in _joinrealpath\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}